{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKAxbUFku8lD"
   },
   "source": [
    "# **Dependancies**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oFJOnSzBk_uB",
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.007344Z",
     "start_time": "2024-04-17T02:58:36.915338Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import *\n",
    "from keras.callbacks import *\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from commons import mean_absolute_percentage_error\n",
    "from keras.layers import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import LogCosh"
   ],
   "outputs": [],
   "execution_count": 181
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22PseW2xqQET"
   },
   "source": [
    "# **Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0HH_FAAlRXx",
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.131354Z",
     "start_time": "2024-04-17T02:58:37.009345Z"
    }
   },
   "source": [
    "PATH_TO_DATA = \"E:/DS440proj/BTCpred/btc_data-research_paper/reg_interval1.csv\"\n",
    "data = pd.read_csv(PATH_TO_DATA)"
   ],
   "outputs": [],
   "execution_count": 182
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.193299Z",
     "start_time": "2024-04-17T02:58:37.132355Z"
    }
   },
   "source": [
    "data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   difficulty3var  fee_to_rewardUSD  hashrate90std  \\\n",
       "0   -4.294967e+09            24.447   5.438008e+18   \n",
       "1   -5.368709e+09            23.309   5.589062e+18   \n",
       "2   -5.368709e+09            19.255   5.634595e+18   \n",
       "3   -5.368709e+09            13.105   6.187523e+18   \n",
       "4   -5.368709e+09            11.452   6.338603e+18   \n",
       "\n",
       "   mediantransactionvalue90trxUSD  mining_profitability30trx  price14wmaUSD  \\\n",
       "0                           1.707                      0.516          13714   \n",
       "1                           1.716                      0.446          13332   \n",
       "2                           1.722                      0.376          12982   \n",
       "3                           1.715                      0.162          12322   \n",
       "4                           1.705                      0.090          12038   \n",
       "\n",
       "   price30emaUSD  price3wmaUSD  price7smaUSD  price7wmaUSD  price90momUSD  \\\n",
       "0          14124         11780         13261         12798         5091.0   \n",
       "1          13959         11405         12933         12373         5773.0   \n",
       "2          13804         11425         12605         12030         5483.0   \n",
       "3          13456         11694         11695         11707         5555.0   \n",
       "4          13285         11136         11487         11484         5254.0   \n",
       "\n",
       "   top100cap90sma  transactionvalue30smaUSD  transactionvalue90emaUSD  \\\n",
       "0          16.875                     96961                     85113   \n",
       "1          16.886                     96445                     85012   \n",
       "2          16.897                     96146                     85180   \n",
       "3          16.941                     94913                     84139   \n",
       "4          16.958                     94620                     83633   \n",
       "\n",
       "   priceUSD  \n",
       "0     10747  \n",
       "1     11561  \n",
       "2     11560  \n",
       "3     11217  \n",
       "4     10800  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>difficulty3var</th>\n",
       "      <th>fee_to_rewardUSD</th>\n",
       "      <th>hashrate90std</th>\n",
       "      <th>mediantransactionvalue90trxUSD</th>\n",
       "      <th>mining_profitability30trx</th>\n",
       "      <th>price14wmaUSD</th>\n",
       "      <th>price30emaUSD</th>\n",
       "      <th>price3wmaUSD</th>\n",
       "      <th>price7smaUSD</th>\n",
       "      <th>price7wmaUSD</th>\n",
       "      <th>price90momUSD</th>\n",
       "      <th>top100cap90sma</th>\n",
       "      <th>transactionvalue30smaUSD</th>\n",
       "      <th>transactionvalue90emaUSD</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.294967e+09</td>\n",
       "      <td>24.447</td>\n",
       "      <td>5.438008e+18</td>\n",
       "      <td>1.707</td>\n",
       "      <td>0.516</td>\n",
       "      <td>13714</td>\n",
       "      <td>14124</td>\n",
       "      <td>11780</td>\n",
       "      <td>13261</td>\n",
       "      <td>12798</td>\n",
       "      <td>5091.0</td>\n",
       "      <td>16.875</td>\n",
       "      <td>96961</td>\n",
       "      <td>85113</td>\n",
       "      <td>10747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.368709e+09</td>\n",
       "      <td>23.309</td>\n",
       "      <td>5.589062e+18</td>\n",
       "      <td>1.716</td>\n",
       "      <td>0.446</td>\n",
       "      <td>13332</td>\n",
       "      <td>13959</td>\n",
       "      <td>11405</td>\n",
       "      <td>12933</td>\n",
       "      <td>12373</td>\n",
       "      <td>5773.0</td>\n",
       "      <td>16.886</td>\n",
       "      <td>96445</td>\n",
       "      <td>85012</td>\n",
       "      <td>11561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.368709e+09</td>\n",
       "      <td>19.255</td>\n",
       "      <td>5.634595e+18</td>\n",
       "      <td>1.722</td>\n",
       "      <td>0.376</td>\n",
       "      <td>12982</td>\n",
       "      <td>13804</td>\n",
       "      <td>11425</td>\n",
       "      <td>12605</td>\n",
       "      <td>12030</td>\n",
       "      <td>5483.0</td>\n",
       "      <td>16.897</td>\n",
       "      <td>96146</td>\n",
       "      <td>85180</td>\n",
       "      <td>11560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.368709e+09</td>\n",
       "      <td>13.105</td>\n",
       "      <td>6.187523e+18</td>\n",
       "      <td>1.715</td>\n",
       "      <td>0.162</td>\n",
       "      <td>12322</td>\n",
       "      <td>13456</td>\n",
       "      <td>11694</td>\n",
       "      <td>11695</td>\n",
       "      <td>11707</td>\n",
       "      <td>5555.0</td>\n",
       "      <td>16.941</td>\n",
       "      <td>94913</td>\n",
       "      <td>84139</td>\n",
       "      <td>11217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.368709e+09</td>\n",
       "      <td>11.452</td>\n",
       "      <td>6.338603e+18</td>\n",
       "      <td>1.705</td>\n",
       "      <td>0.090</td>\n",
       "      <td>12038</td>\n",
       "      <td>13285</td>\n",
       "      <td>11136</td>\n",
       "      <td>11487</td>\n",
       "      <td>11484</td>\n",
       "      <td>5254.0</td>\n",
       "      <td>16.958</td>\n",
       "      <td>94620</td>\n",
       "      <td>83633</td>\n",
       "      <td>10800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 183
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.208799Z",
     "start_time": "2024-04-17T02:58:37.195801Z"
    }
   },
   "source": [
    "data.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(866, 15)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 184
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.224301Z",
     "start_time": "2024-04-17T02:58:37.210300Z"
    }
   },
   "cell_type": "code",
   "source": "y = data['priceUSD'].shift(-1,fill_value=1)",
   "outputs": [],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.239800Z",
     "start_time": "2024-04-17T02:58:37.225303Z"
    }
   },
   "cell_type": "code",
   "source": "y.head()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11561\n",
       "1    11560\n",
       "2    11217\n",
       "3    10800\n",
       "4    11094\n",
       "Name: priceUSD, dtype: int64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.255303Z",
     "start_time": "2024-04-17T02:58:37.241300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX = []\n",
    "    datay = []\n",
    "    for i in range(len(dataset) - time_step):\n",
    "        a = dataset.iloc[i:(i + time_step), :].values  # Use .iloc for DataFrame\n",
    "        dataX.append(a)\n",
    "        datay.append(dataset.iloc[i + time_step, -1])\n",
    "    return np.array(dataX), np.array(datay)\n"
   ],
   "outputs": [],
   "execution_count": 187
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.286313Z",
     "start_time": "2024-04-17T02:58:37.256808Z"
    }
   },
   "source": " X_train, X_test, y_train, y_test =train_test_split(data,y, test_size=0.2, train_size=0.8, shuffle=False, random_state=8)",
   "outputs": [],
   "execution_count": 188
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.301812Z",
     "start_time": "2024-04-17T02:58:37.287313Z"
    }
   },
   "source": [
    "X_train.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(692, 15)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 189
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.317312Z",
     "start_time": "2024-04-17T02:58:37.302812Z"
    }
   },
   "source": [
    "estimators=[]"
   ],
   "outputs": [],
   "execution_count": 190
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.332812Z",
     "start_time": "2024-04-17T02:58:37.318813Z"
    }
   },
   "source": [
    "estimators.append(['robust',RobustScaler()])"
   ],
   "outputs": [],
   "execution_count": 191
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.348090Z",
     "start_time": "2024-04-17T02:58:37.333812Z"
    }
   },
   "source": [
    "estimators.append(['mixmax',MinMaxScaler()])"
   ],
   "outputs": [],
   "execution_count": 192
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.363597Z",
     "start_time": "2024-04-17T02:58:37.355090Z"
    }
   },
   "source": [
    "scale=Pipeline(estimators,verbose=True)"
   ],
   "outputs": [],
   "execution_count": 193
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDojXgA7mpWa",
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.410097Z",
     "start_time": "2024-04-17T02:58:37.364597Z"
    }
   },
   "source": [
    "X_train=scale.fit_transform(X_train)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing robust, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing mixmax, total=   0.0s\n"
     ]
    }
   ],
   "execution_count": 194
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.425597Z",
     "start_time": "2024-04-17T02:58:37.411098Z"
    }
   },
   "source": [
    "X_test=scale.transform(X_test)"
   ],
   "outputs": [],
   "execution_count": 195
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.441097Z",
     "start_time": "2024-04-17T02:58:37.426597Z"
    }
   },
   "source": [
    "X_train=np.reshape(X_train,(X_train.shape[0],1,X_train.shape[1]))"
   ],
   "outputs": [],
   "execution_count": 196
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.456334Z",
     "start_time": "2024-04-17T02:58:37.442101Z"
    }
   },
   "source": [
    "X_test=np.reshape(X_test,(X_test.shape[0],1,X_test.shape[1]))"
   ],
   "outputs": [],
   "execution_count": 197
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2wNcl2z_JKkM",
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.471853Z",
     "start_time": "2024-04-17T02:58:37.457339Z"
    }
   },
   "source": [
    "y_train=y_train.values"
   ],
   "outputs": [],
   "execution_count": 198
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.487467Z",
     "start_time": "2024-04-17T02:58:37.472854Z"
    }
   },
   "source": [
    "y_train=np.reshape(y_train, (y_train.shape[0],1,1))"
   ],
   "outputs": [],
   "execution_count": 199
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.502966Z",
     "start_time": "2024-04-17T02:58:37.488468Z"
    }
   },
   "source": [
    "y_test=y_test.values"
   ],
   "outputs": [],
   "execution_count": 200
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.518466Z",
     "start_time": "2024-04-17T02:58:37.503967Z"
    }
   },
   "source": [
    "y_test=np.reshape(y_test,(y_test.shape[0],1,1))"
   ],
   "outputs": [],
   "execution_count": 201
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.549470Z",
     "start_time": "2024-04-17T02:58:37.519468Z"
    }
   },
   "source": "X_train.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(692, 1, 15)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 202
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.564979Z",
     "start_time": "2024-04-17T02:58:37.550971Z"
    }
   },
   "cell_type": "code",
   "source": "X_train",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3.31408817e-14, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         1.00000000e+00, 9.93024796e-01, 8.66966742e-01]],\n",
       "\n",
       "       [[3.23876798e-14, 9.52563568e-01, 8.61345104e-03, ...,\n",
       "         9.93785828e-01, 9.91538518e-01, 9.68742186e-01]],\n",
       "\n",
       "       [[3.23876798e-14, 7.83576490e-01, 1.12098892e-02, ...,\n",
       "         9.90184980e-01, 9.94010742e-01, 9.68617154e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[2.53075824e-13, 2.60108378e-02, 7.38479840e-01, ...,\n",
       "         9.72951491e-02, 1.00183945e-01, 4.04351088e-01]],\n",
       "\n",
       "       [[1.28981646e-01, 3.26385994e-02, 7.43398522e-01, ...,\n",
       "         9.49828990e-02, 9.80501803e-02, 3.81345336e-01]],\n",
       "\n",
       "       [[1.93684164e-01, 4.46019175e-02, 7.46143017e-01, ...,\n",
       "         9.38508599e-02, 9.72113899e-02, 3.96724181e-01]]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 203
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.580479Z",
     "start_time": "2024-04-17T02:58:37.566479Z"
    }
   },
   "cell_type": "code",
   "source": "y_train.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(692, 1, 1)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 204
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.626979Z",
     "start_time": "2024-04-17T02:58:37.581979Z"
    }
   },
   "cell_type": "code",
   "source": "y_train",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[11561]],\n",
       "\n",
       "       [[11560]],\n",
       "\n",
       "       [[11217]],\n",
       "\n",
       "       [[10800]],\n",
       "\n",
       "       [[11094]],\n",
       "\n",
       "       [[11384]],\n",
       "\n",
       "       [[11085]],\n",
       "\n",
       "       [[11294]],\n",
       "\n",
       "       [[11710]],\n",
       "\n",
       "       [[11372]],\n",
       "\n",
       "       [[10781]],\n",
       "\n",
       "       [[10154]],\n",
       "\n",
       "       [[ 9755]],\n",
       "\n",
       "       [[ 8748]],\n",
       "\n",
       "       [[ 9091]],\n",
       "\n",
       "       [[ 8826]],\n",
       "\n",
       "       [[ 7704]],\n",
       "\n",
       "       [[ 6852]],\n",
       "\n",
       "       [[ 7933]],\n",
       "\n",
       "       [[ 8256]],\n",
       "\n",
       "       [[ 8300]],\n",
       "\n",
       "       [[ 8691]],\n",
       "\n",
       "       [[ 8234]],\n",
       "\n",
       "       [[ 8662]],\n",
       "\n",
       "       [[ 8657]],\n",
       "\n",
       "       [[ 9055]],\n",
       "\n",
       "       [[ 9838]],\n",
       "\n",
       "       [[10058]],\n",
       "\n",
       "       [[10713]],\n",
       "\n",
       "       [[10772]],\n",
       "\n",
       "       [[10902]],\n",
       "\n",
       "       [[11551]],\n",
       "\n",
       "       [[10851]],\n",
       "\n",
       "       [[10325]],\n",
       "\n",
       "       [[10046]],\n",
       "\n",
       "       [[ 9975]],\n",
       "\n",
       "       [[ 9649]],\n",
       "\n",
       "       [[ 9939]],\n",
       "\n",
       "       [[10575]],\n",
       "\n",
       "       [[10607]],\n",
       "\n",
       "       [[10666]],\n",
       "\n",
       "       [[11002]],\n",
       "\n",
       "       [[11365]],\n",
       "\n",
       "       [[11271]],\n",
       "\n",
       "       [[11537]],\n",
       "\n",
       "       [[11051]],\n",
       "\n",
       "       [[10428]],\n",
       "\n",
       "       [[ 9724]],\n",
       "\n",
       "       [[ 8927]],\n",
       "\n",
       "       [[ 9252]],\n",
       "\n",
       "       [[ 9065]],\n",
       "\n",
       "       [[ 9457]],\n",
       "\n",
       "       [[ 9170]],\n",
       "\n",
       "       [[ 8789]],\n",
       "\n",
       "       [[ 8124]],\n",
       "\n",
       "       [[ 8327]],\n",
       "\n",
       "       [[ 8099]],\n",
       "\n",
       "       [[ 7696]],\n",
       "\n",
       "       [[ 8360]],\n",
       "\n",
       "       [[ 8641]],\n",
       "\n",
       "       [[ 9002]],\n",
       "\n",
       "       [[ 8809]],\n",
       "\n",
       "       [[ 8549]],\n",
       "\n",
       "       [[ 8881]],\n",
       "\n",
       "       [[ 8559]],\n",
       "\n",
       "       [[ 8236]],\n",
       "\n",
       "       [[ 7983]],\n",
       "\n",
       "       [[ 7940]],\n",
       "\n",
       "       [[ 7548]],\n",
       "\n",
       "       [[ 6908]],\n",
       "\n",
       "       [[ 7025]],\n",
       "\n",
       "       [[ 6826]],\n",
       "\n",
       "       [[ 7004]],\n",
       "\n",
       "       [[ 7345]],\n",
       "\n",
       "       [[ 7107]],\n",
       "\n",
       "       [[ 6780]],\n",
       "\n",
       "       [[ 6673]],\n",
       "\n",
       "       [[ 6916]],\n",
       "\n",
       "       [[ 7020]],\n",
       "\n",
       "       [[ 6918]],\n",
       "\n",
       "       [[ 6805]],\n",
       "\n",
       "       [[ 6912]],\n",
       "\n",
       "       [[ 7355]],\n",
       "\n",
       "       [[ 8008]],\n",
       "\n",
       "       [[ 8025]],\n",
       "\n",
       "       [[ 8241]],\n",
       "\n",
       "       [[ 8104]],\n",
       "\n",
       "       [[ 8075]],\n",
       "\n",
       "       [[ 8085]],\n",
       "\n",
       "       [[ 8242]],\n",
       "\n",
       "       [[ 8464]],\n",
       "\n",
       "       [[ 8820]],\n",
       "\n",
       "       [[ 8913]],\n",
       "\n",
       "       [[ 8925]],\n",
       "\n",
       "       [[ 9325]],\n",
       "\n",
       "       [[ 9231]],\n",
       "\n",
       "       [[ 8894]],\n",
       "\n",
       "       [[ 9228]],\n",
       "\n",
       "       [[ 9249]],\n",
       "\n",
       "       [[ 9365]],\n",
       "\n",
       "       [[ 9304]],\n",
       "\n",
       "       [[ 9004]],\n",
       "\n",
       "       [[ 9128]],\n",
       "\n",
       "       [[ 9387]],\n",
       "\n",
       "       [[ 9670]],\n",
       "\n",
       "       [[ 9844]],\n",
       "\n",
       "       [[ 9658]],\n",
       "\n",
       "       [[ 9367]],\n",
       "\n",
       "       [[ 9282]],\n",
       "\n",
       "       [[ 9210]],\n",
       "\n",
       "       [[ 9288]],\n",
       "\n",
       "       [[ 8725]],\n",
       "\n",
       "       [[ 8438]],\n",
       "\n",
       "       [[ 8566]],\n",
       "\n",
       "       [[ 8595]],\n",
       "\n",
       "       [[ 8652]],\n",
       "\n",
       "       [[ 8291]],\n",
       "\n",
       "       [[ 8297]],\n",
       "\n",
       "       [[ 8115]],\n",
       "\n",
       "       [[ 8266]],\n",
       "\n",
       "       [[ 8378]],\n",
       "\n",
       "       [[ 8476]],\n",
       "\n",
       "       [[ 8261]],\n",
       "\n",
       "       [[ 7816]],\n",
       "\n",
       "       [[ 7551]],\n",
       "\n",
       "       [[ 7507]],\n",
       "\n",
       "       [[ 7517]],\n",
       "\n",
       "       [[ 7346]],\n",
       "\n",
       "       [[ 7274]],\n",
       "\n",
       "       [[ 7311]],\n",
       "\n",
       "       [[ 7454]],\n",
       "\n",
       "       [[ 7517]],\n",
       "\n",
       "       [[ 7501]],\n",
       "\n",
       "       [[ 7615]],\n",
       "\n",
       "       [[ 7706]],\n",
       "\n",
       "       [[ 7594]],\n",
       "\n",
       "       [[ 7513]],\n",
       "\n",
       "       [[ 7619]],\n",
       "\n",
       "       [[ 7708]],\n",
       "\n",
       "       [[ 7650]],\n",
       "\n",
       "       [[ 7653]],\n",
       "\n",
       "       [[ 7150]],\n",
       "\n",
       "       [[ 6767]],\n",
       "\n",
       "       [[ 6775]],\n",
       "\n",
       "       [[ 6459]],\n",
       "\n",
       "       [[ 6515]],\n",
       "\n",
       "       [[ 6567]],\n",
       "\n",
       "       [[ 6482]],\n",
       "\n",
       "       [[ 6534]],\n",
       "\n",
       "       [[ 6543]],\n",
       "\n",
       "       [[ 6737]],\n",
       "\n",
       "       [[ 6698]],\n",
       "\n",
       "       [[ 6755]],\n",
       "\n",
       "       [[ 6382]],\n",
       "\n",
       "       [[ 6146]],\n",
       "\n",
       "       [[ 6044]],\n",
       "\n",
       "       [[ 6225]],\n",
       "\n",
       "       [[ 6233]],\n",
       "\n",
       "       [[ 6128]],\n",
       "\n",
       "       [[ 6120]],\n",
       "\n",
       "       [[ 6382]],\n",
       "\n",
       "       [[ 6388]],\n",
       "\n",
       "       [[ 6479]],\n",
       "\n",
       "       [[ 6614]],\n",
       "\n",
       "       [[ 6592]],\n",
       "\n",
       "       [[ 6602]],\n",
       "\n",
       "       [[ 6569]],\n",
       "\n",
       "       [[ 6611]],\n",
       "\n",
       "       [[ 6759]],\n",
       "\n",
       "       [[ 6739]],\n",
       "\n",
       "       [[ 6516]],\n",
       "\n",
       "       [[ 6400]],\n",
       "\n",
       "       [[ 6252]],\n",
       "\n",
       "       [[ 6256]],\n",
       "\n",
       "       [[ 6253]],\n",
       "\n",
       "       [[ 6342]],\n",
       "\n",
       "       [[ 6537]],\n",
       "\n",
       "       [[ 6889]],\n",
       "\n",
       "       [[ 7413]],\n",
       "\n",
       "       [[ 7399]],\n",
       "\n",
       "       [[ 7430]],\n",
       "\n",
       "       [[ 7353]],\n",
       "\n",
       "       [[ 7455]],\n",
       "\n",
       "       [[ 7681]],\n",
       "\n",
       "       [[ 8068]],\n",
       "\n",
       "       [[ 8254]],\n",
       "\n",
       "       [[ 8199]],\n",
       "\n",
       "       [[ 8021]],\n",
       "\n",
       "       [[ 8180]],\n",
       "\n",
       "       [[ 8206]],\n",
       "\n",
       "       [[ 8142]],\n",
       "\n",
       "       [[ 7929]],\n",
       "\n",
       "       [[ 7580]],\n",
       "\n",
       "       [[ 7598]],\n",
       "\n",
       "       [[ 7403]],\n",
       "\n",
       "       [[ 7260]],\n",
       "\n",
       "       [[ 7009]],\n",
       "\n",
       "       [[ 7006]],\n",
       "\n",
       "       [[ 7000]],\n",
       "\n",
       "       [[ 6454]],\n",
       "\n",
       "       [[ 6398]],\n",
       "\n",
       "       [[ 6414]],\n",
       "\n",
       "       [[ 6195]],\n",
       "\n",
       "       [[ 6316]],\n",
       "\n",
       "       [[ 6356]],\n",
       "\n",
       "       [[ 6064]],\n",
       "\n",
       "       [[ 6377]],\n",
       "\n",
       "       [[ 6351]],\n",
       "\n",
       "       [[ 6474]],\n",
       "\n",
       "       [[ 6459]],\n",
       "\n",
       "       [[ 6412]],\n",
       "\n",
       "       [[ 6462]],\n",
       "\n",
       "       [[ 6411]],\n",
       "\n",
       "       [[ 6592]],\n",
       "\n",
       "       [[ 6445]],\n",
       "\n",
       "       [[ 6566]],\n",
       "\n",
       "       [[ 6731]],\n",
       "\n",
       "       [[ 6691]],\n",
       "\n",
       "       [[ 6733]],\n",
       "\n",
       "       [[ 6997]],\n",
       "\n",
       "       [[ 7067]],\n",
       "\n",
       "       [[ 6947]],\n",
       "\n",
       "       [[ 6994]],\n",
       "\n",
       "       [[ 7114]],\n",
       "\n",
       "       [[ 7249]],\n",
       "\n",
       "       [[ 7269]],\n",
       "\n",
       "       [[ 7332]],\n",
       "\n",
       "       [[ 7145]],\n",
       "\n",
       "       [[ 6442]],\n",
       "\n",
       "       [[ 6463]],\n",
       "\n",
       "       [[ 6380]],\n",
       "\n",
       "       [[ 6308]],\n",
       "\n",
       "       [[ 6307]],\n",
       "\n",
       "       [[ 6312]],\n",
       "\n",
       "       [[ 6287]],\n",
       "\n",
       "       [[ 6450]],\n",
       "\n",
       "       [[ 6507]],\n",
       "\n",
       "       [[ 6523]],\n",
       "\n",
       "       [[ 6491]],\n",
       "\n",
       "       [[ 6408]],\n",
       "\n",
       "       [[ 6307]],\n",
       "\n",
       "       [[ 6352]],\n",
       "\n",
       "       [[ 6423]],\n",
       "\n",
       "       [[ 6667]],\n",
       "\n",
       "       [[ 6714]],\n",
       "\n",
       "       [[ 6712]],\n",
       "\n",
       "       [[ 6645]],\n",
       "\n",
       "       [[ 6424]],\n",
       "\n",
       "       [[ 6470]],\n",
       "\n",
       "       [[ 6528]],\n",
       "\n",
       "       [[ 6683]],\n",
       "\n",
       "       [[ 6568]],\n",
       "\n",
       "       [[ 6610]],\n",
       "\n",
       "       [[ 6610]],\n",
       "\n",
       "       [[ 6579]],\n",
       "\n",
       "       [[ 6484]],\n",
       "\n",
       "       [[ 6583]],\n",
       "\n",
       "       [[ 6584]],\n",
       "\n",
       "       [[ 6598]],\n",
       "\n",
       "       [[ 6580]],\n",
       "\n",
       "       [[ 6630]],\n",
       "\n",
       "       [[ 6639]],\n",
       "\n",
       "       [[ 6581]],\n",
       "\n",
       "       [[ 6284]],\n",
       "\n",
       "       [[ 6278]],\n",
       "\n",
       "       [[ 6288]],\n",
       "\n",
       "       [[ 6335]],\n",
       "\n",
       "       [[ 6614]],\n",
       "\n",
       "       [[ 6642]],\n",
       "\n",
       "       [[ 6609]],\n",
       "\n",
       "       [[ 6595]],\n",
       "\n",
       "       [[ 6514]],\n",
       "\n",
       "       [[ 6526]],\n",
       "\n",
       "       [[ 6574]],\n",
       "\n",
       "       [[ 6537]],\n",
       "\n",
       "       [[ 6511]],\n",
       "\n",
       "       [[ 6530]],\n",
       "\n",
       "       [[ 6502]],\n",
       "\n",
       "       [[ 6493]],\n",
       "\n",
       "       [[ 6491]],\n",
       "\n",
       "       [[ 6483]],\n",
       "\n",
       "       [[ 6406]],\n",
       "\n",
       "       [[ 6331]],\n",
       "\n",
       "       [[ 6330]],\n",
       "\n",
       "       [[ 6361]],\n",
       "\n",
       "       [[ 6410]],\n",
       "\n",
       "       [[ 6385]],\n",
       "\n",
       "       [[ 6414]],\n",
       "\n",
       "       [[ 6451]],\n",
       "\n",
       "       [[ 6454]],\n",
       "\n",
       "       [[ 6547]],\n",
       "\n",
       "       [[ 6503]],\n",
       "\n",
       "       [[ 6429]],\n",
       "\n",
       "       [[ 6424]],\n",
       "\n",
       "       [[ 6411]],\n",
       "\n",
       "       [[ 6426]],\n",
       "\n",
       "       [[ 6405]],\n",
       "\n",
       "       [[ 6158]],\n",
       "\n",
       "       [[ 3850]],\n",
       "\n",
       "       [[ 3933]],\n",
       "\n",
       "       [[ 4004]],\n",
       "\n",
       "       [[ 3981]],\n",
       "\n",
       "       [[ 3900]],\n",
       "\n",
       "       [[ 3813]],\n",
       "\n",
       "       [[ 3984]],\n",
       "\n",
       "       [[ 3919]],\n",
       "\n",
       "       [[ 3829]],\n",
       "\n",
       "       [[ 3833]],\n",
       "\n",
       "       [[ 3915]],\n",
       "\n",
       "       [[ 3835]],\n",
       "\n",
       "       [[ 3865]],\n",
       "\n",
       "       [[ 3874]],\n",
       "\n",
       "       [[ 3821]],\n",
       "\n",
       "       [[ 3861]],\n",
       "\n",
       "       [[ 3925]],\n",
       "\n",
       "       [[ 3825]],\n",
       "\n",
       "       [[ 3935]],\n",
       "\n",
       "       [[ 3943]],\n",
       "\n",
       "       [[ 3942]],\n",
       "\n",
       "       [[ 3958]],\n",
       "\n",
       "       [[ 4006]],\n",
       "\n",
       "       [[ 4020]],\n",
       "\n",
       "       [[ 3822]],\n",
       "\n",
       "       [[ 3823]],\n",
       "\n",
       "       [[ 3819]],\n",
       "\n",
       "       [[ 3833]],\n",
       "\n",
       "       [[ 3837]],\n",
       "\n",
       "       [[ 3826]],\n",
       "\n",
       "       [[ 3819]],\n",
       "\n",
       "       [[ 3857]],\n",
       "\n",
       "       [[ 3884]],\n",
       "\n",
       "       [[ 3896]],\n",
       "\n",
       "       [[ 3915]],\n",
       "\n",
       "       [[ 3916]],\n",
       "\n",
       "       [[ 3889]],\n",
       "\n",
       "       [[ 3871]],\n",
       "\n",
       "       [[ 3871]],\n",
       "\n",
       "       [[ 3874]],\n",
       "\n",
       "       [[ 3904]],\n",
       "\n",
       "       [[ 4006]],\n",
       "\n",
       "       [[ 3988]],\n",
       "\n",
       "       [[ 3993]],\n",
       "\n",
       "       [[ 4003]],\n",
       "\n",
       "       [[ 4021]],\n",
       "\n",
       "       [[ 3999]],\n",
       "\n",
       "       [[ 4000]],\n",
       "\n",
       "       [[ 3989]],\n",
       "\n",
       "       [[ 3974]],\n",
       "\n",
       "       [[ 3933]],\n",
       "\n",
       "       [[ 4014]],\n",
       "\n",
       "       [[ 5265]],\n",
       "\n",
       "       [[ 5281]],\n",
       "\n",
       "       [[ 5265]],\n",
       "\n",
       "       [[ 6085]],\n",
       "\n",
       "       [[ 6318]],\n",
       "\n",
       "       [[ 6807]],\n",
       "\n",
       "       [[ 7158]],\n",
       "\n",
       "       [[ 7400]],\n",
       "\n",
       "       [[ 7988]],\n",
       "\n",
       "       [[ 8047]],\n",
       "\n",
       "       [[ 7992]],\n",
       "\n",
       "       [[ 7287]],\n",
       "\n",
       "       [[ 7328]],\n",
       "\n",
       "       [[ 7912]],\n",
       "\n",
       "       [[ 7900]],\n",
       "\n",
       "       [[ 7938]],\n",
       "\n",
       "       [[ 7884]],\n",
       "\n",
       "       [[ 7701]],\n",
       "\n",
       "       [[ 7975]],\n",
       "\n",
       "       [[ 8023]],\n",
       "\n",
       "       [[ 8103]],\n",
       "\n",
       "       [[ 8767]],\n",
       "\n",
       "       [[ 8720]],\n",
       "\n",
       "       [[ 8648]],\n",
       "\n",
       "       [[ 8636]],\n",
       "\n",
       "       [[ 8356]],\n",
       "\n",
       "       [[ 8541]],\n",
       "\n",
       "       [[ 8662]],\n",
       "\n",
       "       [[ 8537]],\n",
       "\n",
       "       [[ 7868]],\n",
       "\n",
       "       [[ 7778]],\n",
       "\n",
       "       [[ 7756]],\n",
       "\n",
       "       [[ 7934]],\n",
       "\n",
       "       [[ 7938]],\n",
       "\n",
       "       [[ 7796]],\n",
       "\n",
       "       [[ 7810]],\n",
       "\n",
       "       [[ 7884]],\n",
       "\n",
       "       [[ 8018]],\n",
       "\n",
       "       [[ 8153]],\n",
       "\n",
       "       [[ 8337]],\n",
       "\n",
       "       [[ 8713]],\n",
       "\n",
       "       [[ 9081]],\n",
       "\n",
       "       [[ 9225]],\n",
       "\n",
       "       [[ 9161]],\n",
       "\n",
       "       [[ 9150]],\n",
       "\n",
       "       [[ 9339]],\n",
       "\n",
       "       [[ 9796]],\n",
       "\n",
       "       [[10733]],\n",
       "\n",
       "       [[10780]],\n",
       "\n",
       "       [[10865]],\n",
       "\n",
       "       [[11320]],\n",
       "\n",
       "       [[11702]],\n",
       "\n",
       "       [[11569]],\n",
       "\n",
       "       [[10709]],\n",
       "\n",
       "       [[10323]],\n",
       "\n",
       "       [[11337]],\n",
       "\n",
       "       [[11752]],\n",
       "\n",
       "       [[11141]],\n",
       "\n",
       "       [[11383]],\n",
       "\n",
       "       [[11297]],\n",
       "\n",
       "       [[11763]],\n",
       "\n",
       "       [[11589]],\n",
       "\n",
       "       [[11583]],\n",
       "\n",
       "       [[11424]],\n",
       "\n",
       "       [[10868]],\n",
       "\n",
       "       [[10433]],\n",
       "\n",
       "       [[10364]],\n",
       "\n",
       "       [[ 9580]],\n",
       "\n",
       "       [[10053]],\n",
       "\n",
       "       [[10469]],\n",
       "\n",
       "       [[10672]],\n",
       "\n",
       "       [[10579]],\n",
       "\n",
       "       [[10458]],\n",
       "\n",
       "       [[10082]],\n",
       "\n",
       "       [[ 9714]],\n",
       "\n",
       "       [[10028]],\n",
       "\n",
       "       [[ 9782]],\n",
       "\n",
       "       [[ 9734]],\n",
       "\n",
       "       [[ 9499]],\n",
       "\n",
       "       [[ 9556]],\n",
       "\n",
       "       [[ 9547]],\n",
       "\n",
       "       [[ 9850]],\n",
       "\n",
       "       [[10083]],\n",
       "\n",
       "       [[10482]],\n",
       "\n",
       "       [[10790]],\n",
       "\n",
       "       [[10814]],\n",
       "\n",
       "       [[11680]],\n",
       "\n",
       "       [[11772]],\n",
       "\n",
       "       [[11726]],\n",
       "\n",
       "       [[11811]],\n",
       "\n",
       "       [[11602]],\n",
       "\n",
       "       [[11403]],\n",
       "\n",
       "       [[11404]],\n",
       "\n",
       "       [[11161]],\n",
       "\n",
       "       [[10494]],\n",
       "\n",
       "       [[10035]],\n",
       "\n",
       "       [[10245]],\n",
       "\n",
       "       [[10309]],\n",
       "\n",
       "       [[10295]],\n",
       "\n",
       "       [[10614]],\n",
       "\n",
       "       [[10758]],\n",
       "\n",
       "       [[10219]],\n",
       "\n",
       "       [[10058]],\n",
       "\n",
       "       [[10266]],\n",
       "\n",
       "       [[10156]],\n",
       "\n",
       "       [[10104]],\n",
       "\n",
       "       [[10349]],\n",
       "\n",
       "       [[10191]],\n",
       "\n",
       "       [[10085]],\n",
       "\n",
       "       [[ 9533]],\n",
       "\n",
       "       [[ 9556]],\n",
       "\n",
       "       [[ 9608]],\n",
       "\n",
       "       [[ 9636]],\n",
       "\n",
       "       [[ 9934]],\n",
       "\n",
       "       [[10517]],\n",
       "\n",
       "       [[10566]],\n",
       "\n",
       "       [[10575]],\n",
       "\n",
       "       [[10655]],\n",
       "\n",
       "       [[10426]],\n",
       "\n",
       "       [[10467]],\n",
       "\n",
       "       [[10319]],\n",
       "\n",
       "       [[10243]],\n",
       "\n",
       "       [[10082]],\n",
       "\n",
       "       [[10237]],\n",
       "\n",
       "       [[10328]],\n",
       "\n",
       "       [[10351]],\n",
       "\n",
       "       [[10334]],\n",
       "\n",
       "       [[10287]],\n",
       "\n",
       "       [[10237]],\n",
       "\n",
       "       [[10211]],\n",
       "\n",
       "       [[10007]],\n",
       "\n",
       "       [[10192]],\n",
       "\n",
       "       [[10058]],\n",
       "\n",
       "       [[10005]],\n",
       "\n",
       "       [[ 9909]],\n",
       "\n",
       "       [[ 9469]],\n",
       "\n",
       "       [[ 8465]],\n",
       "\n",
       "       [[ 8260]],\n",
       "\n",
       "       [[ 8054]],\n",
       "\n",
       "       [[ 8171]],\n",
       "\n",
       "       [[ 8092]],\n",
       "\n",
       "       [[ 8081]],\n",
       "\n",
       "       [[ 8365]],\n",
       "\n",
       "       [[ 8265]],\n",
       "\n",
       "       [[ 8255]],\n",
       "\n",
       "       [[ 8173]],\n",
       "\n",
       "       [[ 8129]],\n",
       "\n",
       "       [[ 8016]],\n",
       "\n",
       "       [[ 8068]],\n",
       "\n",
       "       [[ 8214]],\n",
       "\n",
       "       [[ 8339]],\n",
       "\n",
       "       [[ 8556]],\n",
       "\n",
       "       [[ 8404]],\n",
       "\n",
       "       [[ 8340]],\n",
       "\n",
       "       [[ 8364]],\n",
       "\n",
       "       [[ 8319]],\n",
       "\n",
       "       [[ 8274]],\n",
       "\n",
       "       [[ 8081]],\n",
       "\n",
       "       [[ 8057]],\n",
       "\n",
       "       [[ 7980]],\n",
       "\n",
       "       [[ 7979]],\n",
       "\n",
       "       [[ 8030]],\n",
       "\n",
       "       [[ 8235]],\n",
       "\n",
       "       [[ 8209]],\n",
       "\n",
       "       [[ 7748]],\n",
       "\n",
       "       [[ 7456]],\n",
       "\n",
       "       [[ 7873]],\n",
       "\n",
       "       [[ 9321]],\n",
       "\n",
       "       [[ 9407]],\n",
       "\n",
       "       [[ 9466]],\n",
       "\n",
       "       [[ 9388]],\n",
       "\n",
       "       [[ 9218]],\n",
       "\n",
       "       [[ 9196]],\n",
       "\n",
       "       [[ 9176]],\n",
       "\n",
       "       [[ 9292]],\n",
       "\n",
       "       [[ 9245]],\n",
       "\n",
       "       [[ 9285]],\n",
       "\n",
       "       [[ 9357]],\n",
       "\n",
       "       [[ 9362]],\n",
       "\n",
       "       [[ 9274]],\n",
       "\n",
       "       [[ 9015]],\n",
       "\n",
       "       [[ 8833]],\n",
       "\n",
       "       [[ 8922]],\n",
       "\n",
       "       [[ 8830]],\n",
       "\n",
       "       [[ 8776]],\n",
       "\n",
       "       [[ 8797]],\n",
       "\n",
       "       [[ 8728]],\n",
       "\n",
       "       [[ 8601]],\n",
       "\n",
       "       [[ 8524]],\n",
       "\n",
       "       [[ 8584]],\n",
       "\n",
       "       [[ 8460]],\n",
       "\n",
       "       [[ 8204]],\n",
       "\n",
       "       [[ 8176]],\n",
       "\n",
       "       [[ 7924]],\n",
       "\n",
       "       [[ 7367]],\n",
       "\n",
       "       [[ 7255]],\n",
       "\n",
       "       [[ 7209]],\n",
       "\n",
       "       [[ 6978]],\n",
       "\n",
       "       [[ 7165]],\n",
       "\n",
       "       [[ 7269]],\n",
       "\n",
       "       [[ 7555]],\n",
       "\n",
       "       [[ 7595]],\n",
       "\n",
       "       [[ 7673]],\n",
       "\n",
       "       [[ 7360]],\n",
       "\n",
       "       [[ 7315]],\n",
       "\n",
       "       [[ 7319]],\n",
       "\n",
       "       [[ 7314]],\n",
       "\n",
       "       [[ 7351]],\n",
       "\n",
       "       [[ 7436]],\n",
       "\n",
       "       [[ 7556]],\n",
       "\n",
       "       [[ 7549]],\n",
       "\n",
       "       [[ 7492]],\n",
       "\n",
       "       [[ 7340]],\n",
       "\n",
       "       [[ 7266]],\n",
       "\n",
       "       [[ 7217]],\n",
       "\n",
       "       [[ 7258]],\n",
       "\n",
       "       [[ 7204]],\n",
       "\n",
       "       [[ 7128]],\n",
       "\n",
       "       [[ 7085]],\n",
       "\n",
       "       [[ 6854]],\n",
       "\n",
       "       [[ 6799]],\n",
       "\n",
       "       [[ 7178]],\n",
       "\n",
       "       [[ 7211]],\n",
       "\n",
       "       [[ 7208]],\n",
       "\n",
       "       [[ 7276]],\n",
       "\n",
       "       [[ 7529]],\n",
       "\n",
       "       [[ 7362]],\n",
       "\n",
       "       [[ 7283]],\n",
       "\n",
       "       [[ 7278]],\n",
       "\n",
       "       [[ 7263]],\n",
       "\n",
       "       [[ 7361]],\n",
       "\n",
       "       [[ 7469]],\n",
       "\n",
       "       [[ 7388]],\n",
       "\n",
       "       [[ 7293]],\n",
       "\n",
       "       [[ 7238]],\n",
       "\n",
       "       [[ 7127]],\n",
       "\n",
       "       [[ 7250]],\n",
       "\n",
       "       [[ 7390]],\n",
       "\n",
       "       [[ 7503]],\n",
       "\n",
       "       [[ 7588]],\n",
       "\n",
       "       [[ 7953]],\n",
       "\n",
       "       [[ 8273]],\n",
       "\n",
       "       [[ 7943]],\n",
       "\n",
       "       [[ 7933]],\n",
       "\n",
       "       [[ 8120]],\n",
       "\n",
       "       [[ 8146]],\n",
       "\n",
       "       [[ 8151]],\n",
       "\n",
       "       [[ 8605]],\n",
       "\n",
       "       [[ 8778]],\n",
       "\n",
       "       [[ 8693]],\n",
       "\n",
       "       [[ 8869]],\n",
       "\n",
       "       [[ 8907]],\n",
       "\n",
       "       [[ 8859]],\n",
       "\n",
       "       [[ 8670]],\n",
       "\n",
       "       [[ 8672]],\n",
       "\n",
       "       [[ 8693]],\n",
       "\n",
       "       [[ 8469]],\n",
       "\n",
       "       [[ 8410]],\n",
       "\n",
       "       [[ 8349]],\n",
       "\n",
       "       [[ 8466]],\n",
       "\n",
       "       [[ 8744]],\n",
       "\n",
       "       [[ 9049]],\n",
       "\n",
       "       [[ 9349]],\n",
       "\n",
       "       [[ 9394]],\n",
       "\n",
       "       [[ 9366]],\n",
       "\n",
       "       [[ 9393]],\n",
       "\n",
       "       [[ 9398]],\n",
       "\n",
       "       [[ 9356]],\n",
       "\n",
       "       [[ 9233]],\n",
       "\n",
       "       [[ 9421]],\n",
       "\n",
       "       [[ 9706]],\n",
       "\n",
       "       [[ 9798]],\n",
       "\n",
       "       [[ 9823]],\n",
       "\n",
       "       [[10083]],\n",
       "\n",
       "       [[ 9932]],\n",
       "\n",
       "       [[ 9968]],\n",
       "\n",
       "       [[10331]],\n",
       "\n",
       "       [[10289]],\n",
       "\n",
       "       [[10272]],\n",
       "\n",
       "       [[10152]],\n",
       "\n",
       "       [[ 9916]],\n",
       "\n",
       "       [[ 9723]],\n",
       "\n",
       "       [[ 9840]],\n",
       "\n",
       "       [[10091]],\n",
       "\n",
       "       [[ 9612]],\n",
       "\n",
       "       [[ 9688]],\n",
       "\n",
       "       [[ 9666]],\n",
       "\n",
       "       [[ 9850]],\n",
       "\n",
       "       [[ 9755]],\n",
       "\n",
       "       [[ 9520]],\n",
       "\n",
       "       [[ 9065]],\n",
       "\n",
       "       [[ 8803]],\n",
       "\n",
       "       [[ 8706]],\n",
       "\n",
       "       [[ 8690]],\n",
       "\n",
       "       [[ 8572]],\n",
       "\n",
       "       [[ 8754]],\n",
       "\n",
       "       [[ 8791]],\n",
       "\n",
       "       [[ 8767]],\n",
       "\n",
       "       [[ 9024]],\n",
       "\n",
       "       [[ 9099]],\n",
       "\n",
       "       [[ 9050]],\n",
       "\n",
       "       [[ 8589]],\n",
       "\n",
       "       [[ 7886]],\n",
       "\n",
       "       [[ 7957]],\n",
       "\n",
       "       [[ 7856]],\n",
       "\n",
       "       [[ 6696]],\n",
       "\n",
       "       [[ 5278]],\n",
       "\n",
       "       [[ 6288]],\n",
       "\n",
       "       [[ 6167]],\n",
       "\n",
       "       [[ 6134]],\n",
       "\n",
       "       [[ 6097]],\n",
       "\n",
       "       [[ 6629]],\n",
       "\n",
       "       [[ 6658]],\n",
       "\n",
       "       [[ 6666]],\n",
       "\n",
       "       [[ 6685]],\n",
       "\n",
       "       [[ 6228]],\n",
       "\n",
       "       [[ 6124]],\n",
       "\n",
       "       [[ 6266]],\n",
       "\n",
       "       [[ 6451]],\n",
       "\n",
       "       [[ 6314]],\n",
       "\n",
       "       [[ 6722]],\n",
       "\n",
       "       [[ 6822]],\n",
       "\n",
       "       [[ 6773]],\n",
       "\n",
       "       [[ 6799]],\n",
       "\n",
       "       [[ 7082]],\n",
       "\n",
       "       [[ 7310]],\n",
       "\n",
       "       [[ 7280]],\n",
       "\n",
       "       [[ 7286]],\n",
       "\n",
       "       [[ 6980]],\n",
       "\n",
       "       [[ 6846]],\n",
       "\n",
       "       [[ 6946]],\n",
       "\n",
       "       [[ 6745]],\n",
       "\n",
       "       [[ 6874]],\n",
       "\n",
       "       [[ 6793]],\n",
       "\n",
       "       [[ 6893]],\n",
       "\n",
       "       [[ 7074]],\n",
       "\n",
       "       [[ 7129]],\n",
       "\n",
       "       [[ 7157]],\n",
       "\n",
       "       [[ 7047]],\n",
       "\n",
       "       [[ 6863]],\n",
       "\n",
       "       [[ 6986]],\n",
       "\n",
       "       [[ 7272]]], dtype=int64)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 205
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MVCJxdebqmOr"
   },
   "source": [
    "# **Model Architecture + Training**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.642484Z",
     "start_time": "2024-04-17T02:58:37.628480Z"
    }
   },
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ],
   "outputs": [],
   "execution_count": 206
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "NBZ9JgDTrHwV",
    "outputId": "40d0a5ca-682d-42d1-e08b-fd28df246868",
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:37.766172Z",
     "start_time": "2024-04-17T02:58:37.643985Z"
    }
   },
   "source": [
    "\n",
    "adam = optimizers.Adam(learning_rate=lr_schedule(0), amsgrad=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n"
     ]
    }
   ],
   "execution_count": 207
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:38.244420Z",
     "start_time": "2024-04-17T02:58:37.767175Z"
    }
   },
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(350, return_sequences=True, activation='relu'), input_shape=(1, X_train.shape[2])))\n",
    "model.add(Bidirectional(LSTM(350, return_sequences=True, activation='relu')))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss=\"log_cosh\", optimizer=adam, metrics=['mae'])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\DS440proj\\BTCpred\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "execution_count": 208
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WWSdc7AxKV6",
    "ExecuteTime": {
     "end_time": "2024-04-17T02:58:38.290712Z",
     "start_time": "2024-04-17T02:58:38.263436Z"
    }
   },
   "source": [
    "mcp_save = ModelCheckpoint('model/LSTM_reg_seven_new.keras', save_best_only=True, monitor='val_loss', mode='auto')\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=100, verbose=1, mode='auto')"
   ],
   "outputs": [],
   "execution_count": 209
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bIJPsArMr8cs",
    "outputId": "91137564-8bb8-496c-c827-829e240a789a",
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-04-17T03:04:16.635333Z",
     "start_time": "2024-04-17T02:58:38.291713Z"
    }
   },
   "source": [
    "#model.compile(optimizer='adam', loss='log_cosh', metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, epochs=5000, batch_size=32, validation_data=(X_test,y_test), callbacks=[mcp_save,earlyStopping])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 71ms/step - loss: 7868.9038 - mae: 7869.5967 - val_loss: 10004.7998 - val_mae: 10005.4932\n",
      "Epoch 2/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 7891.9722 - mae: 7892.6660 - val_loss: 9890.3057 - val_mae: 9890.9990\n",
      "Epoch 3/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 7823.0229 - mae: 7823.7163 - val_loss: 9385.9482 - val_mae: 9386.6406\n",
      "Epoch 4/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 7244.4033 - mae: 7245.0962 - val_loss: 7874.8906 - val_mae: 7875.5840\n",
      "Epoch 5/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 5890.9868 - mae: 5891.6802 - val_loss: 4314.7124 - val_mae: 4315.4058\n",
      "Epoch 6/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 3015.6438 - mae: 3016.3372 - val_loss: 1946.1733 - val_mae: 1946.8663\n",
      "Epoch 7/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 1213.9712 - mae: 1214.6643 - val_loss: 1485.0715 - val_mae: 1485.7648\n",
      "Epoch 8/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 1094.6063 - mae: 1095.2994 - val_loss: 1599.6479 - val_mae: 1600.3412\n",
      "Epoch 9/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 1023.5129 - mae: 1024.2058 - val_loss: 1276.9358 - val_mae: 1277.6289\n",
      "Epoch 10/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 953.9470 - mae: 954.6402 - val_loss: 1157.6112 - val_mae: 1158.3042\n",
      "Epoch 11/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 887.7205 - mae: 888.4134 - val_loss: 1214.0052 - val_mae: 1214.6982\n",
      "Epoch 12/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 50ms/step - loss: 869.7114 - mae: 870.4042 - val_loss: 1001.1649 - val_mae: 1001.8579\n",
      "Epoch 13/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 800.7921 - mae: 801.4839 - val_loss: 1105.3945 - val_mae: 1106.0876\n",
      "Epoch 14/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 51ms/step - loss: 759.4366 - mae: 760.1294 - val_loss: 857.6762 - val_mae: 858.3693\n",
      "Epoch 15/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 44ms/step - loss: 731.5008 - mae: 732.1938 - val_loss: 843.9480 - val_mae: 844.6412\n",
      "Epoch 16/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 762.1384 - mae: 762.8306 - val_loss: 925.0322 - val_mae: 925.7254\n",
      "Epoch 17/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 747.6493 - mae: 748.3424 - val_loss: 697.7475 - val_mae: 698.4406\n",
      "Epoch 18/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 710.7132 - mae: 711.4061 - val_loss: 893.9892 - val_mae: 894.6824\n",
      "Epoch 19/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 677.7975 - mae: 678.4905 - val_loss: 677.1876 - val_mae: 677.8779\n",
      "Epoch 20/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 676.0793 - mae: 676.7715 - val_loss: 815.0658 - val_mae: 815.7591\n",
      "Epoch 21/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 672.8017 - mae: 673.4948 - val_loss: 745.8244 - val_mae: 746.5176\n",
      "Epoch 22/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 666.1599 - mae: 666.8529 - val_loss: 636.3483 - val_mae: 637.0414\n",
      "Epoch 23/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 631.5971 - mae: 632.2900 - val_loss: 597.5414 - val_mae: 598.2345\n",
      "Epoch 24/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 629.3799 - mae: 630.0730 - val_loss: 631.4794 - val_mae: 632.1727\n",
      "Epoch 25/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 620.0852 - mae: 620.7783 - val_loss: 437.8391 - val_mae: 438.5316\n",
      "Epoch 26/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 659.5863 - mae: 660.2792 - val_loss: 599.3383 - val_mae: 600.0315\n",
      "Epoch 27/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 626.1259 - mae: 626.8179 - val_loss: 484.8485 - val_mae: 485.5401\n",
      "Epoch 28/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 627.8926 - mae: 628.5858 - val_loss: 481.6225 - val_mae: 482.3156\n",
      "Epoch 29/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 584.6555 - mae: 585.3487 - val_loss: 545.5660 - val_mae: 546.2591\n",
      "Epoch 30/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 568.0208 - mae: 568.7139 - val_loss: 572.1432 - val_mae: 572.8364\n",
      "Epoch 31/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 590.5992 - mae: 591.2885 - val_loss: 528.5335 - val_mae: 529.2243\n",
      "Epoch 32/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 551.7169 - mae: 552.4099 - val_loss: 482.8890 - val_mae: 483.5822\n",
      "Epoch 33/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 534.5090 - mae: 535.2009 - val_loss: 458.6316 - val_mae: 459.3203\n",
      "Epoch 34/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 535.7989 - mae: 536.4908 - val_loss: 427.3384 - val_mae: 428.0316\n",
      "Epoch 35/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 527.7710 - mae: 528.4642 - val_loss: 427.9843 - val_mae: 428.6775\n",
      "Epoch 36/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 489.2800 - mae: 489.9711 - val_loss: 362.9133 - val_mae: 363.6064\n",
      "Epoch 37/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 507.2231 - mae: 507.9161 - val_loss: 459.1189 - val_mae: 459.8110\n",
      "Epoch 38/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 510.1873 - mae: 510.8786 - val_loss: 420.3552 - val_mae: 421.0483\n",
      "Epoch 39/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 496.0881 - mae: 496.7810 - val_loss: 411.6888 - val_mae: 412.3815\n",
      "Epoch 40/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 457.4485 - mae: 458.1400 - val_loss: 362.8716 - val_mae: 363.5642\n",
      "Epoch 41/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 50ms/step - loss: 485.7269 - mae: 486.4200 - val_loss: 358.2989 - val_mae: 358.9885\n",
      "Epoch 42/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 470.4500 - mae: 471.1429 - val_loss: 431.8844 - val_mae: 432.5774\n",
      "Epoch 43/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 441.4386 - mae: 442.1315 - val_loss: 383.2630 - val_mae: 383.9562\n",
      "Epoch 44/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 431.9653 - mae: 432.6578 - val_loss: 354.6848 - val_mae: 355.3776\n",
      "Epoch 45/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 427.9925 - mae: 428.6855 - val_loss: 356.0311 - val_mae: 356.7243\n",
      "Epoch 46/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 426.1571 - mae: 426.8489 - val_loss: 357.8303 - val_mae: 358.5208\n",
      "Epoch 47/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 421.6059 - mae: 422.2985 - val_loss: 360.7060 - val_mae: 361.3992\n",
      "Epoch 48/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 399.1554 - mae: 399.8480 - val_loss: 346.2962 - val_mae: 346.9894\n",
      "Epoch 49/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 406.0556 - mae: 406.7487 - val_loss: 345.0571 - val_mae: 345.7489\n",
      "Epoch 50/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 395.4542 - mae: 396.1471 - val_loss: 365.7823 - val_mae: 366.4717\n",
      "Epoch 51/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 384.8193 - mae: 385.5103 - val_loss: 355.6401 - val_mae: 356.3318\n",
      "Epoch 52/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 393.2814 - mae: 393.9746 - val_loss: 350.9004 - val_mae: 351.5932\n",
      "Epoch 53/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 362.3738 - mae: 363.0641 - val_loss: 353.3477 - val_mae: 354.0408\n",
      "Epoch 54/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 359.0341 - mae: 359.7272 - val_loss: 342.3899 - val_mae: 343.0829\n",
      "Epoch 55/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 334.6977 - mae: 335.3907 - val_loss: 373.4970 - val_mae: 374.1902\n",
      "Epoch 56/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 342.0573 - mae: 342.7498 - val_loss: 392.8325 - val_mae: 393.5254\n",
      "Epoch 57/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 326.9220 - mae: 327.6148 - val_loss: 408.7575 - val_mae: 409.4488\n",
      "Epoch 58/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 338.9669 - mae: 339.6593 - val_loss: 351.0598 - val_mae: 351.7529\n",
      "Epoch 59/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 313.9830 - mae: 314.6739 - val_loss: 337.1236 - val_mae: 337.8144\n",
      "Epoch 60/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 332.4256 - mae: 333.1175 - val_loss: 366.9621 - val_mae: 367.6553\n",
      "Epoch 61/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 282.7647 - mae: 283.4573 - val_loss: 405.1633 - val_mae: 405.8565\n",
      "Epoch 62/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 287.4409 - mae: 288.1333 - val_loss: 433.5001 - val_mae: 434.1933\n",
      "Epoch 63/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 279.0586 - mae: 279.7508 - val_loss: 401.0374 - val_mae: 401.7283\n",
      "Epoch 64/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 273.1653 - mae: 273.8576 - val_loss: 390.3099 - val_mae: 391.0017\n",
      "Epoch 65/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 272.9955 - mae: 273.6873 - val_loss: 396.1439 - val_mae: 396.8357\n",
      "Epoch 66/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 276.3392 - mae: 277.0318 - val_loss: 409.6183 - val_mae: 410.3114\n",
      "Epoch 67/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 260.1323 - mae: 260.8245 - val_loss: 471.4590 - val_mae: 472.1503\n",
      "Epoch 68/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 253.6793 - mae: 254.3719 - val_loss: 413.4683 - val_mae: 414.1614\n",
      "Epoch 69/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 253.3548 - mae: 254.0477 - val_loss: 468.1525 - val_mae: 468.8456\n",
      "Epoch 70/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 243.4644 - mae: 244.1566 - val_loss: 425.3175 - val_mae: 426.0100\n",
      "Epoch 71/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 239.5442 - mae: 240.2364 - val_loss: 422.4311 - val_mae: 423.1232\n",
      "Epoch 72/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 259.3174 - mae: 260.0098 - val_loss: 409.3462 - val_mae: 410.0393\n",
      "Epoch 73/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 236.7663 - mae: 237.4585 - val_loss: 468.8337 - val_mae: 469.5247\n",
      "Epoch 74/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 258.5994 - mae: 259.2923 - val_loss: 431.3804 - val_mae: 432.0736\n",
      "Epoch 75/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 247.6570 - mae: 248.3488 - val_loss: 391.9770 - val_mae: 392.6700\n",
      "Epoch 76/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 244.1323 - mae: 244.8242 - val_loss: 457.3347 - val_mae: 458.0278\n",
      "Epoch 77/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 247.5615 - mae: 248.2535 - val_loss: 498.3335 - val_mae: 499.0260\n",
      "Epoch 78/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 254.8493 - mae: 255.5422 - val_loss: 415.1175 - val_mae: 415.8087\n",
      "Epoch 79/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 230.1853 - mae: 230.8773 - val_loss: 488.5920 - val_mae: 489.2852\n",
      "Epoch 80/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 237.8937 - mae: 238.5850 - val_loss: 412.0185 - val_mae: 412.7055\n",
      "Epoch 81/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 220.3138 - mae: 221.0054 - val_loss: 386.9172 - val_mae: 387.6104\n",
      "Epoch 82/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 241.5693 - mae: 242.2604 - val_loss: 401.8898 - val_mae: 402.5815\n",
      "Epoch 83/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 236.5859 - mae: 237.2781 - val_loss: 490.1698 - val_mae: 490.8629\n",
      "Epoch 84/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 239.7415 - mae: 240.4344 - val_loss: 435.8668 - val_mae: 436.5599\n",
      "Epoch 85/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 232.2070 - mae: 232.8982 - val_loss: 421.4017 - val_mae: 422.0947\n",
      "Epoch 86/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 240.6120 - mae: 241.3048 - val_loss: 437.6862 - val_mae: 438.3756\n",
      "Epoch 87/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 238.3150 - mae: 239.0056 - val_loss: 458.9870 - val_mae: 459.6802\n",
      "Epoch 88/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 232.7204 - mae: 233.4100 - val_loss: 413.4973 - val_mae: 414.1905\n",
      "Epoch 89/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 216.0819 - mae: 216.7737 - val_loss: 408.9894 - val_mae: 409.6826\n",
      "Epoch 90/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 230.6560 - mae: 231.3487 - val_loss: 387.4250 - val_mae: 388.1181\n",
      "Epoch 91/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 230.4961 - mae: 231.1891 - val_loss: 423.1926 - val_mae: 423.8838\n",
      "Epoch 92/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 235.4841 - mae: 236.1762 - val_loss: 431.9296 - val_mae: 432.6218\n",
      "Epoch 93/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 236.0515 - mae: 236.7444 - val_loss: 359.3700 - val_mae: 360.0630\n",
      "Epoch 94/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 228.4579 - mae: 229.1503 - val_loss: 495.6667 - val_mae: 496.3578\n",
      "Epoch 95/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 223.2236 - mae: 223.9161 - val_loss: 408.1041 - val_mae: 408.7926\n",
      "Epoch 96/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 229.2390 - mae: 229.9304 - val_loss: 429.2807 - val_mae: 429.9738\n",
      "Epoch 97/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 219.5210 - mae: 220.2136 - val_loss: 427.3591 - val_mae: 428.0519\n",
      "Epoch 98/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 208.0649 - mae: 208.7570 - val_loss: 450.7674 - val_mae: 451.4606\n",
      "Epoch 99/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 232.4951 - mae: 233.1881 - val_loss: 329.1373 - val_mae: 329.8284\n",
      "Epoch 100/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 223.5786 - mae: 224.2710 - val_loss: 446.2540 - val_mae: 446.9469\n",
      "Epoch 101/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 215.9387 - mae: 216.6302 - val_loss: 399.3166 - val_mae: 400.0092\n",
      "Epoch 102/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 212.5949 - mae: 213.2820 - val_loss: 395.7961 - val_mae: 396.4890\n",
      "Epoch 103/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 207.6164 - mae: 208.3082 - val_loss: 346.8778 - val_mae: 347.5710\n",
      "Epoch 104/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 216.2690 - mae: 216.9615 - val_loss: 481.8691 - val_mae: 482.5594\n",
      "Epoch 105/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 220.0461 - mae: 220.7388 - val_loss: 339.8644 - val_mae: 340.5571\n",
      "Epoch 106/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 225.4925 - mae: 226.1846 - val_loss: 397.8680 - val_mae: 398.5611\n",
      "Epoch 107/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 203.3939 - mae: 204.0845 - val_loss: 480.0840 - val_mae: 480.7771\n",
      "Epoch 108/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - loss: 220.3790 - mae: 221.0714 - val_loss: 311.4272 - val_mae: 312.1153\n",
      "Epoch 109/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 222.2650 - mae: 222.9580 - val_loss: 386.3292 - val_mae: 387.0211\n",
      "Epoch 110/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 221.7992 - mae: 222.4904 - val_loss: 322.7694 - val_mae: 323.4625\n",
      "Epoch 111/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 212.0569 - mae: 212.7494 - val_loss: 411.8234 - val_mae: 412.5166\n",
      "Epoch 112/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 208.9106 - mae: 209.6032 - val_loss: 374.8730 - val_mae: 375.5639\n",
      "Epoch 113/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 233.9313 - mae: 234.6238 - val_loss: 306.6126 - val_mae: 307.3058\n",
      "Epoch 114/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 26ms/step - loss: 219.4596 - mae: 220.1516 - val_loss: 345.9343 - val_mae: 346.6244\n",
      "Epoch 115/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 216.5398 - mae: 217.2324 - val_loss: 349.6263 - val_mae: 350.3145\n",
      "Epoch 116/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 219.2404 - mae: 219.9304 - val_loss: 438.2393 - val_mae: 438.9323\n",
      "Epoch 117/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 231.3837 - mae: 232.0743 - val_loss: 329.6717 - val_mae: 330.3648\n",
      "Epoch 118/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 220.6341 - mae: 221.3261 - val_loss: 372.8618 - val_mae: 373.5550\n",
      "Epoch 119/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 204.9943 - mae: 205.6863 - val_loss: 392.8557 - val_mae: 393.5467\n",
      "Epoch 120/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 208.8824 - mae: 209.5741 - val_loss: 388.5805 - val_mae: 389.2737\n",
      "Epoch 121/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 198.8618 - mae: 199.5535 - val_loss: 337.5070 - val_mae: 338.2000\n",
      "Epoch 122/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 205.9149 - mae: 206.6060 - val_loss: 292.9330 - val_mae: 293.6227\n",
      "Epoch 123/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 218.1003 - mae: 218.7893 - val_loss: 410.6999 - val_mae: 411.3930\n",
      "Epoch 124/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 202.2489 - mae: 202.9403 - val_loss: 398.1421 - val_mae: 398.8351\n",
      "Epoch 125/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 205.7600 - mae: 206.4515 - val_loss: 323.3398 - val_mae: 324.0309\n",
      "Epoch 126/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 217.3610 - mae: 218.0540 - val_loss: 425.7446 - val_mae: 426.4376\n",
      "Epoch 127/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 209.8220 - mae: 210.5128 - val_loss: 314.1763 - val_mae: 314.8666\n",
      "Epoch 128/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 208.3388 - mae: 209.0296 - val_loss: 337.5002 - val_mae: 338.1934\n",
      "Epoch 129/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 199.8561 - mae: 200.5465 - val_loss: 306.9202 - val_mae: 307.6134\n",
      "Epoch 130/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 227.5184 - mae: 228.2085 - val_loss: 359.7766 - val_mae: 360.4695\n",
      "Epoch 131/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 196.3397 - mae: 197.0276 - val_loss: 367.5410 - val_mae: 368.2319\n",
      "Epoch 132/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 204.8512 - mae: 205.5425 - val_loss: 386.8493 - val_mae: 387.5424\n",
      "Epoch 133/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 216.7718 - mae: 217.4630 - val_loss: 388.2287 - val_mae: 388.9219\n",
      "Epoch 134/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 184.5397 - mae: 185.2312 - val_loss: 378.0154 - val_mae: 378.7084\n",
      "Epoch 135/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 187.6210 - mae: 188.3132 - val_loss: 326.8943 - val_mae: 327.5859\n",
      "Epoch 136/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 214.7473 - mae: 215.4390 - val_loss: 309.7717 - val_mae: 310.4643\n",
      "Epoch 137/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 209.1236 - mae: 209.8153 - val_loss: 331.2644 - val_mae: 331.9576\n",
      "Epoch 138/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 190.4526 - mae: 191.1435 - val_loss: 307.4673 - val_mae: 308.1605\n",
      "Epoch 139/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 201.0016 - mae: 201.6927 - val_loss: 316.6422 - val_mae: 317.3353\n",
      "Epoch 140/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 211.9734 - mae: 212.6649 - val_loss: 400.1696 - val_mae: 400.8627\n",
      "Epoch 141/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 196.5204 - mae: 197.2118 - val_loss: 320.4401 - val_mae: 321.1332\n",
      "Epoch 142/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 203.7407 - mae: 204.4314 - val_loss: 332.9022 - val_mae: 333.5941\n",
      "Epoch 143/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 208.0614 - mae: 208.7541 - val_loss: 300.9240 - val_mae: 301.6171\n",
      "Epoch 144/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 206.4877 - mae: 207.1790 - val_loss: 396.2390 - val_mae: 396.9322\n",
      "Epoch 145/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 193.1013 - mae: 193.7891 - val_loss: 321.7437 - val_mae: 322.4364\n",
      "Epoch 146/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 197.3448 - mae: 198.0348 - val_loss: 333.9763 - val_mae: 334.6675\n",
      "Epoch 147/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 26ms/step - loss: 200.3347 - mae: 201.0210 - val_loss: 309.3652 - val_mae: 310.0555\n",
      "Epoch 148/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 213.2686 - mae: 213.9608 - val_loss: 264.6985 - val_mae: 265.3917\n",
      "Epoch 149/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 205.4029 - mae: 206.0942 - val_loss: 386.2693 - val_mae: 386.9619\n",
      "Epoch 150/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 187.8918 - mae: 188.5827 - val_loss: 381.3786 - val_mae: 382.0717\n",
      "Epoch 151/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 205.6857 - mae: 206.3769 - val_loss: 280.0178 - val_mae: 280.7109\n",
      "Epoch 152/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 203.9437 - mae: 204.6336 - val_loss: 329.2531 - val_mae: 329.9460\n",
      "Epoch 153/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 187.8309 - mae: 188.5197 - val_loss: 343.8297 - val_mae: 344.5224\n",
      "Epoch 154/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 207.6124 - mae: 208.3040 - val_loss: 309.2430 - val_mae: 309.9333\n",
      "Epoch 155/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 194.3706 - mae: 195.0623 - val_loss: 316.3573 - val_mae: 317.0504\n",
      "Epoch 156/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 198.1056 - mae: 198.7973 - val_loss: 289.9283 - val_mae: 290.6215\n",
      "Epoch 157/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 38ms/step - loss: 209.4359 - mae: 210.1263 - val_loss: 260.4159 - val_mae: 261.1090\n",
      "Epoch 158/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 215.3064 - mae: 215.9991 - val_loss: 344.8078 - val_mae: 345.4983\n",
      "Epoch 159/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 197.5349 - mae: 198.2272 - val_loss: 287.1541 - val_mae: 287.8465\n",
      "Epoch 160/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 206.7609 - mae: 207.4523 - val_loss: 306.5098 - val_mae: 307.2029\n",
      "Epoch 161/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 214.1077 - mae: 214.8004 - val_loss: 345.1790 - val_mae: 345.8718\n",
      "Epoch 162/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 208.7922 - mae: 209.4844 - val_loss: 283.6486 - val_mae: 284.3418\n",
      "Epoch 163/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 195.7775 - mae: 196.4704 - val_loss: 305.8474 - val_mae: 306.5406\n",
      "Epoch 164/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 198.4170 - mae: 199.1058 - val_loss: 287.7247 - val_mae: 288.4147\n",
      "Epoch 165/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 196.1032 - mae: 196.7945 - val_loss: 325.4326 - val_mae: 326.1207\n",
      "Epoch 166/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 183.8150 - mae: 184.5062 - val_loss: 306.2807 - val_mae: 306.9722\n",
      "Epoch 167/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 199.9875 - mae: 200.6770 - val_loss: 268.2058 - val_mae: 268.8989\n",
      "Epoch 168/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 194.9016 - mae: 195.5914 - val_loss: 372.7910 - val_mae: 373.4841\n",
      "Epoch 169/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 206.1678 - mae: 206.8575 - val_loss: 315.5120 - val_mae: 316.2050\n",
      "Epoch 170/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 197.4729 - mae: 198.1653 - val_loss: 257.8613 - val_mae: 258.5540\n",
      "Epoch 171/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 196.1252 - mae: 196.8178 - val_loss: 298.6240 - val_mae: 299.3169\n",
      "Epoch 172/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 194.9638 - mae: 195.6559 - val_loss: 384.9539 - val_mae: 385.6465\n",
      "Epoch 173/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 219.3173 - mae: 220.0096 - val_loss: 267.0656 - val_mae: 267.7581\n",
      "Epoch 174/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 202.9331 - mae: 203.6210 - val_loss: 317.5062 - val_mae: 318.1992\n",
      "Epoch 175/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 200.3194 - mae: 201.0115 - val_loss: 260.3567 - val_mae: 261.0496\n",
      "Epoch 176/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 199.6334 - mae: 200.3244 - val_loss: 307.0715 - val_mae: 307.7607\n",
      "Epoch 177/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 208.3105 - mae: 209.0008 - val_loss: 269.6231 - val_mae: 270.3153\n",
      "Epoch 178/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 190.0615 - mae: 190.7527 - val_loss: 286.4645 - val_mae: 287.1577\n",
      "Epoch 179/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 184.9683 - mae: 185.6609 - val_loss: 276.6495 - val_mae: 277.3398\n",
      "Epoch 180/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 191.6292 - mae: 192.3214 - val_loss: 307.8747 - val_mae: 308.5653\n",
      "Epoch 181/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 191.9204 - mae: 192.6115 - val_loss: 305.7584 - val_mae: 306.4512\n",
      "Epoch 182/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 195.7168 - mae: 196.4062 - val_loss: 272.9184 - val_mae: 273.6116\n",
      "Epoch 183/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 197.8670 - mae: 198.5566 - val_loss: 308.3369 - val_mae: 309.0280\n",
      "Epoch 184/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 42ms/step - loss: 194.0590 - mae: 194.7509 - val_loss: 243.9558 - val_mae: 244.6454\n",
      "Epoch 185/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 26ms/step - loss: 187.4468 - mae: 188.1379 - val_loss: 289.2761 - val_mae: 289.9692\n",
      "Epoch 186/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 26ms/step - loss: 192.8959 - mae: 193.5869 - val_loss: 305.4348 - val_mae: 306.1245\n",
      "Epoch 187/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 190.1493 - mae: 190.8400 - val_loss: 259.5834 - val_mae: 260.2727\n",
      "Epoch 188/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 206.0283 - mae: 206.7193 - val_loss: 314.8525 - val_mae: 315.5455\n",
      "Epoch 189/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 192.8808 - mae: 193.5665 - val_loss: 365.5366 - val_mae: 366.2281\n",
      "Epoch 190/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 204.6915 - mae: 205.3818 - val_loss: 284.0105 - val_mae: 284.7035\n",
      "Epoch 191/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 188.2267 - mae: 188.9188 - val_loss: 304.2302 - val_mae: 304.9230\n",
      "Epoch 192/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 187.7201 - mae: 188.4125 - val_loss: 310.9336 - val_mae: 311.6234\n",
      "Epoch 193/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 203.9886 - mae: 204.6792 - val_loss: 247.1421 - val_mae: 247.8344\n",
      "Epoch 194/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 197.8636 - mae: 198.5565 - val_loss: 387.8683 - val_mae: 388.5597\n",
      "Epoch 195/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 193.0609 - mae: 193.7531 - val_loss: 254.1602 - val_mae: 254.8533\n",
      "Epoch 196/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 189.7799 - mae: 190.4712 - val_loss: 260.2221 - val_mae: 260.9142\n",
      "Epoch 197/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 205.3837 - mae: 206.0748 - val_loss: 294.9880 - val_mae: 295.6810\n",
      "Epoch 198/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 194.9362 - mae: 195.6293 - val_loss: 268.8996 - val_mae: 269.5920\n",
      "Epoch 199/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 186.2019 - mae: 186.8932 - val_loss: 283.9421 - val_mae: 284.6352\n",
      "Epoch 200/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 198.7709 - mae: 199.4618 - val_loss: 321.1596 - val_mae: 321.8528\n",
      "Epoch 201/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 187.0687 - mae: 187.7602 - val_loss: 247.2429 - val_mae: 247.9339\n",
      "Epoch 202/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 196.2523 - mae: 196.9401 - val_loss: 297.5247 - val_mae: 298.2155\n",
      "Epoch 203/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 196.0943 - mae: 196.7867 - val_loss: 279.2166 - val_mae: 279.9083\n",
      "Epoch 204/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 183.1368 - mae: 183.8251 - val_loss: 293.8707 - val_mae: 294.5638\n",
      "Epoch 205/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 186.1045 - mae: 186.7943 - val_loss: 254.2389 - val_mae: 254.9312\n",
      "Epoch 206/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 189.0880 - mae: 189.7797 - val_loss: 271.9316 - val_mae: 272.6216\n",
      "Epoch 207/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 191.0640 - mae: 191.7557 - val_loss: 270.6678 - val_mae: 271.3608\n",
      "Epoch 208/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 191.8951 - mae: 192.5850 - val_loss: 288.8084 - val_mae: 289.5015\n",
      "Epoch 209/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 198.5615 - mae: 199.2519 - val_loss: 284.7696 - val_mae: 285.4627\n",
      "Epoch 210/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 195.6050 - mae: 196.2979 - val_loss: 261.9965 - val_mae: 262.6888\n",
      "Epoch 211/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 195.2262 - mae: 195.9178 - val_loss: 320.6250 - val_mae: 321.3181\n",
      "Epoch 212/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 199.9311 - mae: 200.6240 - val_loss: 291.1978 - val_mae: 291.8892\n",
      "Epoch 213/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 200.3965 - mae: 201.0868 - val_loss: 275.3828 - val_mae: 276.0759\n",
      "Epoch 214/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 190.2292 - mae: 190.9215 - val_loss: 241.8609 - val_mae: 242.5520\n",
      "Epoch 215/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 192.0234 - mae: 192.7145 - val_loss: 281.4318 - val_mae: 282.1223\n",
      "Epoch 216/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 191.5939 - mae: 192.2870 - val_loss: 291.6294 - val_mae: 292.3208\n",
      "Epoch 217/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 190.9378 - mae: 191.6295 - val_loss: 259.3400 - val_mae: 260.0332\n",
      "Epoch 218/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 187.3289 - mae: 188.0175 - val_loss: 255.4689 - val_mae: 256.1589\n",
      "Epoch 219/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 192.3580 - mae: 193.0470 - val_loss: 264.2200 - val_mae: 264.9131\n",
      "Epoch 220/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 186.3567 - mae: 187.0490 - val_loss: 238.7009 - val_mae: 239.3925\n",
      "Epoch 221/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 27ms/step - loss: 194.7245 - mae: 195.4172 - val_loss: 239.1943 - val_mae: 239.8836\n",
      "Epoch 222/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 187.0848 - mae: 187.7742 - val_loss: 296.1525 - val_mae: 296.8446\n",
      "Epoch 223/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 204.4291 - mae: 205.1186 - val_loss: 290.7531 - val_mae: 291.4431\n",
      "Epoch 224/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 184.9974 - mae: 185.6867 - val_loss: 244.0703 - val_mae: 244.7616\n",
      "Epoch 225/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 190.5387 - mae: 191.2311 - val_loss: 246.6380 - val_mae: 247.3311\n",
      "Epoch 226/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 209.1890 - mae: 209.8801 - val_loss: 308.7356 - val_mae: 309.4288\n",
      "Epoch 227/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 191.4354 - mae: 192.1267 - val_loss: 257.2040 - val_mae: 257.8951\n",
      "Epoch 228/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 197.6184 - mae: 198.3076 - val_loss: 325.4426 - val_mae: 326.1358\n",
      "Epoch 229/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 196.9191 - mae: 197.6098 - val_loss: 251.2266 - val_mae: 251.9196\n",
      "Epoch 230/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 190.0162 - mae: 190.7076 - val_loss: 274.2517 - val_mae: 274.9420\n",
      "Epoch 231/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 198.5726 - mae: 199.2640 - val_loss: 246.0070 - val_mae: 246.6982\n",
      "Epoch 232/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 183.9439 - mae: 184.6364 - val_loss: 282.5242 - val_mae: 283.2153\n",
      "Epoch 233/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 189.5478 - mae: 190.2390 - val_loss: 306.5135 - val_mae: 307.2067\n",
      "Epoch 234/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 195.7371 - mae: 196.4282 - val_loss: 263.9246 - val_mae: 264.6161\n",
      "Epoch 235/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 191.2998 - mae: 191.9913 - val_loss: 234.9610 - val_mae: 235.6538\n",
      "Epoch 236/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 207.9199 - mae: 208.6118 - val_loss: 304.9827 - val_mae: 305.6758\n",
      "Epoch 237/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 188.6721 - mae: 189.3636 - val_loss: 293.7461 - val_mae: 294.4385\n",
      "Epoch 238/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 188.9901 - mae: 189.6805 - val_loss: 262.0146 - val_mae: 262.7072\n",
      "Epoch 239/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 183.6696 - mae: 184.3607 - val_loss: 233.6809 - val_mae: 234.3701\n",
      "Epoch 240/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 197.5296 - mae: 198.2200 - val_loss: 248.5448 - val_mae: 249.2379\n",
      "Epoch 241/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 187.9258 - mae: 188.6181 - val_loss: 253.8606 - val_mae: 254.5537\n",
      "Epoch 242/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 183.0073 - mae: 183.6964 - val_loss: 295.6476 - val_mae: 296.3379\n",
      "Epoch 243/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 197.9983 - mae: 198.6893 - val_loss: 253.4091 - val_mae: 254.1022\n",
      "Epoch 244/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 193.6789 - mae: 194.3702 - val_loss: 245.7685 - val_mae: 246.4580\n",
      "Epoch 245/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 189.6799 - mae: 190.3722 - val_loss: 256.1313 - val_mae: 256.8230\n",
      "Epoch 246/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 186.6381 - mae: 187.3282 - val_loss: 274.4424 - val_mae: 275.1356\n",
      "Epoch 247/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 190.4267 - mae: 191.1168 - val_loss: 268.1254 - val_mae: 268.8180\n",
      "Epoch 248/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 38ms/step - loss: 197.2100 - mae: 197.9008 - val_loss: 232.7142 - val_mae: 233.4047\n",
      "Epoch 249/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 26ms/step - loss: 222.5193 - mae: 223.2059 - val_loss: 316.1601 - val_mae: 316.8527\n",
      "Epoch 250/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 183.0573 - mae: 183.7499 - val_loss: 278.7948 - val_mae: 279.4843\n",
      "Epoch 251/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 191.9007 - mae: 192.5930 - val_loss: 297.9670 - val_mae: 298.6596\n",
      "Epoch 252/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 195.9012 - mae: 196.5927 - val_loss: 250.7109 - val_mae: 251.3970\n",
      "Epoch 253/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 186.8462 - mae: 187.5361 - val_loss: 255.3900 - val_mae: 256.0832\n",
      "Epoch 254/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 189.0562 - mae: 189.7477 - val_loss: 232.4608 - val_mae: 233.1524\n",
      "Epoch 255/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 189.9269 - mae: 190.6184 - val_loss: 276.7239 - val_mae: 277.4168\n",
      "Epoch 256/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 191.5068 - mae: 192.1988 - val_loss: 265.2940 - val_mae: 265.9849\n",
      "Epoch 257/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 184.2177 - mae: 184.9089 - val_loss: 233.7751 - val_mae: 234.4640\n",
      "Epoch 258/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 194.1800 - mae: 194.8714 - val_loss: 260.2881 - val_mae: 260.9771\n",
      "Epoch 259/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 185.1994 - mae: 185.8916 - val_loss: 255.0488 - val_mae: 255.7380\n",
      "Epoch 260/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 196.8772 - mae: 197.5690 - val_loss: 226.8506 - val_mae: 227.5427\n",
      "Epoch 261/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 191.8949 - mae: 192.5858 - val_loss: 299.9592 - val_mae: 300.6523\n",
      "Epoch 262/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 187.9035 - mae: 188.5939 - val_loss: 239.0811 - val_mae: 239.7742\n",
      "Epoch 263/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 190.7097 - mae: 191.4020 - val_loss: 248.4354 - val_mae: 249.1285\n",
      "Epoch 264/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 193.6755 - mae: 194.3664 - val_loss: 238.0901 - val_mae: 238.7827\n",
      "Epoch 265/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 190.7092 - mae: 191.4012 - val_loss: 263.8911 - val_mae: 264.5817\n",
      "Epoch 266/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 186.7824 - mae: 187.4752 - val_loss: 261.4402 - val_mae: 262.1334\n",
      "Epoch 267/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 192.3130 - mae: 193.0046 - val_loss: 315.4494 - val_mae: 316.1391\n",
      "Epoch 268/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 191.7586 - mae: 192.4485 - val_loss: 241.1491 - val_mae: 241.8420\n",
      "Epoch 269/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 181.8424 - mae: 182.5324 - val_loss: 289.2530 - val_mae: 289.9431\n",
      "Epoch 270/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 176.9165 - mae: 177.6080 - val_loss: 241.8248 - val_mae: 242.5155\n",
      "Epoch 271/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 183.2290 - mae: 183.9194 - val_loss: 232.0742 - val_mae: 232.7673\n",
      "Epoch 272/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 201.7500 - mae: 202.4422 - val_loss: 254.0049 - val_mae: 254.6981\n",
      "Epoch 273/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 181.8769 - mae: 182.5689 - val_loss: 241.0195 - val_mae: 241.7111\n",
      "Epoch 274/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 186.7465 - mae: 187.4371 - val_loss: 251.1449 - val_mae: 251.8315\n",
      "Epoch 275/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 204.6890 - mae: 205.3805 - val_loss: 259.8625 - val_mae: 260.5546\n",
      "Epoch 276/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 179.0670 - mae: 179.7549 - val_loss: 287.4059 - val_mae: 288.0989\n",
      "Epoch 277/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 197.3726 - mae: 198.0646 - val_loss: 278.4352 - val_mae: 279.1284\n",
      "Epoch 278/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 185.8322 - mae: 186.5211 - val_loss: 268.3865 - val_mae: 269.0794\n",
      "Epoch 279/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 174.2150 - mae: 174.9031 - val_loss: 236.3534 - val_mae: 237.0465\n",
      "Epoch 280/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 180.5667 - mae: 181.2529 - val_loss: 249.9710 - val_mae: 250.6641\n",
      "Epoch 281/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 194.9411 - mae: 195.6277 - val_loss: 242.8499 - val_mae: 243.5419\n",
      "Epoch 282/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 190.5773 - mae: 191.2687 - val_loss: 280.4903 - val_mae: 281.1823\n",
      "Epoch 283/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.2481 - mae: 178.9368 - val_loss: 263.8019 - val_mae: 264.4888\n",
      "Epoch 284/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 196.2622 - mae: 196.9543 - val_loss: 252.4587 - val_mae: 253.1518\n",
      "Epoch 285/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 187.9944 - mae: 188.6839 - val_loss: 247.7684 - val_mae: 248.4616\n",
      "Epoch 286/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 191.4815 - mae: 192.1706 - val_loss: 231.3369 - val_mae: 232.0300\n",
      "Epoch 287/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 195.6034 - mae: 196.2943 - val_loss: 286.2358 - val_mae: 286.9279\n",
      "Epoch 288/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 202.6309 - mae: 203.3225 - val_loss: 270.0612 - val_mae: 270.7540\n",
      "Epoch 289/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 191.2486 - mae: 191.9360 - val_loss: 232.7264 - val_mae: 233.4195\n",
      "Epoch 290/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 184.3481 - mae: 185.0392 - val_loss: 280.2901 - val_mae: 280.9812\n",
      "Epoch 291/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 187.4235 - mae: 188.1154 - val_loss: 249.3178 - val_mae: 250.0109\n",
      "Epoch 292/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 175.6855 - mae: 176.3756 - val_loss: 243.6066 - val_mae: 244.2976\n",
      "Epoch 293/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 188.2335 - mae: 188.9229 - val_loss: 253.1077 - val_mae: 253.8000\n",
      "Epoch 294/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 191.7868 - mae: 192.4765 - val_loss: 232.3426 - val_mae: 233.0356\n",
      "Epoch 295/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 194.0775 - mae: 194.7657 - val_loss: 243.7055 - val_mae: 244.3979\n",
      "Epoch 296/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 192.3648 - mae: 193.0537 - val_loss: 236.6827 - val_mae: 237.3718\n",
      "Epoch 297/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 174.0582 - mae: 174.7502 - val_loss: 245.2238 - val_mae: 245.9170\n",
      "Epoch 298/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 193.4470 - mae: 194.1375 - val_loss: 265.5302 - val_mae: 266.2228\n",
      "Epoch 299/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 173.7686 - mae: 174.4603 - val_loss: 241.0506 - val_mae: 241.7436\n",
      "Epoch 300/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 187.9231 - mae: 188.6148 - val_loss: 243.6827 - val_mae: 244.3759\n",
      "Epoch 301/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 180.2055 - mae: 180.8932 - val_loss: 254.4375 - val_mae: 255.1307\n",
      "Epoch 302/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 183.3786 - mae: 184.0702 - val_loss: 222.2287 - val_mae: 222.9219\n",
      "Epoch 303/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 194.1902 - mae: 194.8824 - val_loss: 291.5067 - val_mae: 292.1999\n",
      "Epoch 304/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 190.0554 - mae: 190.7462 - val_loss: 259.1083 - val_mae: 259.7979\n",
      "Epoch 305/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 175.4986 - mae: 176.1903 - val_loss: 242.9263 - val_mae: 243.6182\n",
      "Epoch 306/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 187.2511 - mae: 187.9396 - val_loss: 226.8439 - val_mae: 227.5341\n",
      "Epoch 307/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 187.1079 - mae: 187.7946 - val_loss: 229.1242 - val_mae: 229.8135\n",
      "Epoch 308/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 203.6063 - mae: 204.2966 - val_loss: 261.7772 - val_mae: 262.4674\n",
      "Epoch 309/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 188.7861 - mae: 189.4773 - val_loss: 276.6040 - val_mae: 277.2946\n",
      "Epoch 310/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 187.9780 - mae: 188.6656 - val_loss: 243.6814 - val_mae: 244.3720\n",
      "Epoch 311/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 176.3186 - mae: 177.0108 - val_loss: 249.9247 - val_mae: 250.6179\n",
      "Epoch 312/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 179.9289 - mae: 180.6183 - val_loss: 236.5926 - val_mae: 237.2857\n",
      "Epoch 313/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 193.1951 - mae: 193.8868 - val_loss: 242.4451 - val_mae: 243.1383\n",
      "Epoch 314/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 181.5319 - mae: 182.2218 - val_loss: 239.7233 - val_mae: 240.4125\n",
      "Epoch 315/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 179.9030 - mae: 180.5933 - val_loss: 229.7955 - val_mae: 230.4852\n",
      "Epoch 316/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 198.6712 - mae: 199.3626 - val_loss: 237.3615 - val_mae: 238.0547\n",
      "Epoch 317/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 202.2090 - mae: 202.8991 - val_loss: 230.8444 - val_mae: 231.5375\n",
      "Epoch 318/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 202.3584 - mae: 203.0511 - val_loss: 231.1203 - val_mae: 231.8134\n",
      "Epoch 319/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 187.8210 - mae: 188.5123 - val_loss: 231.6864 - val_mae: 232.3770\n",
      "Epoch 320/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 193.4472 - mae: 194.1389 - val_loss: 223.5559 - val_mae: 224.2462\n",
      "Epoch 321/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 185.7171 - mae: 186.4094 - val_loss: 265.8744 - val_mae: 266.5635\n",
      "Epoch 322/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 178.1433 - mae: 178.8328 - val_loss: 233.8876 - val_mae: 234.5795\n",
      "Epoch 323/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 183.1962 - mae: 183.8868 - val_loss: 220.6280 - val_mae: 221.3157\n",
      "Epoch 324/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 179.8256 - mae: 180.5173 - val_loss: 261.4686 - val_mae: 262.1609\n",
      "Epoch 325/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 198.1398 - mae: 198.8306 - val_loss: 276.0886 - val_mae: 276.7817\n",
      "Epoch 326/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 201.7137 - mae: 202.4056 - val_loss: 228.7055 - val_mae: 229.3964\n",
      "Epoch 327/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 190.5471 - mae: 191.2379 - val_loss: 250.0995 - val_mae: 250.7927\n",
      "Epoch 328/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 190.0779 - mae: 190.7686 - val_loss: 258.6573 - val_mae: 259.3499\n",
      "Epoch 329/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 188.0658 - mae: 188.7577 - val_loss: 266.7661 - val_mae: 267.4586\n",
      "Epoch 330/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 192.2516 - mae: 192.9436 - val_loss: 221.8604 - val_mae: 222.5518\n",
      "Epoch 331/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 187.0251 - mae: 187.7160 - val_loss: 241.4745 - val_mae: 242.1666\n",
      "Epoch 332/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 185.7067 - mae: 186.3984 - val_loss: 227.3129 - val_mae: 228.0000\n",
      "Epoch 333/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 197.2105 - mae: 197.9032 - val_loss: 273.2816 - val_mae: 273.9709\n",
      "Epoch 334/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 196.6148 - mae: 197.3041 - val_loss: 228.0522 - val_mae: 228.7452\n",
      "Epoch 335/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 196.4045 - mae: 197.0971 - val_loss: 227.6686 - val_mae: 228.3579\n",
      "Epoch 336/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 183.2103 - mae: 183.9007 - val_loss: 244.3754 - val_mae: 245.0685\n",
      "Epoch 337/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 186.8180 - mae: 187.5096 - val_loss: 257.2444 - val_mae: 257.9367\n",
      "Epoch 338/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 178.7501 - mae: 179.4405 - val_loss: 228.5095 - val_mae: 229.1999\n",
      "Epoch 339/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 193.8262 - mae: 194.5181 - val_loss: 220.7995 - val_mae: 221.4920\n",
      "Epoch 340/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 188.1200 - mae: 188.8115 - val_loss: 221.1232 - val_mae: 221.8144\n",
      "Epoch 341/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 192.7545 - mae: 193.4475 - val_loss: 272.3424 - val_mae: 273.0354\n",
      "Epoch 342/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 190.0719 - mae: 190.7627 - val_loss: 236.2236 - val_mae: 236.9135\n",
      "Epoch 343/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 179.5883 - mae: 180.2795 - val_loss: 247.8596 - val_mae: 248.5515\n",
      "Epoch 344/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 187.0354 - mae: 187.7256 - val_loss: 295.4291 - val_mae: 296.1217\n",
      "Epoch 345/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 182.3353 - mae: 183.0240 - val_loss: 238.4258 - val_mae: 239.1189\n",
      "Epoch 346/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 182.3271 - mae: 183.0192 - val_loss: 243.5814 - val_mae: 244.2744\n",
      "Epoch 347/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 192.1887 - mae: 192.8793 - val_loss: 237.3432 - val_mae: 238.0332\n",
      "Epoch 348/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 193.2118 - mae: 193.9028 - val_loss: 238.8511 - val_mae: 239.5441\n",
      "Epoch 349/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 176.8273 - mae: 177.5192 - val_loss: 252.5525 - val_mae: 253.2419\n",
      "Epoch 350/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 183.8869 - mae: 184.5781 - val_loss: 241.8340 - val_mae: 242.5271\n",
      "Epoch 351/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 173.7580 - mae: 174.4506 - val_loss: 228.2493 - val_mae: 228.9419\n",
      "Epoch 352/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 184.1251 - mae: 184.8140 - val_loss: 226.3003 - val_mae: 226.9934\n",
      "Epoch 353/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 179.7940 - mae: 180.4844 - val_loss: 252.2638 - val_mae: 252.9543\n",
      "Epoch 354/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 196.7430 - mae: 197.4347 - val_loss: 248.6075 - val_mae: 249.3000\n",
      "Epoch 355/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 180.9725 - mae: 181.6641 - val_loss: 279.1935 - val_mae: 279.8864\n",
      "Epoch 356/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 196.2979 - mae: 196.9882 - val_loss: 238.0423 - val_mae: 238.7341\n",
      "Epoch 357/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 173.2499 - mae: 173.9397 - val_loss: 228.8405 - val_mae: 229.5336\n",
      "Epoch 358/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 200.5042 - mae: 201.1968 - val_loss: 221.9826 - val_mae: 222.6755\n",
      "Epoch 359/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 196.9012 - mae: 197.5896 - val_loss: 244.4359 - val_mae: 245.1257\n",
      "Epoch 360/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 183.5454 - mae: 184.2375 - val_loss: 249.5965 - val_mae: 250.2896\n",
      "Epoch 361/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 187.7081 - mae: 188.3992 - val_loss: 272.2503 - val_mae: 272.9435\n",
      "Epoch 362/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 199.4814 - mae: 200.1732 - val_loss: 270.6936 - val_mae: 271.3867\n",
      "Epoch 363/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 183.4252 - mae: 184.1166 - val_loss: 223.4065 - val_mae: 224.0996\n",
      "Epoch 364/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 199.3518 - mae: 200.0424 - val_loss: 227.7565 - val_mae: 228.4495\n",
      "Epoch 365/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 182.2910 - mae: 182.9806 - val_loss: 233.4207 - val_mae: 234.1138\n",
      "Epoch 366/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 174.1922 - mae: 174.8817 - val_loss: 243.8825 - val_mae: 244.5724\n",
      "Epoch 367/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 181.9196 - mae: 182.6086 - val_loss: 240.8530 - val_mae: 241.5459\n",
      "Epoch 368/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 178.2476 - mae: 178.9379 - val_loss: 217.0879 - val_mae: 217.7790\n",
      "Epoch 369/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 191.0048 - mae: 191.6928 - val_loss: 245.4895 - val_mae: 246.1791\n",
      "Epoch 370/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 182.0384 - mae: 182.7302 - val_loss: 225.8880 - val_mae: 226.5786\n",
      "Epoch 371/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 191.5150 - mae: 192.2044 - val_loss: 238.9039 - val_mae: 239.5970\n",
      "Epoch 372/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 181.4762 - mae: 182.1689 - val_loss: 244.6739 - val_mae: 245.3620\n",
      "Epoch 373/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 187.8016 - mae: 188.4930 - val_loss: 222.6321 - val_mae: 223.3253\n",
      "Epoch 374/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 184.1036 - mae: 184.7958 - val_loss: 240.3895 - val_mae: 241.0810\n",
      "Epoch 375/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 185.5109 - mae: 186.2011 - val_loss: 221.8182 - val_mae: 222.5065\n",
      "Epoch 376/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 185.3916 - mae: 186.0814 - val_loss: 226.3108 - val_mae: 226.9990\n",
      "Epoch 377/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 178.0454 - mae: 178.7383 - val_loss: 248.2117 - val_mae: 248.9047\n",
      "Epoch 378/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 202.8442 - mae: 203.5362 - val_loss: 231.1294 - val_mae: 231.8212\n",
      "Epoch 379/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 174.9111 - mae: 175.6022 - val_loss: 282.8093 - val_mae: 283.5022\n",
      "Epoch 380/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 197.0493 - mae: 197.7403 - val_loss: 239.9583 - val_mae: 240.6514\n",
      "Epoch 381/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 169.7325 - mae: 170.4229 - val_loss: 232.1505 - val_mae: 232.8421\n",
      "Epoch 382/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 179.8156 - mae: 180.5062 - val_loss: 240.3597 - val_mae: 241.0510\n",
      "Epoch 383/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 180.8179 - mae: 181.5077 - val_loss: 263.5772 - val_mae: 264.2703\n",
      "Epoch 384/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 175.8003 - mae: 176.4884 - val_loss: 275.5573 - val_mae: 276.2505\n",
      "Epoch 385/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 188.2684 - mae: 188.9606 - val_loss: 255.2831 - val_mae: 255.9743\n",
      "Epoch 386/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 188.2155 - mae: 188.9052 - val_loss: 237.2024 - val_mae: 237.8924\n",
      "Epoch 387/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 184.7088 - mae: 185.4003 - val_loss: 262.9738 - val_mae: 263.6659\n",
      "Epoch 388/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 185.4127 - mae: 186.1018 - val_loss: 216.9877 - val_mae: 217.6790\n",
      "Epoch 389/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 189.0732 - mae: 189.7657 - val_loss: 303.7471 - val_mae: 304.4378\n",
      "Epoch 390/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 184.4892 - mae: 185.1770 - val_loss: 217.5613 - val_mae: 218.2531\n",
      "Epoch 391/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 186.5705 - mae: 187.2574 - val_loss: 221.5645 - val_mae: 222.2557\n",
      "Epoch 392/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 187.1915 - mae: 187.8830 - val_loss: 254.0076 - val_mae: 254.6957\n",
      "Epoch 393/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 194.5264 - mae: 195.2183 - val_loss: 258.7514 - val_mae: 259.4445\n",
      "Epoch 394/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 182.2540 - mae: 182.9461 - val_loss: 244.7586 - val_mae: 245.4514\n",
      "Epoch 395/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 191.1036 - mae: 191.7960 - val_loss: 218.6241 - val_mae: 219.3146\n",
      "Epoch 396/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 173.2361 - mae: 173.9286 - val_loss: 241.1877 - val_mae: 241.8771\n",
      "Epoch 397/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 206.4871 - mae: 207.1742 - val_loss: 215.4570 - val_mae: 216.1455\n",
      "Epoch 398/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 185.7920 - mae: 186.4827 - val_loss: 254.7260 - val_mae: 255.4158\n",
      "Epoch 399/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 183.2995 - mae: 183.9921 - val_loss: 236.4846 - val_mae: 237.1728\n",
      "Epoch 400/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 188.6962 - mae: 189.3860 - val_loss: 222.8475 - val_mae: 223.5396\n",
      "Epoch 401/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 180.3185 - mae: 181.0107 - val_loss: 217.2163 - val_mae: 217.9038\n",
      "Epoch 402/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 195.6483 - mae: 196.3392 - val_loss: 216.4110 - val_mae: 217.1034\n",
      "Epoch 403/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 197.8152 - mae: 198.5047 - val_loss: 254.2481 - val_mae: 254.9410\n",
      "Epoch 404/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 188.1493 - mae: 188.8413 - val_loss: 224.4561 - val_mae: 225.1470\n",
      "Epoch 405/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 199.4492 - mae: 200.1414 - val_loss: 229.0806 - val_mae: 229.7713\n",
      "Epoch 406/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 26ms/step - loss: 192.4208 - mae: 193.1101 - val_loss: 294.8195 - val_mae: 295.5127\n",
      "Epoch 407/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 193.5515 - mae: 194.2423 - val_loss: 217.1574 - val_mae: 217.8485\n",
      "Epoch 408/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 182.2036 - mae: 182.8961 - val_loss: 242.2618 - val_mae: 242.9539\n",
      "Epoch 409/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 190.6292 - mae: 191.3192 - val_loss: 226.7394 - val_mae: 227.4324\n",
      "Epoch 410/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 191.3862 - mae: 192.0781 - val_loss: 222.3416 - val_mae: 223.0347\n",
      "Epoch 411/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 173.8375 - mae: 174.5282 - val_loss: 218.7352 - val_mae: 219.4247\n",
      "Epoch 412/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 183.0338 - mae: 183.7232 - val_loss: 228.8245 - val_mae: 229.5175\n",
      "Epoch 413/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 176.9401 - mae: 177.6315 - val_loss: 243.0501 - val_mae: 243.7417\n",
      "Epoch 414/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 178.9758 - mae: 179.6641 - val_loss: 215.7954 - val_mae: 216.4846\n",
      "Epoch 415/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 172.3405 - mae: 173.0332 - val_loss: 246.4344 - val_mae: 247.1236\n",
      "Epoch 416/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 193.6604 - mae: 194.3507 - val_loss: 236.2836 - val_mae: 236.9655\n",
      "Epoch 417/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 183.5589 - mae: 184.2512 - val_loss: 219.0432 - val_mae: 219.7300\n",
      "Epoch 418/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 179.0069 - mae: 179.6972 - val_loss: 223.4652 - val_mae: 224.1583\n",
      "Epoch 419/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 185.8460 - mae: 186.5377 - val_loss: 217.2025 - val_mae: 217.8947\n",
      "Epoch 420/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 188.3985 - mae: 189.0901 - val_loss: 241.4013 - val_mae: 242.0931\n",
      "Epoch 421/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.8326 - mae: 178.5222 - val_loss: 226.3830 - val_mae: 227.0760\n",
      "Epoch 422/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.5233 - mae: 181.2144 - val_loss: 220.7101 - val_mae: 221.4032\n",
      "Epoch 423/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 189.0562 - mae: 189.7472 - val_loss: 218.6428 - val_mae: 219.3355\n",
      "Epoch 424/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 194.4194 - mae: 195.1100 - val_loss: 230.6883 - val_mae: 231.3784\n",
      "Epoch 425/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 184.4161 - mae: 185.1078 - val_loss: 238.8683 - val_mae: 239.5573\n",
      "Epoch 426/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.7880 - mae: 178.4765 - val_loss: 242.5061 - val_mae: 243.1969\n",
      "Epoch 427/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 184.0267 - mae: 184.7176 - val_loss: 214.7651 - val_mae: 215.4582\n",
      "Epoch 428/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 179.7749 - mae: 180.4654 - val_loss: 226.2943 - val_mae: 226.9872\n",
      "Epoch 429/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.1967 - mae: 178.8872 - val_loss: 248.3556 - val_mae: 249.0488\n",
      "Epoch 430/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 183.5254 - mae: 184.2160 - val_loss: 232.6644 - val_mae: 233.3566\n",
      "Epoch 431/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 194.1138 - mae: 194.8065 - val_loss: 261.8527 - val_mae: 262.5455\n",
      "Epoch 432/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 187.8678 - mae: 188.5576 - val_loss: 220.6031 - val_mae: 221.2961\n",
      "Epoch 433/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 199.6205 - mae: 200.3118 - val_loss: 217.0941 - val_mae: 217.7824\n",
      "Epoch 434/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 185.1165 - mae: 185.8062 - val_loss: 215.0301 - val_mae: 215.7227\n",
      "Epoch 435/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 172.9472 - mae: 173.6399 - val_loss: 244.1632 - val_mae: 244.8559\n",
      "Epoch 436/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 188.3890 - mae: 189.0793 - val_loss: 223.6684 - val_mae: 224.3558\n",
      "Epoch 437/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 174.8372 - mae: 175.5295 - val_loss: 223.5174 - val_mae: 224.2106\n",
      "Epoch 438/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 173.0721 - mae: 173.7639 - val_loss: 230.7978 - val_mae: 231.4861\n",
      "Epoch 439/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 177.7121 - mae: 178.4042 - val_loss: 219.1927 - val_mae: 219.8856\n",
      "Epoch 440/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 181.6080 - mae: 182.2997 - val_loss: 215.6112 - val_mae: 216.3009\n",
      "Epoch 441/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 182.8346 - mae: 183.5266 - val_loss: 219.7737 - val_mae: 220.4668\n",
      "Epoch 442/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 188.1055 - mae: 188.7978 - val_loss: 215.3577 - val_mae: 216.0412\n",
      "Epoch 443/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 181.5309 - mae: 182.2236 - val_loss: 218.6839 - val_mae: 219.3742\n",
      "Epoch 444/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 174.9153 - mae: 175.6068 - val_loss: 212.1939 - val_mae: 212.8850\n",
      "Epoch 445/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 186.3383 - mae: 187.0298 - val_loss: 246.4481 - val_mae: 247.1352\n",
      "Epoch 446/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 183.2391 - mae: 183.9318 - val_loss: 214.9709 - val_mae: 215.6641\n",
      "Epoch 447/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 182.7881 - mae: 183.4787 - val_loss: 215.4592 - val_mae: 216.1505\n",
      "Epoch 448/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 181.6106 - mae: 182.2999 - val_loss: 223.5130 - val_mae: 224.2060\n",
      "Epoch 449/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 181.0122 - mae: 181.7016 - val_loss: 215.1290 - val_mae: 215.8189\n",
      "Epoch 450/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 26ms/step - loss: 175.3459 - mae: 176.0365 - val_loss: 220.6889 - val_mae: 221.3803\n",
      "Epoch 451/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 195.9138 - mae: 196.6069 - val_loss: 229.7341 - val_mae: 230.4250\n",
      "Epoch 452/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 186.6913 - mae: 187.3787 - val_loss: 215.4780 - val_mae: 216.1707\n",
      "Epoch 453/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 188.3881 - mae: 189.0744 - val_loss: 222.9215 - val_mae: 223.6145\n",
      "Epoch 454/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.4538 - mae: 181.1453 - val_loss: 213.8120 - val_mae: 214.5044\n",
      "Epoch 455/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 173.1159 - mae: 173.8081 - val_loss: 217.8008 - val_mae: 218.4940\n",
      "Epoch 456/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 176.2338 - mae: 176.9233 - val_loss: 245.6219 - val_mae: 246.3148\n",
      "Epoch 457/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.0494 - mae: 178.7408 - val_loss: 252.5728 - val_mae: 253.2657\n",
      "Epoch 458/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 189.0655 - mae: 189.7562 - val_loss: 213.4654 - val_mae: 214.1572\n",
      "Epoch 459/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 185.2732 - mae: 185.9653 - val_loss: 246.5609 - val_mae: 247.2510\n",
      "Epoch 460/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 187.4602 - mae: 188.1513 - val_loss: 223.8019 - val_mae: 224.4943\n",
      "Epoch 461/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 190.2759 - mae: 190.9670 - val_loss: 214.5961 - val_mae: 215.2892\n",
      "Epoch 462/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 178.8200 - mae: 179.5103 - val_loss: 227.1366 - val_mae: 227.8295\n",
      "Epoch 463/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 177.9436 - mae: 178.6362 - val_loss: 225.4642 - val_mae: 226.1540\n",
      "Epoch 464/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 176.0822 - mae: 176.7715 - val_loss: 244.7973 - val_mae: 245.4903\n",
      "Epoch 465/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 185.5764 - mae: 186.2655 - val_loss: 219.6290 - val_mae: 220.3222\n",
      "Epoch 466/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 183.7737 - mae: 184.4656 - val_loss: 229.0614 - val_mae: 229.7527\n",
      "Epoch 467/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 201.3862 - mae: 202.0771 - val_loss: 218.8025 - val_mae: 219.4914\n",
      "Epoch 468/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 183.9063 - mae: 184.5992 - val_loss: 279.6577 - val_mae: 280.3504\n",
      "Epoch 469/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 198.4110 - mae: 199.1010 - val_loss: 212.2047 - val_mae: 212.8953\n",
      "Epoch 470/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 191.2621 - mae: 191.9545 - val_loss: 270.6243 - val_mae: 271.3172\n",
      "Epoch 471/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 187.9950 - mae: 188.6864 - val_loss: 240.4538 - val_mae: 241.1469\n",
      "Epoch 472/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 189.2735 - mae: 189.9612 - val_loss: 214.4724 - val_mae: 215.1650\n",
      "Epoch 473/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 202.7284 - mae: 203.4169 - val_loss: 239.2526 - val_mae: 239.9454\n",
      "Epoch 474/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.1836 - mae: 176.8702 - val_loss: 224.6729 - val_mae: 225.3639\n",
      "Epoch 475/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 190.4988 - mae: 191.1872 - val_loss: 246.0798 - val_mae: 246.7718\n",
      "Epoch 476/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 172.0906 - mae: 172.7803 - val_loss: 221.1225 - val_mae: 221.8120\n",
      "Epoch 477/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 180.6470 - mae: 181.3398 - val_loss: 223.0561 - val_mae: 223.7490\n",
      "Epoch 478/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 170.8302 - mae: 171.5158 - val_loss: 215.1791 - val_mae: 215.8702\n",
      "Epoch 479/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 193.6428 - mae: 194.3346 - val_loss: 215.1706 - val_mae: 215.8577\n",
      "Epoch 480/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 168.1408 - mae: 168.8314 - val_loss: 215.6577 - val_mae: 216.3495\n",
      "Epoch 481/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 193.5090 - mae: 194.1993 - val_loss: 267.4598 - val_mae: 268.1517\n",
      "Epoch 482/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 192.7939 - mae: 193.4828 - val_loss: 270.1776 - val_mae: 270.8698\n",
      "Epoch 483/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 184.4014 - mae: 185.0888 - val_loss: 224.5034 - val_mae: 225.1957\n",
      "Epoch 484/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 175.5776 - mae: 176.2685 - val_loss: 223.7127 - val_mae: 224.4043\n",
      "Epoch 485/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 195.3788 - mae: 196.0679 - val_loss: 235.3978 - val_mae: 236.0880\n",
      "Epoch 486/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 189.0518 - mae: 189.7426 - val_loss: 220.5366 - val_mae: 221.2293\n",
      "Epoch 487/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 183.2327 - mae: 183.9222 - val_loss: 215.1060 - val_mae: 215.7987\n",
      "Epoch 488/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 179.9243 - mae: 180.6166 - val_loss: 214.1957 - val_mae: 214.8851\n",
      "Epoch 489/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 186.7573 - mae: 187.4495 - val_loss: 240.9937 - val_mae: 241.6830\n",
      "Epoch 490/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 179.0809 - mae: 179.7726 - val_loss: 214.9823 - val_mae: 215.6729\n",
      "Epoch 491/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 181.1566 - mae: 181.8452 - val_loss: 222.6824 - val_mae: 223.3720\n",
      "Epoch 492/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 200.3894 - mae: 201.0796 - val_loss: 216.1026 - val_mae: 216.7957\n",
      "Epoch 493/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.9720 - mae: 177.6622 - val_loss: 225.1399 - val_mae: 225.8328\n",
      "Epoch 494/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 186.6622 - mae: 187.3526 - val_loss: 217.2053 - val_mae: 217.8961\n",
      "Epoch 495/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 188.1832 - mae: 188.8733 - val_loss: 231.7897 - val_mae: 232.4828\n",
      "Epoch 496/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 181.6989 - mae: 182.3909 - val_loss: 229.1899 - val_mae: 229.8830\n",
      "Epoch 497/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 164.6568 - mae: 165.3492 - val_loss: 238.6100 - val_mae: 239.3009\n",
      "Epoch 498/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 186.6399 - mae: 187.3305 - val_loss: 225.6709 - val_mae: 226.3637\n",
      "Epoch 499/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 183.8408 - mae: 184.5324 - val_loss: 212.5407 - val_mae: 213.2324\n",
      "Epoch 500/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 188.1987 - mae: 188.8906 - val_loss: 276.8971 - val_mae: 277.5899\n",
      "Epoch 501/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 174.7012 - mae: 175.3917 - val_loss: 218.5800 - val_mae: 219.2698\n",
      "Epoch 502/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.6677 - mae: 177.3595 - val_loss: 214.4403 - val_mae: 215.1280\n",
      "Epoch 503/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 199.5229 - mae: 200.2137 - val_loss: 250.8520 - val_mae: 251.5450\n",
      "Epoch 504/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 185.0278 - mae: 185.7166 - val_loss: 241.8987 - val_mae: 242.5901\n",
      "Epoch 505/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 183.2992 - mae: 183.9900 - val_loss: 277.2734 - val_mae: 277.9646\n",
      "Epoch 506/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.8042 - mae: 181.4934 - val_loss: 219.2836 - val_mae: 219.9765\n",
      "Epoch 507/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.5571 - mae: 177.2473 - val_loss: 214.7340 - val_mae: 215.4258\n",
      "Epoch 508/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 163.3831 - mae: 164.0729 - val_loss: 223.0935 - val_mae: 223.7863\n",
      "Epoch 509/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 182.0394 - mae: 182.7297 - val_loss: 218.5977 - val_mae: 219.2880\n",
      "Epoch 510/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 183.3672 - mae: 184.0579 - val_loss: 232.7005 - val_mae: 233.3931\n",
      "Epoch 511/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 189.3559 - mae: 190.0460 - val_loss: 239.3125 - val_mae: 240.0055\n",
      "Epoch 512/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 192.5578 - mae: 193.2498 - val_loss: 222.5121 - val_mae: 223.2051\n",
      "Epoch 513/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.1621 - mae: 178.8508 - val_loss: 217.9976 - val_mae: 218.6897\n",
      "Epoch 514/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 198.4570 - mae: 199.1490 - val_loss: 217.9477 - val_mae: 218.6385\n",
      "Epoch 515/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 184.6821 - mae: 185.3742 - val_loss: 225.7319 - val_mae: 226.4239\n",
      "Epoch 516/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 193.3012 - mae: 193.9939 - val_loss: 223.8890 - val_mae: 224.5820\n",
      "Epoch 517/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 201.4840 - mae: 202.1758 - val_loss: 212.6395 - val_mae: 213.3289\n",
      "Epoch 518/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 26ms/step - loss: 189.2426 - mae: 189.9353 - val_loss: 271.1914 - val_mae: 271.8818\n",
      "Epoch 519/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 189.2862 - mae: 189.9760 - val_loss: 212.7275 - val_mae: 213.4205\n",
      "Epoch 520/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 185.3658 - mae: 186.0568 - val_loss: 212.0559 - val_mae: 212.7443\n",
      "Epoch 521/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 186.3752 - mae: 187.0677 - val_loss: 213.1473 - val_mae: 213.8389\n",
      "Epoch 522/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 202.7862 - mae: 203.4769 - val_loss: 220.8930 - val_mae: 221.5835\n",
      "Epoch 523/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 174.0573 - mae: 174.7502 - val_loss: 223.9445 - val_mae: 224.6355\n",
      "Epoch 524/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 172.1817 - mae: 172.8741 - val_loss: 220.5346 - val_mae: 221.2266\n",
      "Epoch 525/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 185.4454 - mae: 186.1377 - val_loss: 225.3783 - val_mae: 226.0710\n",
      "Epoch 526/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 173.0829 - mae: 173.7744 - val_loss: 237.5528 - val_mae: 238.2459\n",
      "Epoch 527/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 185.4985 - mae: 186.1872 - val_loss: 256.2138 - val_mae: 256.9064\n",
      "Epoch 528/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.1979 - mae: 178.8889 - val_loss: 243.9855 - val_mae: 244.6762\n",
      "Epoch 529/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 187.7953 - mae: 188.4853 - val_loss: 219.0262 - val_mae: 219.7169\n",
      "Epoch 530/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 184.7516 - mae: 185.4416 - val_loss: 217.1902 - val_mae: 217.8818\n",
      "Epoch 531/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 194.3816 - mae: 195.0739 - val_loss: 213.9526 - val_mae: 214.6456\n",
      "Epoch 532/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 177.1796 - mae: 177.8699 - val_loss: 218.8217 - val_mae: 219.5148\n",
      "Epoch 533/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 184.3410 - mae: 185.0329 - val_loss: 211.5234 - val_mae: 212.2106\n",
      "Epoch 534/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 177.4260 - mae: 178.1161 - val_loss: 217.0420 - val_mae: 217.7334\n",
      "Epoch 535/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 164.6943 - mae: 165.3862 - val_loss: 215.2376 - val_mae: 215.9276\n",
      "Epoch 536/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 187.0050 - mae: 187.6933 - val_loss: 211.4988 - val_mae: 212.1908\n",
      "Epoch 537/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 186.5921 - mae: 187.2794 - val_loss: 212.7734 - val_mae: 213.4640\n",
      "Epoch 538/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.2641 - mae: 180.9537 - val_loss: 214.5586 - val_mae: 215.2516\n",
      "Epoch 539/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.1057 - mae: 176.7957 - val_loss: 246.4315 - val_mae: 247.1241\n",
      "Epoch 540/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 179.4820 - mae: 180.1723 - val_loss: 222.8581 - val_mae: 223.5466\n",
      "Epoch 541/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.7630 - mae: 179.4509 - val_loss: 222.4864 - val_mae: 223.1750\n",
      "Epoch 542/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.1020 - mae: 177.7939 - val_loss: 235.3782 - val_mae: 236.0709\n",
      "Epoch 543/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 186.3615 - mae: 187.0536 - val_loss: 223.5683 - val_mae: 224.2574\n",
      "Epoch 544/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 189.9342 - mae: 190.6258 - val_loss: 239.9221 - val_mae: 240.6152\n",
      "Epoch 545/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 173.7330 - mae: 174.4252 - val_loss: 212.9427 - val_mae: 213.6340\n",
      "Epoch 546/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 170.3577 - mae: 171.0494 - val_loss: 216.5814 - val_mae: 217.2742\n",
      "Epoch 547/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 165.4968 - mae: 166.1881 - val_loss: 234.4261 - val_mae: 235.1192\n",
      "Epoch 548/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 175.9189 - mae: 176.6114 - val_loss: 212.9963 - val_mae: 213.6885\n",
      "Epoch 549/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 174.4018 - mae: 175.0936 - val_loss: 213.1587 - val_mae: 213.8518\n",
      "Epoch 550/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 189.8214 - mae: 190.5138 - val_loss: 215.4270 - val_mae: 216.1167\n",
      "Epoch 551/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 186.2224 - mae: 186.9146 - val_loss: 214.4930 - val_mae: 215.1861\n",
      "Epoch 552/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 187.5297 - mae: 188.2215 - val_loss: 214.9741 - val_mae: 215.6667\n",
      "Epoch 553/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 188.5295 - mae: 189.2188 - val_loss: 257.3964 - val_mae: 258.0892\n",
      "Epoch 554/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 189.3552 - mae: 190.0480 - val_loss: 222.8290 - val_mae: 223.5188\n",
      "Epoch 555/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 180.8298 - mae: 181.5212 - val_loss: 214.8757 - val_mae: 215.5682\n",
      "Epoch 556/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.9792 - mae: 181.6707 - val_loss: 217.8819 - val_mae: 218.5706\n",
      "Epoch 557/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.7766 - mae: 181.4695 - val_loss: 229.0874 - val_mae: 229.7727\n",
      "Epoch 558/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 181.9125 - mae: 182.6037 - val_loss: 220.4439 - val_mae: 221.1363\n",
      "Epoch 559/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 184.9539 - mae: 185.6443 - val_loss: 218.6780 - val_mae: 219.3705\n",
      "Epoch 560/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 190.4132 - mae: 191.1051 - val_loss: 215.5896 - val_mae: 216.2817\n",
      "Epoch 561/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 175.7877 - mae: 176.4777 - val_loss: 218.1109 - val_mae: 218.8036\n",
      "Epoch 562/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 187.7603 - mae: 188.4503 - val_loss: 224.8649 - val_mae: 225.5567\n",
      "Epoch 563/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.0555 - mae: 177.7476 - val_loss: 218.7473 - val_mae: 219.4358\n",
      "Epoch 564/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 193.6911 - mae: 194.3812 - val_loss: 247.3887 - val_mae: 248.0808\n",
      "Epoch 565/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.9843 - mae: 178.6771 - val_loss: 236.2270 - val_mae: 236.9202\n",
      "Epoch 566/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 182.5837 - mae: 183.2755 - val_loss: 221.6636 - val_mae: 222.3557\n",
      "Epoch 567/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 193.7320 - mae: 194.4244 - val_loss: 217.8480 - val_mae: 218.5409\n",
      "Epoch 568/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 180.4504 - mae: 181.1416 - val_loss: 231.0657 - val_mae: 231.7544\n",
      "Epoch 569/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 187.2649 - mae: 187.9572 - val_loss: 278.9023 - val_mae: 279.5954\n",
      "Epoch 570/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 190.7104 - mae: 191.3998 - val_loss: 215.1701 - val_mae: 215.8611\n",
      "Epoch 571/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 188.6592 - mae: 189.3499 - val_loss: 214.2589 - val_mae: 214.9517\n",
      "Epoch 572/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 178.9467 - mae: 179.6375 - val_loss: 257.2769 - val_mae: 257.9701\n",
      "Epoch 573/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 182.9197 - mae: 183.6117 - val_loss: 225.2022 - val_mae: 225.8930\n",
      "Epoch 574/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 177.5773 - mae: 178.2690 - val_loss: 216.4897 - val_mae: 217.1824\n",
      "Epoch 575/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 26ms/step - loss: 164.0322 - mae: 164.7231 - val_loss: 213.6391 - val_mae: 214.3293\n",
      "Epoch 576/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 197.1606 - mae: 197.8526 - val_loss: 223.2981 - val_mae: 223.9849\n",
      "Epoch 577/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 201.9561 - mae: 202.6476 - val_loss: 269.1262 - val_mae: 269.8193\n",
      "Epoch 578/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 180.2599 - mae: 180.9506 - val_loss: 215.1999 - val_mae: 215.8895\n",
      "Epoch 579/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 181.5041 - mae: 182.1964 - val_loss: 221.3614 - val_mae: 222.0511\n",
      "Epoch 580/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 179.9408 - mae: 180.6318 - val_loss: 217.3087 - val_mae: 218.0005\n",
      "Epoch 581/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 174.1814 - mae: 174.8728 - val_loss: 215.9675 - val_mae: 216.6575\n",
      "Epoch 582/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 178.1811 - mae: 178.8739 - val_loss: 215.7604 - val_mae: 216.4447\n",
      "Epoch 583/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 175.4350 - mae: 176.1273 - val_loss: 213.3335 - val_mae: 214.0255\n",
      "Epoch 584/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 27ms/step - loss: 182.2036 - mae: 182.8955 - val_loss: 213.2641 - val_mae: 213.9538\n",
      "Epoch 585/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 177.9128 - mae: 178.5999 - val_loss: 235.0384 - val_mae: 235.7316\n",
      "Epoch 586/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 183.7137 - mae: 184.4015 - val_loss: 215.5083 - val_mae: 216.1987\n",
      "Epoch 587/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.4644 - mae: 181.1534 - val_loss: 213.0644 - val_mae: 213.7529\n",
      "Epoch 588/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 186.5161 - mae: 187.2034 - val_loss: 232.0356 - val_mae: 232.7269\n",
      "Epoch 589/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 180.9987 - mae: 181.6907 - val_loss: 212.4664 - val_mae: 213.1543\n",
      "Epoch 590/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 168.7909 - mae: 169.4837 - val_loss: 243.6506 - val_mae: 244.3437\n",
      "Epoch 591/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.4337 - mae: 179.1247 - val_loss: 214.2799 - val_mae: 214.9730\n",
      "Epoch 592/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 184.1441 - mae: 184.8342 - val_loss: 232.3723 - val_mae: 233.0646\n",
      "Epoch 593/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 184.2732 - mae: 184.9645 - val_loss: 246.9714 - val_mae: 247.6645\n",
      "Epoch 594/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 184.3467 - mae: 185.0381 - val_loss: 223.4896 - val_mae: 224.1824\n",
      "Epoch 595/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 183.7488 - mae: 184.4395 - val_loss: 214.4601 - val_mae: 215.1501\n",
      "Epoch 596/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 189.9645 - mae: 190.6559 - val_loss: 237.0807 - val_mae: 237.7739\n",
      "Epoch 597/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 172.6137 - mae: 173.3050 - val_loss: 214.4570 - val_mae: 215.1432\n",
      "Epoch 598/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.5129 - mae: 177.2051 - val_loss: 239.0544 - val_mae: 239.7436\n",
      "Epoch 599/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 175.4579 - mae: 176.1469 - val_loss: 213.7009 - val_mae: 214.3913\n",
      "Epoch 600/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 181.1319 - mae: 181.8191 - val_loss: 223.0563 - val_mae: 223.7440\n",
      "Epoch 601/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 179.1101 - mae: 179.8010 - val_loss: 245.1352 - val_mae: 245.8284\n",
      "Epoch 602/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 184.9636 - mae: 185.6543 - val_loss: 228.1362 - val_mae: 228.8293\n",
      "Epoch 603/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 171.8364 - mae: 172.5268 - val_loss: 226.9127 - val_mae: 227.6023\n",
      "Epoch 604/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 184.1550 - mae: 184.8465 - val_loss: 216.2036 - val_mae: 216.8955\n",
      "Epoch 605/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 186.5400 - mae: 187.2313 - val_loss: 215.7074 - val_mae: 216.3978\n",
      "Epoch 606/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 179.5579 - mae: 180.2493 - val_loss: 246.5988 - val_mae: 247.2916\n",
      "Epoch 607/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 188.2708 - mae: 188.9625 - val_loss: 230.0014 - val_mae: 230.6915\n",
      "Epoch 608/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 168.8129 - mae: 169.5033 - val_loss: 213.2298 - val_mae: 213.9217\n",
      "Epoch 609/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 189.1167 - mae: 189.8073 - val_loss: 247.0235 - val_mae: 247.7165\n",
      "Epoch 610/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 173.8974 - mae: 174.5880 - val_loss: 257.2089 - val_mae: 257.8992\n",
      "Epoch 611/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 181.1665 - mae: 181.8559 - val_loss: 224.7426 - val_mae: 225.4355\n",
      "Epoch 612/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 167.1737 - mae: 167.8667 - val_loss: 230.0912 - val_mae: 230.7783\n",
      "Epoch 613/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 197.2924 - mae: 197.9848 - val_loss: 263.0890 - val_mae: 263.7807\n",
      "Epoch 614/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 187.0156 - mae: 187.7060 - val_loss: 213.7715 - val_mae: 214.4635\n",
      "Epoch 615/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 194.2773 - mae: 194.9670 - val_loss: 219.7150 - val_mae: 220.4067\n",
      "Epoch 616/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 207.2990 - mae: 207.9917 - val_loss: 214.0358 - val_mae: 214.7272\n",
      "Epoch 617/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 189.6143 - mae: 190.3073 - val_loss: 215.5768 - val_mae: 216.2646\n",
      "Epoch 618/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 184.0990 - mae: 184.7897 - val_loss: 225.2705 - val_mae: 225.9593\n",
      "Epoch 619/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 189.0932 - mae: 189.7832 - val_loss: 214.7919 - val_mae: 215.4850\n",
      "Epoch 620/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.1205 - mae: 180.8130 - val_loss: 217.3355 - val_mae: 218.0248\n",
      "Epoch 621/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.3596 - mae: 179.0512 - val_loss: 214.1318 - val_mae: 214.8228\n",
      "Epoch 622/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 186.2023 - mae: 186.8953 - val_loss: 223.9343 - val_mae: 224.6263\n",
      "Epoch 623/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.5356 - mae: 178.2265 - val_loss: 221.4186 - val_mae: 222.1112\n",
      "Epoch 624/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 188.9152 - mae: 189.6057 - val_loss: 243.2638 - val_mae: 243.9556\n",
      "Epoch 625/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 188.4704 - mae: 189.1584 - val_loss: 223.7623 - val_mae: 224.4515\n",
      "Epoch 626/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 191.2501 - mae: 191.9400 - val_loss: 223.4133 - val_mae: 224.1034\n",
      "Epoch 627/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 189.7804 - mae: 190.4709 - val_loss: 216.9478 - val_mae: 217.6408\n",
      "Epoch 628/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.4334 - mae: 177.1233 - val_loss: 227.0657 - val_mae: 227.7556\n",
      "Epoch 629/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 182.9657 - mae: 183.6555 - val_loss: 233.0328 - val_mae: 233.7205\n",
      "Epoch 630/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 172.7134 - mae: 173.4044 - val_loss: 219.9654 - val_mae: 220.6582\n",
      "Epoch 631/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 182.6391 - mae: 183.3291 - val_loss: 221.1559 - val_mae: 221.8478\n",
      "Epoch 632/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 174.8625 - mae: 175.5490 - val_loss: 231.8461 - val_mae: 232.5373\n",
      "Epoch 633/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 182.1290 - mae: 182.8195 - val_loss: 253.5132 - val_mae: 254.2064\n",
      "Epoch 634/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 187.5495 - mae: 188.2407 - val_loss: 271.1098 - val_mae: 271.8029\n",
      "Epoch 635/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 201.1745 - mae: 201.8670 - val_loss: 223.5045 - val_mae: 224.1944\n",
      "Epoch 636/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 200.3540 - mae: 201.0459 - val_loss: 245.4489 - val_mae: 246.1420\n",
      "Epoch 636: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2bd84ef0be0>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 210
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LRZ1nHe0Gjy5"
   },
   "source": [
    "# **Testing Model**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qyAUCY0FGwsM",
    "ExecuteTime": {
     "end_time": "2024-04-17T03:04:16.650744Z",
     "start_time": "2024-04-17T03:04:16.635834Z"
    }
   },
   "source": [
    "#from tensorflow.keras.models import load_model\n",
    "#prediction_model = load_model('model/LSTM_reg_seven_new.keras',compile=False)"
   ],
   "outputs": [],
   "execution_count": 211
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T03:04:16.666245Z",
     "start_time": "2024-04-17T03:04:16.651746Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 211
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "lT71_QwcHEof",
    "outputId": "674692de-7a3b-4e60-addc-39ce1d9a328d",
    "ExecuteTime": {
     "end_time": "2024-04-17T03:04:17.190824Z",
     "start_time": "2024-04-17T03:04:16.667245Z"
    }
   },
   "source": "y_pred = np.ravel(model.predict(X_test))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m6/6\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n"
     ]
    }
   ],
   "execution_count": 212
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T03:04:17.206186Z",
     "start_time": "2024-04-17T03:04:17.191825Z"
    }
   },
   "source": [
    "y_test=np.ravel(y_test)"
   ],
   "outputs": [],
   "execution_count": 213
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T03:04:17.221484Z",
     "start_time": "2024-04-17T03:04:17.207442Z"
    }
   },
   "cell_type": "code",
   "source": "y_pred",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7252.6304,  7514.9824,  7564.5757,  7608.727 ,  7711.8076,\n",
       "        7729.9536,  8161.7505,  8812.908 ,  8768.04  ,  8867.056 ,\n",
       "        8974.49  ,  8780.8955,  8869.326 ,  9050.582 ,  9372.69  ,\n",
       "        9835.937 ,  9681.195 ,  8713.654 ,  8624.28  ,  8607.952 ,\n",
       "        8856.57  ,  9321.081 ,  9370.993 ,  9317.287 ,  9500.489 ,\n",
       "        9583.632 ,  9526.408 ,  9552.997 ,  9202.487 ,  9001.067 ,\n",
       "        9078.959 ,  9033.559 ,  8747.93  ,  8791.634 ,  8959.368 ,\n",
       "        9243.759 ,  9401.05  ,  9486.851 ,  9535.141 ,  9539.026 ,\n",
       "        9822.957 ,  9526.416 ,  9684.634 ,  9784.924 ,  9670.047 ,\n",
       "        9633.303 ,  9701.977 ,  9701.001 ,  9790.78  ,  9693.945 ,\n",
       "        9468.099 ,  9470.87  ,  9457.8125,  9292.4375,  9521.058 ,\n",
       "        9613.4795,  9538.239 ,  9370.13  ,  9351.822 ,  9392.017 ,\n",
       "        9489.679 ,  9647.718 ,  9488.028 ,  9286.436 ,  9242.338 ,\n",
       "        9167.907 ,  9113.467 ,  9160.525 ,  9197.751 ,  9229.115 ,\n",
       "        9214.929 ,  9143.173 ,  9159.7705,  9131.425 ,  9245.416 ,\n",
       "        9306.987 ,  9378.544 ,  9375.886 ,  9259.813 ,  9295.316 ,\n",
       "        9312.065 ,  9352.17  ,  9325.11  ,  9277.312 ,  9153.775 ,\n",
       "        9141.323 ,  9173.847 ,  9195.904 ,  9205.545 ,  9301.971 ,\n",
       "        9344.421 ,  9500.505 ,  9526.041 ,  9594.947 ,  9799.255 ,\n",
       "       10346.079 , 10901.113 , 11035.277 , 10965.034 , 11093.969 ,\n",
       "       11453.3955, 11218.701 , 11111.103 , 11076.587 , 11254.365 ,\n",
       "       11529.554 , 11510.077 , 11490.8955, 11467.101 , 11414.697 ,\n",
       "       11223.373 , 11285.255 , 11477.494 , 11558.112 , 11526.67  ,\n",
       "       11464.972 , 11281.329 , 11330.526 , 11456.164 , 11280.776 ,\n",
       "       11150.402 , 11092.037 , 11168.135 , 11235.654 , 11342.632 ,\n",
       "       11423.624 , 11354.253 , 10854.407 , 10210.101 , 10057.219 ,\n",
       "        9978.527 ,  9970.877 ,  9994.872 , 10056.318 , 10229.188 ,\n",
       "       10217.2295, 10283.154 , 10314.456 , 10418.426 , 10672.73  ,\n",
       "       10796.653 , 10800.852 , 10825.316 , 10893.736 , 11050.322 ,\n",
       "       10844.544 , 10378.448 , 10344.799 , 10345.869 , 10564.774 ,\n",
       "       10621.125 , 10634.088 , 10794.593 , 10666.208 , 10670.745 ,\n",
       "       10688.751 , 10480.435 , 10464.623 , 10504.094 , 10622.6045,\n",
       "       10647.364 , 10555.274 , 10650.625 , 10887.661 , 11207.203 ,\n",
       "       11238.017 , 11320.169 , 11308.969 , 11254.133 , 11244.414 ,\n",
       "       11180.632 , 11143.896 , 11248.325 , 11378.023 ], dtype=float32)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 214
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T03:04:17.237024Z",
     "start_time": "2024-04-17T03:04:17.222458Z"
    }
   },
   "source": [
    "r2=r2_score(y_test,y_pred) #testing score/ r^2\n",
    "r2"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5141881600594139"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 215
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T03:04:17.252499Z",
     "start_time": "2024-04-17T03:04:17.238166Z"
    }
   },
   "source": [
    "mae=mean_absolute_error(y_test,y_pred) #mae\n",
    "mae"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246.1420309132543"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 216
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T03:04:17.267898Z",
     "start_time": "2024-04-17T03:04:17.253624Z"
    }
   },
   "source": [
    "rmse=np.sqrt(mean_squared_error(y_test,y_pred)) #rmse\n",
    "rmse"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "894.8456113136394"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 217
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T03:04:17.283323Z",
     "start_time": "2024-04-17T03:04:17.268877Z"
    }
   },
   "source": [
    "mape=mean_absolute_percentage_error(y_test,y_pred) #mape\n",
    "mape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6540.296897257733"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 218
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T03:04:17.298518Z",
     "start_time": "2024-04-17T03:04:17.286082Z"
    }
   },
   "source": [
    "pd.DataFrame(zip(['MAE','RMSE','MAPE','R^2'],[mae,rmse,mape,r2])).transpose()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            0           1            2         3\n",
       "0         MAE        RMSE         MAPE       R^2\n",
       "1  246.142031  894.845611  6540.296897  0.514188"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAE</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>MAPE</td>\n",
       "      <td>R^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>246.142031</td>\n",
       "      <td>894.845611</td>\n",
       "      <td>6540.296897</td>\n",
       "      <td>0.514188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 219
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T03:04:17.314018Z",
     "start_time": "2024-04-17T03:04:17.299518Z"
    }
   },
   "source": [
    "pd.DataFrame([y_test,y_pred]).transpose()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           0             1\n",
       "0     7519.0   7252.630371\n",
       "1     7541.0   7514.982422\n",
       "2     7583.0   7564.575684\n",
       "3     7705.0   7608.727051\n",
       "4     7726.0   7711.807617\n",
       "..       ...           ...\n",
       "169  11370.0  11244.414062\n",
       "170  11348.0  11180.631836\n",
       "171  11433.0  11143.896484\n",
       "172  11582.0  11248.325195\n",
       "173      1.0  11378.023438\n",
       "\n",
       "[174 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7519.0</td>\n",
       "      <td>7252.630371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7541.0</td>\n",
       "      <td>7514.982422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7583.0</td>\n",
       "      <td>7564.575684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7705.0</td>\n",
       "      <td>7608.727051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7726.0</td>\n",
       "      <td>7711.807617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>11370.0</td>\n",
       "      <td>11244.414062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>11348.0</td>\n",
       "      <td>11180.631836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>11433.0</td>\n",
       "      <td>11143.896484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>11582.0</td>\n",
       "      <td>11248.325195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11378.023438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows  2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 220
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T03:04:17.329163Z",
     "start_time": "2024-04-17T03:04:17.314658Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 220
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Stock Market Predictor.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
