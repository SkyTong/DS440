{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKAxbUFku8lD"
   },
   "source": [
    "# **Dependancies**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oFJOnSzBk_uB",
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:38.022552Z",
     "start_time": "2024-04-21T17:21:38.016552Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import *\n",
    "from keras.callbacks import *\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from commons import mean_absolute_percentage_error\n",
    "from keras.layers import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import LogCosh"
   ],
   "outputs": [],
   "execution_count": 184
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22PseW2xqQET"
   },
   "source": [
    "# **Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0HH_FAAlRXx",
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:38.330927Z",
     "start_time": "2024-04-21T17:21:38.316419Z"
    }
   },
   "source": [
    "PATH_TO_DATA = \"reg_interval20-23nd.csv\"\n",
    "data = pd.read_csv(PATH_TO_DATA)"
   ],
   "outputs": [],
   "execution_count": 185
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:38.362031Z",
     "start_time": "2024-04-21T17:21:38.348504Z"
    }
   },
   "source": [
    "data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   fee_to_rewardUSD  mediantransactionvalue30trxUSD  \\\n",
       "0             0.457                          -0.240   \n",
       "1             0.776                          -0.261   \n",
       "2             0.770                          -0.279   \n",
       "3             0.583                          -0.300   \n",
       "4             0.580                          -0.325   \n",
       "\n",
       "   mining_profitability90trx  price30varUSD  price3momUSD  price3varUSD  \\\n",
       "0                     -0.307        28623.0      -231.566        3878.0   \n",
       "1                     -0.308        29355.0      -261.045        4729.0   \n",
       "2                     -0.310        29328.0       -42.402        3051.0   \n",
       "3                     -0.311        29574.0       152.469       11526.0   \n",
       "4                     -0.312        30437.0       376.272       10731.0   \n",
       "\n",
       "   price90momUSD  price90varUSD  sentinusdUSD  top100cap3trx  \\\n",
       "0      -1017.000       573722.0  2.022007e+09          0.003   \n",
       "1      -1046.000       581575.0  3.495276e+09         -0.020   \n",
       "2       -878.841       587195.0  5.664998e+09         -0.020   \n",
       "3       -626.347       590895.0  3.470998e+09         -0.010   \n",
       "4       -565.003       593111.0  2.540099e+09          0.003   \n",
       "\n",
       "   transactionvalueUSD  priceUSD  \n",
       "0              12757.0    7127.0  \n",
       "1              16735.0    7250.0  \n",
       "2              23302.0    7390.0  \n",
       "3              16928.0    7503.0  \n",
       "4              14695.0    7588.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fee_to_rewardUSD</th>\n",
       "      <th>mediantransactionvalue30trxUSD</th>\n",
       "      <th>mining_profitability90trx</th>\n",
       "      <th>price30varUSD</th>\n",
       "      <th>price3momUSD</th>\n",
       "      <th>price3varUSD</th>\n",
       "      <th>price90momUSD</th>\n",
       "      <th>price90varUSD</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>top100cap3trx</th>\n",
       "      <th>transactionvalueUSD</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.457</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>28623.0</td>\n",
       "      <td>-231.566</td>\n",
       "      <td>3878.0</td>\n",
       "      <td>-1017.000</td>\n",
       "      <td>573722.0</td>\n",
       "      <td>2.022007e+09</td>\n",
       "      <td>0.003</td>\n",
       "      <td>12757.0</td>\n",
       "      <td>7127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.776</td>\n",
       "      <td>-0.261</td>\n",
       "      <td>-0.308</td>\n",
       "      <td>29355.0</td>\n",
       "      <td>-261.045</td>\n",
       "      <td>4729.0</td>\n",
       "      <td>-1046.000</td>\n",
       "      <td>581575.0</td>\n",
       "      <td>3.495276e+09</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>16735.0</td>\n",
       "      <td>7250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.770</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>29328.0</td>\n",
       "      <td>-42.402</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>-878.841</td>\n",
       "      <td>587195.0</td>\n",
       "      <td>5.664998e+09</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>23302.0</td>\n",
       "      <td>7390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.583</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>29574.0</td>\n",
       "      <td>152.469</td>\n",
       "      <td>11526.0</td>\n",
       "      <td>-626.347</td>\n",
       "      <td>590895.0</td>\n",
       "      <td>3.470998e+09</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>16928.0</td>\n",
       "      <td>7503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.580</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>30437.0</td>\n",
       "      <td>376.272</td>\n",
       "      <td>10731.0</td>\n",
       "      <td>-565.003</td>\n",
       "      <td>593111.0</td>\n",
       "      <td>2.540099e+09</td>\n",
       "      <td>0.003</td>\n",
       "      <td>14695.0</td>\n",
       "      <td>7588.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 186
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:38.377550Z",
     "start_time": "2024-04-21T17:21:38.371541Z"
    }
   },
   "source": [
    "data.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1097, 12)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 187
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:38.392934Z",
     "start_time": "2024-04-21T17:21:38.388434Z"
    }
   },
   "cell_type": "code",
   "source": "y = data['priceUSD']",
   "outputs": [],
   "execution_count": 188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:38.439184Z",
     "start_time": "2024-04-21T17:21:38.424970Z"
    }
   },
   "cell_type": "code",
   "source": "X = data",
   "outputs": [],
   "execution_count": 189
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:38.485915Z",
     "start_time": "2024-04-21T17:21:38.482296Z"
    }
   },
   "cell_type": "code",
   "source": "X['priceUSD'] = X['priceUSD'].shift(1,fill_value=12255)",
   "outputs": [],
   "execution_count": 190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:38.516587Z",
     "start_time": "2024-04-21T17:21:38.502575Z"
    }
   },
   "cell_type": "code",
   "source": "X",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fee_to_rewardUSD  mediantransactionvalue30trxUSD  \\\n",
       "0                0.457                          -0.240   \n",
       "1                0.776                          -0.261   \n",
       "2                0.770                          -0.279   \n",
       "3                0.583                          -0.300   \n",
       "4                0.580                          -0.325   \n",
       "...                ...                             ...   \n",
       "1092             1.932                          -0.085   \n",
       "1093             2.283                          -0.087   \n",
       "1094             2.161                          -0.090   \n",
       "1095             1.235                          -0.094   \n",
       "1096             0.729                          -0.100   \n",
       "\n",
       "      mining_profitability90trx  price30varUSD  price3momUSD  price3varUSD  \\\n",
       "0                        -0.307        28623.0      -231.566      3878.000   \n",
       "1                        -0.308        29355.0      -261.045      4729.000   \n",
       "2                        -0.310        29328.0       -42.402      3051.000   \n",
       "3                        -0.311        29574.0       152.469     11526.000   \n",
       "4                        -0.312        30437.0       376.272     10731.000   \n",
       "...                         ...            ...           ...           ...   \n",
       "1092                     -0.406        82135.0      -179.890      8243.000   \n",
       "1093                     -0.405        76543.0      -258.919      8530.000   \n",
       "1094                     -0.404        82274.0      -257.127      1350.000   \n",
       "1095                     -0.403        86919.0       -69.693       287.999   \n",
       "1096                     -0.402        91811.0       -32.908        68.577   \n",
       "\n",
       "      price90momUSD  price90varUSD  sentinusdUSD  top100cap3trx  \\\n",
       "0         -1017.000       573722.0  2.022007e+09          0.003   \n",
       "1         -1046.000       581575.0  3.495276e+09         -0.020   \n",
       "2          -878.841       587195.0  5.664998e+09         -0.020   \n",
       "3          -626.347       590895.0  3.470998e+09         -0.010   \n",
       "4          -565.003       593111.0  2.540099e+09          0.003   \n",
       "...             ...            ...           ...            ...   \n",
       "1092      -2758.000      2474152.0  5.572254e+09          0.031   \n",
       "1093      -2936.000      2479394.0  6.313827e+09          0.047   \n",
       "1094      -2778.000      2489811.0  7.554070e+09          0.027   \n",
       "1095      -2661.000      2500289.0  4.493923e+09          0.030   \n",
       "1096      -2751.000      2507215.0  3.568420e+09          0.048   \n",
       "\n",
       "      transactionvalueUSD  priceUSD  \n",
       "0                 12757.0   12255.0  \n",
       "1                 16735.0    7127.0  \n",
       "2                 23302.0    7250.0  \n",
       "3                 16928.0    7390.0  \n",
       "4                 14695.0    7503.0  \n",
       "...                   ...       ...  \n",
       "1092              53190.0   16640.0  \n",
       "1093              54195.0   16591.0  \n",
       "1094              50405.0   16550.0  \n",
       "1095              42790.0   16570.0  \n",
       "1096              49147.0   16559.0  \n",
       "\n",
       "[1097 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fee_to_rewardUSD</th>\n",
       "      <th>mediantransactionvalue30trxUSD</th>\n",
       "      <th>mining_profitability90trx</th>\n",
       "      <th>price30varUSD</th>\n",
       "      <th>price3momUSD</th>\n",
       "      <th>price3varUSD</th>\n",
       "      <th>price90momUSD</th>\n",
       "      <th>price90varUSD</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>top100cap3trx</th>\n",
       "      <th>transactionvalueUSD</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.457</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>28623.0</td>\n",
       "      <td>-231.566</td>\n",
       "      <td>3878.000</td>\n",
       "      <td>-1017.000</td>\n",
       "      <td>573722.0</td>\n",
       "      <td>2.022007e+09</td>\n",
       "      <td>0.003</td>\n",
       "      <td>12757.0</td>\n",
       "      <td>12255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.776</td>\n",
       "      <td>-0.261</td>\n",
       "      <td>-0.308</td>\n",
       "      <td>29355.0</td>\n",
       "      <td>-261.045</td>\n",
       "      <td>4729.000</td>\n",
       "      <td>-1046.000</td>\n",
       "      <td>581575.0</td>\n",
       "      <td>3.495276e+09</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>16735.0</td>\n",
       "      <td>7127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.770</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>29328.0</td>\n",
       "      <td>-42.402</td>\n",
       "      <td>3051.000</td>\n",
       "      <td>-878.841</td>\n",
       "      <td>587195.0</td>\n",
       "      <td>5.664998e+09</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>23302.0</td>\n",
       "      <td>7250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.583</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>29574.0</td>\n",
       "      <td>152.469</td>\n",
       "      <td>11526.000</td>\n",
       "      <td>-626.347</td>\n",
       "      <td>590895.0</td>\n",
       "      <td>3.470998e+09</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>16928.0</td>\n",
       "      <td>7390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.580</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>30437.0</td>\n",
       "      <td>376.272</td>\n",
       "      <td>10731.000</td>\n",
       "      <td>-565.003</td>\n",
       "      <td>593111.0</td>\n",
       "      <td>2.540099e+09</td>\n",
       "      <td>0.003</td>\n",
       "      <td>14695.0</td>\n",
       "      <td>7503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>1.932</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>82135.0</td>\n",
       "      <td>-179.890</td>\n",
       "      <td>8243.000</td>\n",
       "      <td>-2758.000</td>\n",
       "      <td>2474152.0</td>\n",
       "      <td>5.572254e+09</td>\n",
       "      <td>0.031</td>\n",
       "      <td>53190.0</td>\n",
       "      <td>16640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>2.283</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>76543.0</td>\n",
       "      <td>-258.919</td>\n",
       "      <td>8530.000</td>\n",
       "      <td>-2936.000</td>\n",
       "      <td>2479394.0</td>\n",
       "      <td>6.313827e+09</td>\n",
       "      <td>0.047</td>\n",
       "      <td>54195.0</td>\n",
       "      <td>16591.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>2.161</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>82274.0</td>\n",
       "      <td>-257.127</td>\n",
       "      <td>1350.000</td>\n",
       "      <td>-2778.000</td>\n",
       "      <td>2489811.0</td>\n",
       "      <td>7.554070e+09</td>\n",
       "      <td>0.027</td>\n",
       "      <td>50405.0</td>\n",
       "      <td>16550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>1.235</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>86919.0</td>\n",
       "      <td>-69.693</td>\n",
       "      <td>287.999</td>\n",
       "      <td>-2661.000</td>\n",
       "      <td>2500289.0</td>\n",
       "      <td>4.493923e+09</td>\n",
       "      <td>0.030</td>\n",
       "      <td>42790.0</td>\n",
       "      <td>16570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>0.729</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.402</td>\n",
       "      <td>91811.0</td>\n",
       "      <td>-32.908</td>\n",
       "      <td>68.577</td>\n",
       "      <td>-2751.000</td>\n",
       "      <td>2507215.0</td>\n",
       "      <td>3.568420e+09</td>\n",
       "      <td>0.048</td>\n",
       "      <td>49147.0</td>\n",
       "      <td>16559.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1097 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 191
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:38.608867Z",
     "start_time": "2024-04-21T17:21:38.601966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#X1 = data\n",
    "#X1['target'] = X1['priceUSD'].shift(-1)\n"
   ],
   "outputs": [],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:38.671047Z",
     "start_time": "2024-04-21T17:21:38.656017Z"
    }
   },
   "cell_type": "code",
   "source": "#X1.dropna(subset=['target'], inplace=True)",
   "outputs": [],
   "execution_count": 193
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hSzHTpuzmScU",
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:38.701907Z",
     "start_time": "2024-04-21T17:21:38.689068Z"
    }
   },
   "source": "#X = data.iloc[:,:-1]",
   "outputs": [],
   "execution_count": 194
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:38.795271Z",
     "start_time": "2024-04-21T17:21:38.778645Z"
    }
   },
   "source": "#y=data.iloc[:,-1:]",
   "outputs": [],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:38.810779Z",
     "start_time": "2024-04-21T17:21:38.806779Z"
    }
   },
   "cell_type": "code",
   "source": "#y = data['priceUSD'].shift(-1,fill_value=1)",
   "outputs": [],
   "execution_count": 196
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:38.856972Z",
     "start_time": "2024-04-21T17:21:38.843100Z"
    }
   },
   "cell_type": "code",
   "source": "#y = data['priceUSD']",
   "outputs": [],
   "execution_count": 197
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:38.918768Z",
     "start_time": "2024-04-21T17:21:38.904900Z"
    }
   },
   "cell_type": "code",
   "source": "y",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        7127.0\n",
       "1        7250.0\n",
       "2        7390.0\n",
       "3        7503.0\n",
       "4        7588.0\n",
       "         ...   \n",
       "1092    16591.0\n",
       "1093    16550.0\n",
       "1094    16570.0\n",
       "1095    16559.0\n",
       "1096    16691.0\n",
       "Name: priceUSD, Length: 1097, dtype: float64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 198
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:38.934916Z",
     "start_time": "2024-04-21T17:21:38.921020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX = []\n",
    "    datay = []\n",
    "    for i in range(len(dataset) - time_step):\n",
    "        a = dataset.iloc[i:(i + time_step), :].values  # Use .iloc for DataFrame\n",
    "        dataX.append(a)\n",
    "        datay.append(dataset.iloc[i + time_step, -1])\n",
    "    return np.array(dataX), np.array(datay)\n"
   ],
   "outputs": [],
   "execution_count": 199
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:38.949984Z",
     "start_time": "2024-04-21T17:21:38.940975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#time_step = 15\n",
    "#X2 ,y2 = create_dataset(X1, time_step)\n",
    "\n",
    "#print(\"X: \", X2.shape)\n",
    "#print(\"y: \", y2.shape)"
   ],
   "outputs": [],
   "execution_count": 200
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:38.996511Z",
     "start_time": "2024-04-21T17:21:38.982467Z"
    }
   },
   "cell_type": "code",
   "source": "#X2",
   "outputs": [],
   "execution_count": 201
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.058575Z",
     "start_time": "2024-04-21T17:21:39.046500Z"
    }
   },
   "cell_type": "code",
   "source": "#y2",
   "outputs": [],
   "execution_count": 202
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.089526Z",
     "start_time": "2024-04-21T17:21:39.077092Z"
    }
   },
   "cell_type": "code",
   "source": "#y2_reshaped = y2.reshape(-1, 1, 1)",
   "outputs": [],
   "execution_count": 203
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.104942Z",
     "start_time": "2024-04-21T17:21:39.098096Z"
    }
   },
   "cell_type": "code",
   "source": "#y2_reshaped",
   "outputs": [],
   "execution_count": 204
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.135723Z",
     "start_time": "2024-04-21T17:21:39.122773Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 204
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.166337Z",
     "start_time": "2024-04-21T17:21:39.152423Z"
    }
   },
   "source": "X_train, X_test, y_train, y_test =train_test_split(X,y, test_size=0.2, train_size=0.8, shuffle=False, random_state=8)",
   "outputs": [],
   "execution_count": 205
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.196988Z",
     "start_time": "2024-04-21T17:21:39.192477Z"
    }
   },
   "source": [
    "X_train.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(877, 12)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 206
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.243393Z",
     "start_time": "2024-04-21T17:21:39.229383Z"
    }
   },
   "source": [
    "estimators=[]"
   ],
   "outputs": [],
   "execution_count": 207
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.274145Z",
     "start_time": "2024-04-21T17:21:39.260413Z"
    }
   },
   "source": [
    "estimators.append(['robust',RobustScaler()])"
   ],
   "outputs": [],
   "execution_count": 208
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.320756Z",
     "start_time": "2024-04-21T17:21:39.306246Z"
    }
   },
   "source": [
    "estimators.append(['mixmax',MinMaxScaler()])"
   ],
   "outputs": [],
   "execution_count": 209
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.413206Z",
     "start_time": "2024-04-21T17:21:39.398661Z"
    }
   },
   "source": [
    "scale=Pipeline(estimators,verbose=True)"
   ],
   "outputs": [],
   "execution_count": 210
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDojXgA7mpWa",
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.428604Z",
     "start_time": "2024-04-21T17:21:39.416345Z"
    }
   },
   "source": [
    "X_train=scale.fit_transform(X_train)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing robust, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing mixmax, total=   0.0s\n"
     ]
    }
   ],
   "execution_count": 211
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.490348Z",
     "start_time": "2024-04-21T17:21:39.476374Z"
    }
   },
   "source": [
    "X_test=scale.transform(X_test)"
   ],
   "outputs": [],
   "execution_count": 212
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.536888Z",
     "start_time": "2024-04-21T17:21:39.522373Z"
    }
   },
   "source": [
    "X_train=np.reshape(X_train,(X_train.shape[0],1,X_train.shape[1]))"
   ],
   "outputs": [],
   "execution_count": 213
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.567716Z",
     "start_time": "2024-04-21T17:21:39.559208Z"
    }
   },
   "source": [
    "X_test=np.reshape(X_test,(X_test.shape[0],1,X_test.shape[1]))"
   ],
   "outputs": [],
   "execution_count": 214
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2wNcl2z_JKkM",
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.598753Z",
     "start_time": "2024-04-21T17:21:39.593244Z"
    }
   },
   "source": [
    "y_train=y_train.values"
   ],
   "outputs": [],
   "execution_count": 215
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.629953Z",
     "start_time": "2024-04-21T17:21:39.613260Z"
    }
   },
   "source": [
    "y_train=np.reshape(y_train, (y_train.shape[0],1,1))"
   ],
   "outputs": [],
   "execution_count": 216
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.660984Z",
     "start_time": "2024-04-21T17:21:39.647972Z"
    }
   },
   "source": [
    "y_test=y_test.values"
   ],
   "outputs": [],
   "execution_count": 217
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.707535Z",
     "start_time": "2024-04-21T17:21:39.695528Z"
    }
   },
   "source": [
    "y_test=np.reshape(y_test,(y_test.shape[0],1,1))"
   ],
   "outputs": [],
   "execution_count": 218
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.738560Z",
     "start_time": "2024-04-21T17:21:39.725552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ],
   "outputs": [],
   "execution_count": 219
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.769585Z",
     "start_time": "2024-04-21T17:21:39.753067Z"
    }
   },
   "source": "X_train.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(877, 1, 12)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 220
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.785293Z",
     "start_time": "2024-04-21T17:21:39.772585Z"
    }
   },
   "cell_type": "code",
   "source": "X_train",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.1867065 , 0.03035714, ..., 0.40980393,\n",
       "         0.        , 0.1159221 ]],\n",
       "\n",
       "       [[0.01123754, 0.17102315, 0.02946429, ..., 0.39477125,\n",
       "         0.00163186, 0.0339292 ]],\n",
       "\n",
       "       [[0.01102617, 0.15758029, 0.02767857, ..., 0.39477125,\n",
       "         0.00432579, 0.03589588]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.05830133, 0.44660193, 0.03214286, ..., 0.4130719 ,\n",
       "         0.1255354 , 0.38865083]],\n",
       "\n",
       "       [[0.0585127 , 0.44436148, 0.03035714, ..., 0.43333334,\n",
       "         0.07643056, 0.39578202]],\n",
       "\n",
       "       [[0.05301723, 0.44286782, 0.02857143, ..., 0.43986928,\n",
       "         0.10168917, 0.39096928]]], dtype=float32)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 221
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.815839Z",
     "start_time": "2024-04-21T17:21:39.801318Z"
    }
   },
   "cell_type": "code",
   "source": "y_train.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(877, 1, 1)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 222
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.862412Z",
     "start_time": "2024-04-21T17:21:39.848411Z"
    }
   },
   "cell_type": "code",
   "source": "y_train",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 7127.]],\n",
       "\n",
       "       [[ 7250.]],\n",
       "\n",
       "       [[ 7390.]],\n",
       "\n",
       "       [[ 7503.]],\n",
       "\n",
       "       [[ 7588.]],\n",
       "\n",
       "       [[ 7953.]],\n",
       "\n",
       "       [[ 8273.]],\n",
       "\n",
       "       [[ 7943.]],\n",
       "\n",
       "       [[ 7933.]],\n",
       "\n",
       "       [[ 8120.]],\n",
       "\n",
       "       [[ 8146.]],\n",
       "\n",
       "       [[ 8151.]],\n",
       "\n",
       "       [[ 8605.]],\n",
       "\n",
       "       [[ 8778.]],\n",
       "\n",
       "       [[ 8693.]],\n",
       "\n",
       "       [[ 8869.]],\n",
       "\n",
       "       [[ 8907.]],\n",
       "\n",
       "       [[ 8859.]],\n",
       "\n",
       "       [[ 8670.]],\n",
       "\n",
       "       [[ 8672.]],\n",
       "\n",
       "       [[ 8693.]],\n",
       "\n",
       "       [[ 8469.]],\n",
       "\n",
       "       [[ 8410.]],\n",
       "\n",
       "       [[ 8349.]],\n",
       "\n",
       "       [[ 8466.]],\n",
       "\n",
       "       [[ 8744.]],\n",
       "\n",
       "       [[ 9049.]],\n",
       "\n",
       "       [[ 9349.]],\n",
       "\n",
       "       [[ 9394.]],\n",
       "\n",
       "       [[ 9366.]],\n",
       "\n",
       "       [[ 9393.]],\n",
       "\n",
       "       [[ 9398.]],\n",
       "\n",
       "       [[ 9356.]],\n",
       "\n",
       "       [[ 9233.]],\n",
       "\n",
       "       [[ 9421.]],\n",
       "\n",
       "       [[ 9706.]],\n",
       "\n",
       "       [[ 9798.]],\n",
       "\n",
       "       [[ 9823.]],\n",
       "\n",
       "       [[10083.]],\n",
       "\n",
       "       [[ 9932.]],\n",
       "\n",
       "       [[ 9968.]],\n",
       "\n",
       "       [[10331.]],\n",
       "\n",
       "       [[10289.]],\n",
       "\n",
       "       [[10272.]],\n",
       "\n",
       "       [[10152.]],\n",
       "\n",
       "       [[ 9916.]],\n",
       "\n",
       "       [[ 9723.]],\n",
       "\n",
       "       [[ 9840.]],\n",
       "\n",
       "       [[10091.]],\n",
       "\n",
       "       [[ 9612.]],\n",
       "\n",
       "       [[ 9688.]],\n",
       "\n",
       "       [[ 9666.]],\n",
       "\n",
       "       [[ 9850.]],\n",
       "\n",
       "       [[ 9755.]],\n",
       "\n",
       "       [[ 9520.]],\n",
       "\n",
       "       [[ 9065.]],\n",
       "\n",
       "       [[ 8803.]],\n",
       "\n",
       "       [[ 8706.]],\n",
       "\n",
       "       [[ 8690.]],\n",
       "\n",
       "       [[ 8572.]],\n",
       "\n",
       "       [[ 8754.]],\n",
       "\n",
       "       [[ 8791.]],\n",
       "\n",
       "       [[ 8767.]],\n",
       "\n",
       "       [[ 9024.]],\n",
       "\n",
       "       [[ 9099.]],\n",
       "\n",
       "       [[ 9050.]],\n",
       "\n",
       "       [[ 8589.]],\n",
       "\n",
       "       [[ 7886.]],\n",
       "\n",
       "       [[ 7957.]],\n",
       "\n",
       "       [[ 7856.]],\n",
       "\n",
       "       [[ 6696.]],\n",
       "\n",
       "       [[ 5278.]],\n",
       "\n",
       "       [[ 5401.]],\n",
       "\n",
       "       [[ 5316.]],\n",
       "\n",
       "       [[ 5005.]],\n",
       "\n",
       "       [[ 5179.]],\n",
       "\n",
       "       [[ 5182.]],\n",
       "\n",
       "       [[ 5668.]],\n",
       "\n",
       "       [[ 6288.]],\n",
       "\n",
       "       [[ 6167.]],\n",
       "\n",
       "       [[ 6134.]],\n",
       "\n",
       "       [[ 6097.]],\n",
       "\n",
       "       [[ 6629.]],\n",
       "\n",
       "       [[ 6658.]],\n",
       "\n",
       "       [[ 6666.]],\n",
       "\n",
       "       [[ 6685.]],\n",
       "\n",
       "       [[ 6228.]],\n",
       "\n",
       "       [[ 6124.]],\n",
       "\n",
       "       [[ 6266.]],\n",
       "\n",
       "       [[ 6451.]],\n",
       "\n",
       "       [[ 6314.]],\n",
       "\n",
       "       [[ 6722.]],\n",
       "\n",
       "       [[ 6822.]],\n",
       "\n",
       "       [[ 6773.]],\n",
       "\n",
       "       [[ 6799.]],\n",
       "\n",
       "       [[ 7082.]],\n",
       "\n",
       "       [[ 7310.]],\n",
       "\n",
       "       [[ 7280.]],\n",
       "\n",
       "       [[ 7286.]],\n",
       "\n",
       "       [[ 6980.]],\n",
       "\n",
       "       [[ 6846.]],\n",
       "\n",
       "       [[ 6946.]],\n",
       "\n",
       "       [[ 6745.]],\n",
       "\n",
       "       [[ 6874.]],\n",
       "\n",
       "       [[ 6793.]],\n",
       "\n",
       "       [[ 6893.]],\n",
       "\n",
       "       [[ 7074.]],\n",
       "\n",
       "       [[ 7129.]],\n",
       "\n",
       "       [[ 7157.]],\n",
       "\n",
       "       [[ 7047.]],\n",
       "\n",
       "       [[ 6863.]],\n",
       "\n",
       "       [[ 6986.]],\n",
       "\n",
       "       [[ 7272.]],\n",
       "\n",
       "       [[ 7519.]],\n",
       "\n",
       "       [[ 7541.]],\n",
       "\n",
       "       [[ 7583.]],\n",
       "\n",
       "       [[ 7705.]],\n",
       "\n",
       "       [[ 7726.]],\n",
       "\n",
       "       [[ 8198.]],\n",
       "\n",
       "       [[ 8883.]],\n",
       "\n",
       "       [[ 8777.]],\n",
       "\n",
       "       [[ 8854.]],\n",
       "\n",
       "       [[ 8973.]],\n",
       "\n",
       "       [[ 8780.]],\n",
       "\n",
       "       [[ 8904.]],\n",
       "\n",
       "       [[ 9109.]],\n",
       "\n",
       "       [[ 9445.]],\n",
       "\n",
       "       [[ 9917.]],\n",
       "\n",
       "       [[ 9724.]],\n",
       "\n",
       "       [[ 8697.]],\n",
       "\n",
       "       [[ 8704.]],\n",
       "\n",
       "       [[ 8775.]],\n",
       "\n",
       "       [[ 9039.]],\n",
       "\n",
       "       [[ 9523.]],\n",
       "\n",
       "       [[ 9519.]],\n",
       "\n",
       "       [[ 9407.]],\n",
       "\n",
       "       [[ 9623.]],\n",
       "\n",
       "       [[ 9728.]],\n",
       "\n",
       "       [[ 9680.]],\n",
       "\n",
       "       [[ 9677.]],\n",
       "\n",
       "       [[ 9302.]],\n",
       "\n",
       "       [[ 9137.]],\n",
       "\n",
       "       [[ 9216.]],\n",
       "\n",
       "       [[ 9139.]],\n",
       "\n",
       "       [[ 8829.]],\n",
       "\n",
       "       [[ 8872.]],\n",
       "\n",
       "       [[ 9033.]],\n",
       "\n",
       "       [[ 9320.]],\n",
       "\n",
       "       [[ 9463.]],\n",
       "\n",
       "       [[ 9510.]],\n",
       "\n",
       "       [[ 9558.]],\n",
       "\n",
       "       [[ 9581.]],\n",
       "\n",
       "       [[ 9894.]],\n",
       "\n",
       "       [[ 9561.]],\n",
       "\n",
       "       [[ 9710.]],\n",
       "\n",
       "       [[ 9760.]],\n",
       "\n",
       "       [[ 9656.]],\n",
       "\n",
       "       [[ 9644.]],\n",
       "\n",
       "       [[ 9733.]],\n",
       "\n",
       "       [[ 9719.]],\n",
       "\n",
       "       [[ 9793.]],\n",
       "\n",
       "       [[ 9659.]],\n",
       "\n",
       "       [[ 9427.]],\n",
       "\n",
       "       [[ 9444.]],\n",
       "\n",
       "       [[ 9425.]],\n",
       "\n",
       "       [[ 9261.]],\n",
       "\n",
       "       [[ 9500.]],\n",
       "\n",
       "       [[ 9462.]],\n",
       "\n",
       "       [[ 9429.]],\n",
       "\n",
       "       [[ 9356.]],\n",
       "\n",
       "       [[ 9330.]],\n",
       "\n",
       "       [[ 9371.]],\n",
       "\n",
       "       [[ 9490.]],\n",
       "\n",
       "       [[ 9649.]],\n",
       "\n",
       "       [[ 9468.]],\n",
       "\n",
       "       [[ 9261.]],\n",
       "\n",
       "       [[ 9219.]],\n",
       "\n",
       "       [[ 9143.]],\n",
       "\n",
       "       [[ 9087.]],\n",
       "\n",
       "       [[ 9150.]],\n",
       "\n",
       "       [[ 9182.]],\n",
       "\n",
       "       [[ 9224.]],\n",
       "\n",
       "       [[ 9203.]],\n",
       "\n",
       "       [[ 9125.]],\n",
       "\n",
       "       [[ 9137.]],\n",
       "\n",
       "       [[ 9110.]],\n",
       "\n",
       "       [[ 9244.]],\n",
       "\n",
       "       [[ 9300.]],\n",
       "\n",
       "       [[ 9374.]],\n",
       "\n",
       "       [[ 9362.]],\n",
       "\n",
       "       [[ 9236.]],\n",
       "\n",
       "       [[ 9279.]],\n",
       "\n",
       "       [[ 9292.]],\n",
       "\n",
       "       [[ 9316.]],\n",
       "\n",
       "       [[ 9252.]],\n",
       "\n",
       "       [[ 9258.]],\n",
       "\n",
       "       [[ 9169.]],\n",
       "\n",
       "       [[ 9169.]],\n",
       "\n",
       "       [[ 9201.]],\n",
       "\n",
       "       [[ 9198.]],\n",
       "\n",
       "       [[ 9220.]],\n",
       "\n",
       "       [[ 9342.]],\n",
       "\n",
       "       [[ 9397.]],\n",
       "\n",
       "       [[ 9561.]],\n",
       "\n",
       "       [[ 9565.]],\n",
       "\n",
       "       [[ 9627.]],\n",
       "\n",
       "       [[ 9836.]],\n",
       "\n",
       "       [[10423.]],\n",
       "\n",
       "       [[10988.]],\n",
       "\n",
       "       [[11098.]],\n",
       "\n",
       "       [[11039.]],\n",
       "\n",
       "       [[11199.]],\n",
       "\n",
       "       [[11595.]],\n",
       "\n",
       "       [[11342.]],\n",
       "\n",
       "       [[11258.]],\n",
       "\n",
       "       [[11252.]],\n",
       "\n",
       "       [[11461.]],\n",
       "\n",
       "       [[11757.]],\n",
       "\n",
       "       [[11719.]],\n",
       "\n",
       "       [[11683.]],\n",
       "\n",
       "       [[11675.]],\n",
       "\n",
       "       [[11895.]],\n",
       "\n",
       "       [[11640.]],\n",
       "\n",
       "       [[11466.]],\n",
       "\n",
       "       [[11553.]],\n",
       "\n",
       "       [[11755.]],\n",
       "\n",
       "       [[11879.]],\n",
       "\n",
       "       [[11854.]],\n",
       "\n",
       "       [[12053.]],\n",
       "\n",
       "       [[12170.]],\n",
       "\n",
       "       [[11803.]],\n",
       "\n",
       "       [[11801.]],\n",
       "\n",
       "       [[11753.]],\n",
       "\n",
       "       [[11563.]],\n",
       "\n",
       "       [[11628.]],\n",
       "\n",
       "       [[11740.]],\n",
       "\n",
       "       [[11521.]],\n",
       "\n",
       "       [[11410.]],\n",
       "\n",
       "       [[11355.]],\n",
       "\n",
       "       [[11445.]],\n",
       "\n",
       "       [[11513.]],\n",
       "\n",
       "       [[11614.]],\n",
       "\n",
       "       [[11689.]],\n",
       "\n",
       "       [[11872.]],\n",
       "\n",
       "       [[11587.]],\n",
       "\n",
       "       [[11059.]],\n",
       "\n",
       "       [[10393.]],\n",
       "\n",
       "       [[10279.]],\n",
       "\n",
       "       [[10205.]],\n",
       "\n",
       "       [[10164.]],\n",
       "\n",
       "       [[10156.]],\n",
       "\n",
       "       [[10189.]],\n",
       "\n",
       "       [[10344.]],\n",
       "\n",
       "       [[10309.]],\n",
       "\n",
       "       [[10379.]],\n",
       "\n",
       "       [[10404.]],\n",
       "\n",
       "       [[10512.]],\n",
       "\n",
       "       [[10778.]],\n",
       "\n",
       "       [[10900.]],\n",
       "\n",
       "       [[10899.]],\n",
       "\n",
       "       [[10931.]],\n",
       "\n",
       "       [[11019.]],\n",
       "\n",
       "       [[10928.]],\n",
       "\n",
       "       [[10692.]],\n",
       "\n",
       "       [[10475.]],\n",
       "\n",
       "       [[10445.]],\n",
       "\n",
       "       [[10447.]],\n",
       "\n",
       "       [[10679.]],\n",
       "\n",
       "       [[10724.]],\n",
       "\n",
       "       [[10725.]],\n",
       "\n",
       "       [[10887.]],\n",
       "\n",
       "       [[10736.]],\n",
       "\n",
       "       [[10751.]],\n",
       "\n",
       "       [[10766.]],\n",
       "\n",
       "       [[10535.]],\n",
       "\n",
       "       [[10556.]],\n",
       "\n",
       "       [[10611.]],\n",
       "\n",
       "       [[10710.]],\n",
       "\n",
       "       [[10719.]],\n",
       "\n",
       "       [[10625.]],\n",
       "\n",
       "       [[10737.]],\n",
       "\n",
       "       [[10986.]],\n",
       "\n",
       "       [[11335.]],\n",
       "\n",
       "       [[11364.]],\n",
       "\n",
       "       [[11448.]],\n",
       "\n",
       "       [[11455.]],\n",
       "\n",
       "       [[11409.]],\n",
       "\n",
       "       [[11417.]],\n",
       "\n",
       "       [[11370.]],\n",
       "\n",
       "       [[11348.]],\n",
       "\n",
       "       [[11433.]],\n",
       "\n",
       "       [[11582.]],\n",
       "\n",
       "       [[11847.]],\n",
       "\n",
       "       [[12446.]],\n",
       "\n",
       "       [[12929.]],\n",
       "\n",
       "       [[12936.]],\n",
       "\n",
       "       [[13026.]],\n",
       "\n",
       "       [[13058.]],\n",
       "\n",
       "       [[13072.]],\n",
       "\n",
       "       [[13360.]],\n",
       "\n",
       "       [[13454.]],\n",
       "\n",
       "       [[13319.]],\n",
       "\n",
       "       [[13435.]],\n",
       "\n",
       "       [[13738.]],\n",
       "\n",
       "       [[13771.]],\n",
       "\n",
       "       [[13600.]],\n",
       "\n",
       "       [[13611.]],\n",
       "\n",
       "       [[13898.]],\n",
       "\n",
       "       [[14706.]],\n",
       "\n",
       "       [[15578.]],\n",
       "\n",
       "       [[15354.]],\n",
       "\n",
       "       [[15193.]],\n",
       "\n",
       "       [[15382.]],\n",
       "\n",
       "       [[15323.]],\n",
       "\n",
       "       [[15585.]],\n",
       "\n",
       "       [[15919.]],\n",
       "\n",
       "       [[16289.]],\n",
       "\n",
       "       [[16045.]],\n",
       "\n",
       "       [[16000.]],\n",
       "\n",
       "       [[16364.]],\n",
       "\n",
       "       [[17072.]],\n",
       "\n",
       "       [[17879.]],\n",
       "\n",
       "       [[17839.]],\n",
       "\n",
       "       [[18323.]],\n",
       "\n",
       "       [[18706.]],\n",
       "\n",
       "       [[18429.]],\n",
       "\n",
       "       [[18442.]],\n",
       "\n",
       "       [[18848.]],\n",
       "\n",
       "       [[19064.]],\n",
       "\n",
       "       [[17408.]],\n",
       "\n",
       "       [[16995.]],\n",
       "\n",
       "       [[17316.]],\n",
       "\n",
       "       [[17994.]],\n",
       "\n",
       "       [[18902.]],\n",
       "\n",
       "       [[19276.]],\n",
       "\n",
       "       [[18951.]],\n",
       "\n",
       "       [[19280.]],\n",
       "\n",
       "       [[19133.]],\n",
       "\n",
       "       [[19000.]],\n",
       "\n",
       "       [[19151.]],\n",
       "\n",
       "       [[19207.]],\n",
       "\n",
       "       [[18955.]],\n",
       "\n",
       "       [[18273.]],\n",
       "\n",
       "       [[18314.]],\n",
       "\n",
       "       [[17948.]],\n",
       "\n",
       "       [[18472.]],\n",
       "\n",
       "       [[19117.]],\n",
       "\n",
       "       [[19167.]],\n",
       "\n",
       "       [[19353.]],\n",
       "\n",
       "       [[20057.]],\n",
       "\n",
       "       [[22598.]],\n",
       "\n",
       "       [[22874.]],\n",
       "\n",
       "       [[23341.]],\n",
       "\n",
       "       [[23594.]],\n",
       "\n",
       "       [[23257.]],\n",
       "\n",
       "       [[23084.]],\n",
       "\n",
       "       [[23562.]],\n",
       "\n",
       "       [[23307.]],\n",
       "\n",
       "       [[24013.]],\n",
       "\n",
       "       [[25252.]],\n",
       "\n",
       "       [[27061.]],\n",
       "\n",
       "       [[26978.]],\n",
       "\n",
       "       [[26678.]],\n",
       "\n",
       "       [[28128.]],\n",
       "\n",
       "       [[28876.]],\n",
       "\n",
       "       [[29260.]],\n",
       "\n",
       "       [[30703.]],\n",
       "\n",
       "       [[33457.]],\n",
       "\n",
       "       [[31858.]],\n",
       "\n",
       "       [[32246.]],\n",
       "\n",
       "       [[34854.]],\n",
       "\n",
       "       [[38029.]],\n",
       "\n",
       "       [[39789.]],\n",
       "\n",
       "       [[40392.]],\n",
       "\n",
       "       [[39729.]],\n",
       "\n",
       "       [[34315.]],\n",
       "\n",
       "       [[34860.]],\n",
       "\n",
       "       [[34653.]],\n",
       "\n",
       "       [[38495.]],\n",
       "\n",
       "       [[37496.]],\n",
       "\n",
       "       [[36863.]],\n",
       "\n",
       "       [[35675.]],\n",
       "\n",
       "       [[36046.]],\n",
       "\n",
       "       [[36868.]],\n",
       "\n",
       "       [[35175.]],\n",
       "\n",
       "       [[32969.]],\n",
       "\n",
       "       [[31849.]],\n",
       "\n",
       "       [[32346.]],\n",
       "\n",
       "       [[32240.]],\n",
       "\n",
       "       [[33356.]],\n",
       "\n",
       "       [[32051.]],\n",
       "\n",
       "       [[31173.]],\n",
       "\n",
       "       [[31756.]],\n",
       "\n",
       "       [[35032.]],\n",
       "\n",
       "       [[34058.]],\n",
       "\n",
       "       [[33452.]],\n",
       "\n",
       "       [[33701.]],\n",
       "\n",
       "       [[34689.]],\n",
       "\n",
       "       [[36550.]],\n",
       "\n",
       "       [[37530.]],\n",
       "\n",
       "       [[37607.]],\n",
       "\n",
       "       [[39803.]],\n",
       "\n",
       "       [[38705.]],\n",
       "\n",
       "       [[40920.]],\n",
       "\n",
       "       [[46682.]],\n",
       "\n",
       "       [[45766.]],\n",
       "\n",
       "       [[46240.]],\n",
       "\n",
       "       [[47590.]],\n",
       "\n",
       "       [[47268.]],\n",
       "\n",
       "       [[48570.]],\n",
       "\n",
       "       [[47853.]],\n",
       "\n",
       "       [[48845.]],\n",
       "\n",
       "       [[50897.]],\n",
       "\n",
       "       [[51901.]],\n",
       "\n",
       "       [[53058.]],\n",
       "\n",
       "       [[56272.]],\n",
       "\n",
       "       [[57022.]],\n",
       "\n",
       "       [[54729.]],\n",
       "\n",
       "       [[48981.]],\n",
       "\n",
       "       [[49790.]],\n",
       "\n",
       "       [[49992.]],\n",
       "\n",
       "       [[46648.]],\n",
       "\n",
       "       [[47126.]],\n",
       "\n",
       "       [[44822.]],\n",
       "\n",
       "       [[47582.]],\n",
       "\n",
       "       [[48631.]],\n",
       "\n",
       "       [[50406.]],\n",
       "\n",
       "       [[49417.]],\n",
       "\n",
       "       [[47709.]],\n",
       "\n",
       "       [[48591.]],\n",
       "\n",
       "       [[50194.]],\n",
       "\n",
       "       [[50778.]],\n",
       "\n",
       "       [[53969.]],\n",
       "\n",
       "       [[55356.]],\n",
       "\n",
       "       [[56264.]],\n",
       "\n",
       "       [[56840.]],\n",
       "\n",
       "       [[58772.]],\n",
       "\n",
       "       [[60475.]],\n",
       "\n",
       "       [[57111.]],\n",
       "\n",
       "       [[55340.]],\n",
       "\n",
       "       [[56137.]],\n",
       "\n",
       "       [[58477.]],\n",
       "\n",
       "       [[58278.]],\n",
       "\n",
       "       [[58776.]],\n",
       "\n",
       "       [[57303.]],\n",
       "\n",
       "       [[56801.]],\n",
       "\n",
       "       [[54699.]],\n",
       "\n",
       "       [[55143.]],\n",
       "\n",
       "       [[52127.]],\n",
       "\n",
       "       [[53208.]],\n",
       "\n",
       "       [[55175.]],\n",
       "\n",
       "       [[55835.]],\n",
       "\n",
       "       [[56910.]],\n",
       "\n",
       "       [[58349.]],\n",
       "\n",
       "       [[58700.]],\n",
       "\n",
       "       [[58868.]],\n",
       "\n",
       "       [[59266.]],\n",
       "\n",
       "       [[58933.]],\n",
       "\n",
       "       [[57705.]],\n",
       "\n",
       "       [[58085.]],\n",
       "\n",
       "       [[58460.]],\n",
       "\n",
       "       [[56977.]],\n",
       "\n",
       "       [[57176.]],\n",
       "\n",
       "       [[58209.]],\n",
       "\n",
       "       [[59866.]],\n",
       "\n",
       "       [[59794.]],\n",
       "\n",
       "       [[60108.]],\n",
       "\n",
       "       [[62149.]],\n",
       "\n",
       "       [[63438.]],\n",
       "\n",
       "       [[62899.]],\n",
       "\n",
       "       [[61731.]],\n",
       "\n",
       "       [[61305.]],\n",
       "\n",
       "       [[56083.]],\n",
       "\n",
       "       [[56387.]],\n",
       "\n",
       "       [[55518.]],\n",
       "\n",
       "       [[55452.]],\n",
       "\n",
       "       [[53812.]],\n",
       "\n",
       "       [[49891.]],\n",
       "\n",
       "       [[50077.]],\n",
       "\n",
       "       [[49657.]],\n",
       "\n",
       "       [[53000.]],\n",
       "\n",
       "       [[54583.]],\n",
       "\n",
       "       [[54785.]],\n",
       "\n",
       "       [[53891.]],\n",
       "\n",
       "       [[55260.]],\n",
       "\n",
       "       [[57787.]],\n",
       "\n",
       "       [[56860.]],\n",
       "\n",
       "       [[57912.]],\n",
       "\n",
       "       [[55308.]],\n",
       "\n",
       "       [[55872.]],\n",
       "\n",
       "       [[56974.]],\n",
       "\n",
       "       [[56818.]],\n",
       "\n",
       "       [[58527.]],\n",
       "\n",
       "       [[57981.]],\n",
       "\n",
       "       [[57763.]],\n",
       "\n",
       "       [[55852.]],\n",
       "\n",
       "       [[55961.]],\n",
       "\n",
       "       [[49849.]],\n",
       "\n",
       "       [[50185.]],\n",
       "\n",
       "       [[48875.]],\n",
       "\n",
       "       [[47738.]],\n",
       "\n",
       "       [[44336.]],\n",
       "\n",
       "       [[44192.]],\n",
       "\n",
       "       [[39146.]],\n",
       "\n",
       "       [[39826.]],\n",
       "\n",
       "       [[39137.]],\n",
       "\n",
       "       [[37516.]],\n",
       "\n",
       "       [[35087.]],\n",
       "\n",
       "       [[37011.]],\n",
       "\n",
       "       [[38084.]],\n",
       "\n",
       "       [[39251.]],\n",
       "\n",
       "       [[38812.]],\n",
       "\n",
       "       [[36624.]],\n",
       "\n",
       "       [[35265.]],\n",
       "\n",
       "       [[35480.]],\n",
       "\n",
       "       [[36154.]],\n",
       "\n",
       "       [[36599.]],\n",
       "\n",
       "       [[37295.]],\n",
       "\n",
       "       [[38539.]],\n",
       "\n",
       "       [[37117.]],\n",
       "\n",
       "       [[36607.]],\n",
       "\n",
       "       [[35953.]],\n",
       "\n",
       "       [[35888.]],\n",
       "\n",
       "       [[32877.]],\n",
       "\n",
       "       [[34833.]],\n",
       "\n",
       "       [[36990.]],\n",
       "\n",
       "       [[36990.]],\n",
       "\n",
       "       [[35728.]],\n",
       "\n",
       "       [[36366.]],\n",
       "\n",
       "       [[39660.]],\n",
       "\n",
       "       [[40204.]],\n",
       "\n",
       "       [[39423.]],\n",
       "\n",
       "       [[38607.]],\n",
       "\n",
       "       [[37005.]],\n",
       "\n",
       "       [[35757.]],\n",
       "\n",
       "       [[35080.]],\n",
       "\n",
       "       [[33176.]],\n",
       "\n",
       "       [[32011.]],\n",
       "\n",
       "       [[33745.]],\n",
       "\n",
       "       [[33747.]],\n",
       "\n",
       "       [[33376.]],\n",
       "\n",
       "       [[31488.]],\n",
       "\n",
       "       [[33067.]],\n",
       "\n",
       "       [[34472.]],\n",
       "\n",
       "       [[35544.]],\n",
       "\n",
       "       [[34930.]],\n",
       "\n",
       "       [[33731.]],\n",
       "\n",
       "       [[33285.]],\n",
       "\n",
       "       [[34298.]],\n",
       "\n",
       "       [[35271.]],\n",
       "\n",
       "       [[34100.]],\n",
       "\n",
       "       [[34153.]],\n",
       "\n",
       "       [[34557.]],\n",
       "\n",
       "       [[32896.]],\n",
       "\n",
       "       [[33163.]],\n",
       "\n",
       "       [[33705.]],\n",
       "\n",
       "       [[33795.]],\n",
       "\n",
       "       [[33701.]],\n",
       "\n",
       "       [[32855.]],\n",
       "\n",
       "       [[32489.]],\n",
       "\n",
       "       [[32109.]],\n",
       "\n",
       "       [[31750.]],\n",
       "\n",
       "       [[31556.]],\n",
       "\n",
       "       [[31763.]],\n",
       "\n",
       "       [[31188.]],\n",
       "\n",
       "       [[29837.]],\n",
       "\n",
       "       [[31172.]],\n",
       "\n",
       "       [[32128.]],\n",
       "\n",
       "       [[32475.]],\n",
       "\n",
       "       [[33847.]],\n",
       "\n",
       "       [[34348.]],\n",
       "\n",
       "       [[38286.]],\n",
       "\n",
       "       [[37661.]],\n",
       "\n",
       "       [[39851.]],\n",
       "\n",
       "       [[39851.]],\n",
       "\n",
       "       [[39610.]],\n",
       "\n",
       "       [[41622.]],\n",
       "\n",
       "       [[41514.]],\n",
       "\n",
       "       [[39591.]],\n",
       "\n",
       "       [[38471.]],\n",
       "\n",
       "       [[38711.]],\n",
       "\n",
       "       [[39416.]],\n",
       "\n",
       "       [[41331.]],\n",
       "\n",
       "       [[43524.]],\n",
       "\n",
       "       [[44325.]],\n",
       "\n",
       "       [[44866.]],\n",
       "\n",
       "       [[45589.]],\n",
       "\n",
       "       [[46075.]],\n",
       "\n",
       "       [[44927.]],\n",
       "\n",
       "       [[46133.]],\n",
       "\n",
       "       [[47095.]],\n",
       "\n",
       "       [[46413.]],\n",
       "\n",
       "       [[46913.]],\n",
       "\n",
       "       [[45963.]],\n",
       "\n",
       "       [[45125.]],\n",
       "\n",
       "       [[45200.]],\n",
       "\n",
       "       [[47750.]],\n",
       "\n",
       "       [[49017.]],\n",
       "\n",
       "       [[48868.]],\n",
       "\n",
       "       [[49864.]],\n",
       "\n",
       "       [[48904.]],\n",
       "\n",
       "       [[48247.]],\n",
       "\n",
       "       [[47348.]],\n",
       "\n",
       "       [[47710.]],\n",
       "\n",
       "       [[48876.]],\n",
       "\n",
       "       [[48633.]],\n",
       "\n",
       "       [[48075.]],\n",
       "\n",
       "       [[47296.]],\n",
       "\n",
       "       [[47671.]],\n",
       "\n",
       "       [[49644.]],\n",
       "\n",
       "       [[49885.]],\n",
       "\n",
       "       [[50052.]],\n",
       "\n",
       "       [[50328.]],\n",
       "\n",
       "       [[51762.]],\n",
       "\n",
       "       [[49996.]],\n",
       "\n",
       "       [[46294.]],\n",
       "\n",
       "       [[46406.]],\n",
       "\n",
       "       [[45928.]],\n",
       "\n",
       "       [[45367.]],\n",
       "\n",
       "       [[45624.]],\n",
       "\n",
       "       [[44807.]],\n",
       "\n",
       "       [[46027.]],\n",
       "\n",
       "       [[47555.]],\n",
       "\n",
       "       [[47895.]],\n",
       "\n",
       "       [[47571.]],\n",
       "\n",
       "       [[48211.]],\n",
       "\n",
       "       [[47731.]],\n",
       "\n",
       "       [[44664.]],\n",
       "\n",
       "       [[42474.]],\n",
       "\n",
       "       [[42525.]],\n",
       "\n",
       "       [[44068.]],\n",
       "\n",
       "       [[43142.]],\n",
       "\n",
       "       [[42569.]],\n",
       "\n",
       "       [[42793.]],\n",
       "\n",
       "       [[43533.]],\n",
       "\n",
       "       [[41958.]],\n",
       "\n",
       "       [[41870.]],\n",
       "\n",
       "       [[43259.]],\n",
       "\n",
       "       [[45991.]],\n",
       "\n",
       "       [[47827.]],\n",
       "\n",
       "       [[48014.]],\n",
       "\n",
       "       [[48102.]],\n",
       "\n",
       "       [[49987.]],\n",
       "\n",
       "       [[52731.]],\n",
       "\n",
       "       [[54374.]],\n",
       "\n",
       "       [[54422.]],\n",
       "\n",
       "       [[54742.]],\n",
       "\n",
       "       [[55138.]],\n",
       "\n",
       "       [[56648.]],\n",
       "\n",
       "       [[56645.]],\n",
       "\n",
       "       [[56000.]],\n",
       "\n",
       "       [[57661.]],\n",
       "\n",
       "       [[59735.]],\n",
       "\n",
       "       [[61309.]],\n",
       "\n",
       "       [[60859.]],\n",
       "\n",
       "       [[61801.]],\n",
       "\n",
       "       [[62672.]],\n",
       "\n",
       "       [[64842.]],\n",
       "\n",
       "       [[64384.]],\n",
       "\n",
       "       [[62236.]],\n",
       "\n",
       "       [[61072.]],\n",
       "\n",
       "       [[60729.]],\n",
       "\n",
       "       [[62611.]],\n",
       "\n",
       "       [[62362.]],\n",
       "\n",
       "       [[59558.]],\n",
       "\n",
       "       [[60198.]],\n",
       "\n",
       "       [[61532.]],\n",
       "\n",
       "       [[61625.]],\n",
       "\n",
       "       [[61102.]],\n",
       "\n",
       "       [[61287.]],\n",
       "\n",
       "       [[62481.]],\n",
       "\n",
       "       [[62829.]],\n",
       "\n",
       "       [[61830.]],\n",
       "\n",
       "       [[61493.]],\n",
       "\n",
       "       [[60938.]],\n",
       "\n",
       "       [[62105.]],\n",
       "\n",
       "       [[65725.]],\n",
       "\n",
       "       [[67547.]],\n",
       "\n",
       "       [[66810.]],\n",
       "\n",
       "       [[64900.]],\n",
       "\n",
       "       [[64162.]],\n",
       "\n",
       "       [[64030.]],\n",
       "\n",
       "       [[64468.]],\n",
       "\n",
       "       [[65132.]],\n",
       "\n",
       "       [[60894.]],\n",
       "\n",
       "       [[59850.]],\n",
       "\n",
       "       [[59049.]],\n",
       "\n",
       "       [[57169.]],\n",
       "\n",
       "       [[58631.]],\n",
       "\n",
       "       [[59111.]],\n",
       "\n",
       "       [[57360.]],\n",
       "\n",
       "       [[56882.]],\n",
       "\n",
       "       [[56748.]],\n",
       "\n",
       "       [[58177.]],\n",
       "\n",
       "       [[55921.]],\n",
       "\n",
       "       [[54662.]],\n",
       "\n",
       "       [[54581.]],\n",
       "\n",
       "       [[57563.]],\n",
       "\n",
       "       [[57338.]],\n",
       "\n",
       "       [[57373.]],\n",
       "\n",
       "       [[56692.]],\n",
       "\n",
       "       [[55868.]],\n",
       "\n",
       "       [[49075.]],\n",
       "\n",
       "       [[49085.]],\n",
       "\n",
       "       [[48807.]],\n",
       "\n",
       "       [[50984.]],\n",
       "\n",
       "       [[50293.]],\n",
       "\n",
       "       [[49089.]],\n",
       "\n",
       "       [[48247.]],\n",
       "\n",
       "       [[48444.]],\n",
       "\n",
       "       [[49536.]],\n",
       "\n",
       "       [[48237.]],\n",
       "\n",
       "       [[47180.]],\n",
       "\n",
       "       [[48126.]],\n",
       "\n",
       "       [[48590.]],\n",
       "\n",
       "       [[47079.]],\n",
       "\n",
       "       [[46612.]],\n",
       "\n",
       "       [[47192.]],\n",
       "\n",
       "       [[46424.]],\n",
       "\n",
       "       [[48396.]],\n",
       "\n",
       "       [[48978.]],\n",
       "\n",
       "       [[49064.]],\n",
       "\n",
       "       [[51034.]],\n",
       "\n",
       "       [[50830.]],\n",
       "\n",
       "       [[50143.]],\n",
       "\n",
       "       [[51062.]],\n",
       "\n",
       "       [[48887.]],\n",
       "\n",
       "       [[47594.]],\n",
       "\n",
       "       [[47092.]],\n",
       "\n",
       "       [[47298.]],\n",
       "\n",
       "       [[47103.]],\n",
       "\n",
       "       [[47238.]],\n",
       "\n",
       "       [[46829.]],\n",
       "\n",
       "       [[46438.]],\n",
       "\n",
       "       [[45916.]],\n",
       "\n",
       "       [[43100.]],\n",
       "\n",
       "       [[42023.]],\n",
       "\n",
       "       [[41706.]],\n",
       "\n",
       "       [[41902.]],\n",
       "\n",
       "       [[41605.]],\n",
       "\n",
       "       [[42189.]],\n",
       "\n",
       "       [[43175.]],\n",
       "\n",
       "       [[43433.]],\n",
       "\n",
       "       [[42745.]],\n",
       "\n",
       "       [[43128.]],\n",
       "\n",
       "       [[43093.]],\n",
       "\n",
       "       [[42545.]],\n",
       "\n",
       "       [[41930.]],\n",
       "\n",
       "       [[41916.]],\n",
       "\n",
       "       [[42215.]],\n",
       "\n",
       "       [[38697.]],\n",
       "\n",
       "       [[35519.]],\n",
       "\n",
       "       [[35411.]],\n",
       "\n",
       "       [[35098.]],\n",
       "\n",
       "       [[36508.]],\n",
       "\n",
       "       [[37493.]],\n",
       "\n",
       "       [[36352.]],\n",
       "\n",
       "       [[37038.]],\n",
       "\n",
       "       [[37817.]],\n",
       "\n",
       "       [[37953.]],\n",
       "\n",
       "       [[37556.]],\n",
       "\n",
       "       [[38555.]],\n",
       "\n",
       "       [[38061.]],\n",
       "\n",
       "       [[36802.]],\n",
       "\n",
       "       [[38631.]],\n",
       "\n",
       "       [[41523.]],\n",
       "\n",
       "       [[41593.]],\n",
       "\n",
       "       [[43092.]],\n",
       "\n",
       "       [[43854.]],\n",
       "\n",
       "       [[43922.]],\n",
       "\n",
       "       [[44331.]],\n",
       "\n",
       "       [[43185.]],\n",
       "\n",
       "       [[42333.]],\n",
       "\n",
       "       [[42336.]],\n",
       "\n",
       "       [[42232.]],\n",
       "\n",
       "       [[43867.]],\n",
       "\n",
       "       [[43998.]],\n",
       "\n",
       "       [[42666.]],\n",
       "\n",
       "       [[40411.]],\n",
       "\n",
       "       [[40065.]],\n",
       "\n",
       "       [[38767.]],\n",
       "\n",
       "       [[38507.]],\n",
       "\n",
       "       [[37400.]],\n",
       "\n",
       "       [[38221.]],\n",
       "\n",
       "       [[36117.]],\n",
       "\n",
       "       [[38813.]],\n",
       "\n",
       "       [[39217.]],\n",
       "\n",
       "       [[38714.]],\n",
       "\n",
       "       [[39337.]],\n",
       "\n",
       "       [[43632.]],\n",
       "\n",
       "       [[44055.]],\n",
       "\n",
       "       [[43130.]],\n",
       "\n",
       "       [[40909.]],\n",
       "\n",
       "       [[39056.]],\n",
       "\n",
       "       [[38897.]],\n",
       "\n",
       "       [[38233.]],\n",
       "\n",
       "       [[38584.]],\n",
       "\n",
       "       [[41317.]],\n",
       "\n",
       "       [[39547.]],\n",
       "\n",
       "       [[38901.]],\n",
       "\n",
       "       [[38996.]],\n",
       "\n",
       "       [[38776.]],\n",
       "\n",
       "       [[38654.]],\n",
       "\n",
       "       [[38933.]],\n",
       "\n",
       "       [[40098.]],\n",
       "\n",
       "       [[40722.]],\n",
       "\n",
       "       [[40678.]],\n",
       "\n",
       "       [[41493.]],\n",
       "\n",
       "       [[41413.]],\n",
       "\n",
       "       [[41100.]],\n",
       "\n",
       "       [[42431.]],\n",
       "\n",
       "       [[42247.]],\n",
       "\n",
       "       [[43324.]],\n",
       "\n",
       "       [[44274.]],\n",
       "\n",
       "       [[44390.]],\n",
       "\n",
       "       [[44930.]],\n",
       "\n",
       "       [[47302.]],\n",
       "\n",
       "       [[47546.]],\n",
       "\n",
       "       [[47240.]],\n",
       "\n",
       "       [[46673.]],\n",
       "\n",
       "       [[45524.]],\n",
       "\n",
       "       [[46450.]],\n",
       "\n",
       "       [[46321.]],\n",
       "\n",
       "       [[46041.]],\n",
       "\n",
       "       [[46345.]],\n",
       "\n",
       "       [[44634.]],\n",
       "\n",
       "       [[43453.]],\n",
       "\n",
       "       [[43305.]],\n",
       "\n",
       "       [[42453.]],\n",
       "\n",
       "       [[42755.]],\n",
       "\n",
       "       [[41238.]],\n",
       "\n",
       "       [[39931.]],\n",
       "\n",
       "       [[40459.]],\n",
       "\n",
       "       [[40705.]],\n",
       "\n",
       "       [[40226.]],\n",
       "\n",
       "       [[40399.]],\n",
       "\n",
       "       [[40318.]],\n",
       "\n",
       "       [[39660.]],\n",
       "\n",
       "       [[41050.]],\n",
       "\n",
       "       [[41462.]],\n",
       "\n",
       "       [[41706.]],\n",
       "\n",
       "       [[40149.]],\n",
       "\n",
       "       [[39684.]],\n",
       "\n",
       "       [[39645.]],\n",
       "\n",
       "       [[39226.]],\n",
       "\n",
       "       [[39694.]],\n",
       "\n",
       "       [[38810.]],\n",
       "\n",
       "       [[39615.]],\n",
       "\n",
       "       [[39101.]],\n",
       "\n",
       "       [[38509.]],\n",
       "\n",
       "       [[38058.]],\n",
       "\n",
       "       [[38684.]],\n",
       "\n",
       "       [[38264.]],\n",
       "\n",
       "       [[38809.]],\n",
       "\n",
       "       [[38452.]],\n",
       "\n",
       "       [[36159.]],\n",
       "\n",
       "       [[35876.]],\n",
       "\n",
       "       [[34566.]],\n",
       "\n",
       "       [[32700.]],\n",
       "\n",
       "       [[31334.]],\n",
       "\n",
       "       [[30593.]],\n",
       "\n",
       "       [[28537.]],\n",
       "\n",
       "       [[30174.]],\n",
       "\n",
       "       [[29393.]],\n",
       "\n",
       "       [[30116.]],\n",
       "\n",
       "       [[29997.]],\n",
       "\n",
       "       [[30281.]],\n",
       "\n",
       "       [[29621.]],\n",
       "\n",
       "       [[29546.]],\n",
       "\n",
       "       [[29822.]],\n",
       "\n",
       "       [[29343.]],\n",
       "\n",
       "       [[29797.]],\n",
       "\n",
       "       [[30108.]],\n",
       "\n",
       "       [[29312.]],\n",
       "\n",
       "       [[29758.]],\n",
       "\n",
       "       [[29457.]],\n",
       "\n",
       "       [[28904.]]], dtype=float32)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 223
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.925074Z",
     "start_time": "2024-04-21T17:21:39.907063Z"
    }
   },
   "cell_type": "code",
   "source": "#X_train, X_test, y_train, y_test =train_test_split(X2,y2_reshaped, test_size=0.2, train_size=0.8, shuffle=False, random_state=8)",
   "outputs": [],
   "execution_count": 224
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.940295Z",
     "start_time": "2024-04-21T17:21:39.931283Z"
    }
   },
   "cell_type": "code",
   "source": "#X_train.shape[2]",
   "outputs": [],
   "execution_count": 225
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:39.955815Z",
     "start_time": "2024-04-21T17:21:39.952805Z"
    }
   },
   "cell_type": "code",
   "source": "#y_train.shape",
   "outputs": [],
   "execution_count": 226
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:40.017771Z",
     "start_time": "2024-04-21T17:21:40.004065Z"
    }
   },
   "cell_type": "code",
   "source": "#X_test.shape",
   "outputs": [],
   "execution_count": 227
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MVCJxdebqmOr"
   },
   "source": [
    "# **Model Architecture + Training**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:40.064808Z",
     "start_time": "2024-04-21T17:21:40.046297Z"
    }
   },
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ],
   "outputs": [],
   "execution_count": 228
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "NBZ9JgDTrHwV",
    "outputId": "40d0a5ca-682d-42d1-e08b-fd28df246868",
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:40.095242Z",
     "start_time": "2024-04-21T17:21:40.081456Z"
    }
   },
   "source": [
    "\n",
    "adam = optimizers.Adam(learning_rate=lr_schedule(0), amsgrad=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n"
     ]
    }
   ],
   "execution_count": 229
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:40.126116Z",
     "start_time": "2024-04-21T17:21:40.107776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ],
   "outputs": [],
   "execution_count": 230
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:40.265446Z",
     "start_time": "2024-04-21T17:21:40.130748Z"
    }
   },
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(350, return_sequences=True, activation='relu'), input_shape=(1, X_train.shape[2])))\n",
    "model.add(Bidirectional(LSTM(350, return_sequences=True, activation='relu')))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss=\"log_cosh\", optimizer=adam, metrics=['mae'])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\DS440proj\\BTCpred\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "execution_count": 231
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WWSdc7AxKV6",
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:40.280958Z",
     "start_time": "2024-04-21T17:21:40.266945Z"
    }
   },
   "source": [
    "mcp_save = ModelCheckpoint('LSTM_reg_18-21rmse355.keras', save_best_only=True, monitor='val_loss', mode='auto')\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=100, verbose=1, mode='auto')"
   ],
   "outputs": [],
   "execution_count": 232
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bIJPsArMr8cs",
    "outputId": "91137564-8bb8-496c-c827-829e240a789a",
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-04-21T17:25:25.899048Z",
     "start_time": "2024-04-21T17:21:40.282459Z"
    }
   },
   "source": [
    "#model.compile(optimizer='adam', loss='log_cosh', metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, epochs=5000, batch_size=32, validation_data=(X_test,y_test), callbacks=[mcp_save,earlyStopping])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 39ms/step - loss: 31110.5703 - mae: 31111.2637 - val_loss: 20485.0508 - val_mae: 20485.7441\n",
      "Epoch 2/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 31771.1934 - mae: 31771.8867 - val_loss: 20402.8809 - val_mae: 20403.5781\n",
      "Epoch 3/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 30596.3125 - mae: 30597.0039 - val_loss: 19994.1836 - val_mae: 19994.8789\n",
      "Epoch 4/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 29476.2148 - mae: 29476.9062 - val_loss: 18874.1152 - val_mae: 18874.8105\n",
      "Epoch 5/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 41ms/step - loss: 27475.4316 - mae: 27476.1250 - val_loss: 16339.9980 - val_mae: 16340.6904\n",
      "Epoch 6/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - loss: 21819.1895 - mae: 21819.8828 - val_loss: 11544.5488 - val_mae: 11545.2432\n",
      "Epoch 7/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - loss: 14015.1973 - mae: 14015.8896 - val_loss: 6207.8140 - val_mae: 6208.5078\n",
      "Epoch 8/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 41ms/step - loss: 10702.3887 - mae: 10703.0811 - val_loss: 4276.2549 - val_mae: 4276.9482\n",
      "Epoch 9/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - loss: 9756.2510 - mae: 9756.9443 - val_loss: 4249.2915 - val_mae: 4249.9849\n",
      "Epoch 10/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 9056.7109 - mae: 9057.4043 - val_loss: 4362.6118 - val_mae: 4363.3032\n",
      "Epoch 11/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 8363.2383 - mae: 8363.9307 - val_loss: 4359.5938 - val_mae: 4360.2876\n",
      "Epoch 12/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 7425.0664 - mae: 7425.7593 - val_loss: 4448.5825 - val_mae: 4449.2764\n",
      "Epoch 13/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 7142.6567 - mae: 7143.3501 - val_loss: 4819.9780 - val_mae: 4820.6709\n",
      "Epoch 14/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 6435.2598 - mae: 6435.9531 - val_loss: 4802.2358 - val_mae: 4802.9297\n",
      "Epoch 15/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 5862.9722 - mae: 5863.6655 - val_loss: 4920.3286 - val_mae: 4921.0215\n",
      "Epoch 16/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 5641.6475 - mae: 5642.3408 - val_loss: 4851.0718 - val_mae: 4851.7651\n",
      "Epoch 17/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 5070.6118 - mae: 5071.3052 - val_loss: 4851.5127 - val_mae: 4852.2056\n",
      "Epoch 18/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 4930.5752 - mae: 4931.2686 - val_loss: 4797.4326 - val_mae: 4798.1255\n",
      "Epoch 19/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 4788.9199 - mae: 4789.6133 - val_loss: 4820.7026 - val_mae: 4821.3960\n",
      "Epoch 20/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 4646.0005 - mae: 4646.6938 - val_loss: 4492.4702 - val_mae: 4493.1636\n",
      "Epoch 21/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 4278.1826 - mae: 4278.8765 - val_loss: 4468.8789 - val_mae: 4469.5723\n",
      "Epoch 22/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 4106.6880 - mae: 4107.3809 - val_loss: 4361.9482 - val_mae: 4362.6416\n",
      "Epoch 23/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 4008.6055 - mae: 4009.2991 - val_loss: 4266.2812 - val_mae: 4266.9746\n",
      "Epoch 24/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 3868.7832 - mae: 3869.4763 - val_loss: 4005.3215 - val_mae: 4006.0149\n",
      "Epoch 25/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 3742.5918 - mae: 3743.2849 - val_loss: 3900.5889 - val_mae: 3901.2817\n",
      "Epoch 26/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 3404.5088 - mae: 3405.2021 - val_loss: 4024.0239 - val_mae: 4024.7173\n",
      "Epoch 27/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 3508.2622 - mae: 3508.9553 - val_loss: 3562.6616 - val_mae: 3563.3552\n",
      "Epoch 28/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 3417.2861 - mae: 3417.9792 - val_loss: 3676.1819 - val_mae: 3676.8750\n",
      "Epoch 29/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 3266.1724 - mae: 3266.8652 - val_loss: 3613.8887 - val_mae: 3614.5818\n",
      "Epoch 30/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 3226.4316 - mae: 3227.1250 - val_loss: 3503.0398 - val_mae: 3503.7332\n",
      "Epoch 31/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 3173.9229 - mae: 3174.6155 - val_loss: 3531.0769 - val_mae: 3531.7703\n",
      "Epoch 32/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 3050.4397 - mae: 3051.1328 - val_loss: 3203.2461 - val_mae: 3203.9392\n",
      "Epoch 33/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 3016.1248 - mae: 3016.8181 - val_loss: 3240.7983 - val_mae: 3241.4915\n",
      "Epoch 34/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 2991.1914 - mae: 2991.8850 - val_loss: 3378.1592 - val_mae: 3378.8523\n",
      "Epoch 35/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 2825.8806 - mae: 2826.5730 - val_loss: 3130.3245 - val_mae: 3131.0176\n",
      "Epoch 36/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 2817.0151 - mae: 2817.7085 - val_loss: 3141.9734 - val_mae: 3142.6667\n",
      "Epoch 37/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 2610.5830 - mae: 2611.2761 - val_loss: 3012.6890 - val_mae: 3013.3823\n",
      "Epoch 38/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 2690.4590 - mae: 2691.1523 - val_loss: 3126.3091 - val_mae: 3127.0020\n",
      "Epoch 39/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 20ms/step - loss: 2594.7620 - mae: 2595.4548 - val_loss: 3112.2380 - val_mae: 3112.9312\n",
      "Epoch 40/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 2491.2349 - mae: 2491.9277 - val_loss: 3093.1191 - val_mae: 3093.8120\n",
      "Epoch 41/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 2640.3335 - mae: 2641.0269 - val_loss: 3016.8508 - val_mae: 3017.5444\n",
      "Epoch 42/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 41ms/step - loss: 2358.5876 - mae: 2359.2803 - val_loss: 2936.8508 - val_mae: 2937.5435\n",
      "Epoch 43/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 2394.9885 - mae: 2395.6816 - val_loss: 3204.4390 - val_mae: 3205.1323\n",
      "Epoch 44/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 2485.2893 - mae: 2485.9822 - val_loss: 3107.7659 - val_mae: 3108.4585\n",
      "Epoch 45/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 2331.6831 - mae: 2332.3765 - val_loss: 2959.0764 - val_mae: 2959.7693\n",
      "Epoch 46/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 42ms/step - loss: 2334.3088 - mae: 2335.0015 - val_loss: 2746.2046 - val_mae: 2746.8977\n",
      "Epoch 47/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 2217.0630 - mae: 2217.7561 - val_loss: 2869.2896 - val_mae: 2869.9824\n",
      "Epoch 48/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 2254.9324 - mae: 2255.6255 - val_loss: 3058.7234 - val_mae: 3059.4167\n",
      "Epoch 49/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 2237.2295 - mae: 2237.9226 - val_loss: 3059.9219 - val_mae: 3060.6150\n",
      "Epoch 50/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 2249.5679 - mae: 2250.2610 - val_loss: 2798.4373 - val_mae: 2799.1304\n",
      "Epoch 51/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 2042.2419 - mae: 2042.9349 - val_loss: 2769.5647 - val_mae: 2770.2581\n",
      "Epoch 52/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 2071.1470 - mae: 2071.8398 - val_loss: 2928.9294 - val_mae: 2929.6228\n",
      "Epoch 53/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 2036.5483 - mae: 2037.2416 - val_loss: 2865.3262 - val_mae: 2866.0190\n",
      "Epoch 54/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 1842.6611 - mae: 1843.3533 - val_loss: 2959.4417 - val_mae: 2960.1353\n",
      "Epoch 55/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 20ms/step - loss: 1953.9181 - mae: 1954.6112 - val_loss: 2806.1594 - val_mae: 2806.8525\n",
      "Epoch 56/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 1916.1873 - mae: 1916.8805 - val_loss: 2817.2705 - val_mae: 2817.9636\n",
      "Epoch 57/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 1967.9813 - mae: 1968.6744 - val_loss: 2851.0115 - val_mae: 2851.7046\n",
      "Epoch 58/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 1841.3755 - mae: 1842.0685 - val_loss: 2778.6880 - val_mae: 2779.3813\n",
      "Epoch 59/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 1833.9198 - mae: 1834.6127 - val_loss: 2671.3682 - val_mae: 2672.0613\n",
      "Epoch 60/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 1792.4496 - mae: 1793.1429 - val_loss: 2608.4033 - val_mae: 2609.0969\n",
      "Epoch 61/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 1788.6515 - mae: 1789.3446 - val_loss: 2887.6531 - val_mae: 2888.3459\n",
      "Epoch 62/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 1746.6378 - mae: 1747.3311 - val_loss: 2874.6426 - val_mae: 2875.3357\n",
      "Epoch 63/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 1548.4531 - mae: 1549.1460 - val_loss: 2744.5466 - val_mae: 2745.2400\n",
      "Epoch 64/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 1475.2433 - mae: 1475.9359 - val_loss: 2914.1621 - val_mae: 2914.8557\n",
      "Epoch 65/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 1502.2281 - mae: 1502.9213 - val_loss: 2359.5159 - val_mae: 2360.2090\n",
      "Epoch 66/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 1538.0887 - mae: 1538.7819 - val_loss: 2532.7339 - val_mae: 2533.4270\n",
      "Epoch 67/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 1561.5093 - mae: 1562.2021 - val_loss: 2642.9966 - val_mae: 2643.6897\n",
      "Epoch 68/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 1464.0468 - mae: 1464.7391 - val_loss: 2713.1262 - val_mae: 2713.8193\n",
      "Epoch 69/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 1433.1908 - mae: 1433.8840 - val_loss: 2617.0872 - val_mae: 2617.7805\n",
      "Epoch 70/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 1375.0385 - mae: 1375.7316 - val_loss: 2451.3711 - val_mae: 2452.0623\n",
      "Epoch 71/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 1341.3109 - mae: 1342.0035 - val_loss: 2256.9375 - val_mae: 2257.6306\n",
      "Epoch 72/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 1304.9357 - mae: 1305.6287 - val_loss: 2481.7336 - val_mae: 2482.4268\n",
      "Epoch 73/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 1253.8855 - mae: 1254.5773 - val_loss: 2360.7024 - val_mae: 2361.3955\n",
      "Epoch 74/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 1156.4553 - mae: 1157.1484 - val_loss: 2361.8635 - val_mae: 2362.5569\n",
      "Epoch 75/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 1266.6901 - mae: 1267.3832 - val_loss: 2197.3755 - val_mae: 2198.0688\n",
      "Epoch 76/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 1181.6062 - mae: 1182.2993 - val_loss: 2274.3066 - val_mae: 2275.0000\n",
      "Epoch 77/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 1221.8057 - mae: 1222.4987 - val_loss: 2376.4014 - val_mae: 2377.0945\n",
      "Epoch 78/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 1248.2855 - mae: 1248.9786 - val_loss: 1997.8119 - val_mae: 1998.5051\n",
      "Epoch 79/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 1080.6940 - mae: 1081.3870 - val_loss: 1979.6683 - val_mae: 1980.3613\n",
      "Epoch 80/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 1096.5979 - mae: 1097.2910 - val_loss: 2225.5886 - val_mae: 2226.2817\n",
      "Epoch 81/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 1086.6163 - mae: 1087.3091 - val_loss: 2114.0903 - val_mae: 2114.7832\n",
      "Epoch 82/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 1041.7205 - mae: 1042.4136 - val_loss: 1995.1787 - val_mae: 1995.8718\n",
      "Epoch 83/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 1014.6489 - mae: 1015.3409 - val_loss: 2108.8899 - val_mae: 2109.5830\n",
      "Epoch 84/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 1091.2797 - mae: 1091.9727 - val_loss: 1793.7379 - val_mae: 1794.4309\n",
      "Epoch 85/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 1031.0592 - mae: 1031.7522 - val_loss: 1779.6511 - val_mae: 1780.3441\n",
      "Epoch 86/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 1007.9827 - mae: 1008.6758 - val_loss: 1780.6006 - val_mae: 1781.2937\n",
      "Epoch 87/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 1062.2858 - mae: 1062.9789 - val_loss: 1890.8165 - val_mae: 1891.5095\n",
      "Epoch 88/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - loss: 997.2058 - mae: 997.8987 - val_loss: 1221.8513 - val_mae: 1222.5444\n",
      "Epoch 89/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 1028.6622 - mae: 1029.3552 - val_loss: 1492.4412 - val_mae: 1493.1344\n",
      "Epoch 90/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 960.8604 - mae: 961.5531 - val_loss: 1417.6014 - val_mae: 1418.2946\n",
      "Epoch 91/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 988.5655 - mae: 989.2582 - val_loss: 1692.9563 - val_mae: 1693.6492\n",
      "Epoch 92/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 982.0633 - mae: 982.7563 - val_loss: 1340.2085 - val_mae: 1340.9014\n",
      "Epoch 93/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 42ms/step - loss: 908.6229 - mae: 909.3154 - val_loss: 1081.0625 - val_mae: 1081.7556\n",
      "Epoch 94/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 895.3353 - mae: 896.0285 - val_loss: 1467.5410 - val_mae: 1468.2341\n",
      "Epoch 95/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 924.6314 - mae: 925.3235 - val_loss: 1212.2511 - val_mae: 1212.9442\n",
      "Epoch 96/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 892.0652 - mae: 892.7579 - val_loss: 1321.8452 - val_mae: 1322.5383\n",
      "Epoch 97/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 1027.5536 - mae: 1028.2465 - val_loss: 1183.8063 - val_mae: 1184.4994\n",
      "Epoch 98/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 872.9246 - mae: 873.6175 - val_loss: 1194.5626 - val_mae: 1195.2557\n",
      "Epoch 99/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 837.2605 - mae: 837.9537 - val_loss: 1150.4429 - val_mae: 1151.1360\n",
      "Epoch 100/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 826.2236 - mae: 826.9164 - val_loss: 996.9788 - val_mae: 997.6718\n",
      "Epoch 101/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 908.1266 - mae: 908.8193 - val_loss: 860.8861 - val_mae: 861.5782\n",
      "Epoch 102/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 874.8676 - mae: 875.5605 - val_loss: 1063.5265 - val_mae: 1064.2197\n",
      "Epoch 103/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 826.5609 - mae: 827.2532 - val_loss: 920.9688 - val_mae: 921.6618\n",
      "Epoch 104/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 858.4390 - mae: 859.1314 - val_loss: 838.0333 - val_mae: 838.7264\n",
      "Epoch 105/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 816.2957 - mae: 816.9879 - val_loss: 762.7308 - val_mae: 763.4239\n",
      "Epoch 106/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 803.2072 - mae: 803.8997 - val_loss: 696.3769 - val_mae: 697.0699\n",
      "Epoch 107/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 864.7835 - mae: 865.4766 - val_loss: 695.8932 - val_mae: 696.5864\n",
      "Epoch 108/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 817.0784 - mae: 817.7693 - val_loss: 724.6600 - val_mae: 725.3531\n",
      "Epoch 109/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 775.8732 - mae: 776.5664 - val_loss: 662.5856 - val_mae: 663.2788\n",
      "Epoch 110/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 774.7665 - mae: 775.4587 - val_loss: 615.3571 - val_mae: 616.0502\n",
      "Epoch 111/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 785.5140 - mae: 786.2069 - val_loss: 576.1235 - val_mae: 576.8167\n",
      "Epoch 112/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 814.2748 - mae: 814.9677 - val_loss: 528.7975 - val_mae: 529.4907\n",
      "Epoch 113/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 826.3925 - mae: 827.0857 - val_loss: 630.6744 - val_mae: 631.3675\n",
      "Epoch 114/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 796.2565 - mae: 796.9495 - val_loss: 674.1640 - val_mae: 674.8571\n",
      "Epoch 115/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 795.8603 - mae: 796.5533 - val_loss: 590.8389 - val_mae: 591.5310\n",
      "Epoch 116/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - loss: 764.0461 - mae: 764.7377 - val_loss: 528.4185 - val_mae: 529.1116\n",
      "Epoch 117/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - loss: 806.7391 - mae: 807.4322 - val_loss: 492.7114 - val_mae: 493.4041\n",
      "Epoch 118/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 759.4575 - mae: 760.1475 - val_loss: 540.6514 - val_mae: 541.3445\n",
      "Epoch 119/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 756.1091 - mae: 756.8011 - val_loss: 550.4474 - val_mae: 551.1405\n",
      "Epoch 120/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - loss: 818.9445 - mae: 819.6349 - val_loss: 422.4760 - val_mae: 423.1691\n",
      "Epoch 121/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 790.4323 - mae: 791.1252 - val_loss: 513.1499 - val_mae: 513.8430\n",
      "Epoch 122/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 799.7902 - mae: 800.4828 - val_loss: 671.9599 - val_mae: 672.6531\n",
      "Epoch 123/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - loss: 746.4152 - mae: 747.1082 - val_loss: 411.6415 - val_mae: 412.3347\n",
      "Epoch 124/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 814.3245 - mae: 815.0173 - val_loss: 496.6359 - val_mae: 497.3290\n",
      "Epoch 125/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 738.1578 - mae: 738.8494 - val_loss: 431.8737 - val_mae: 432.5661\n",
      "Epoch 126/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 737.3915 - mae: 738.0846 - val_loss: 447.5609 - val_mae: 448.2539\n",
      "Epoch 127/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 727.3904 - mae: 728.0823 - val_loss: 420.4084 - val_mae: 421.1015\n",
      "Epoch 128/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 803.0408 - mae: 803.7337 - val_loss: 451.4920 - val_mae: 452.1851\n",
      "Epoch 129/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 754.8869 - mae: 755.5796 - val_loss: 417.3863 - val_mae: 418.0785\n",
      "Epoch 130/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 750.2114 - mae: 750.9042 - val_loss: 409.5258 - val_mae: 410.2140\n",
      "Epoch 131/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 801.2161 - mae: 801.9080 - val_loss: 424.7537 - val_mae: 425.4464\n",
      "Epoch 132/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 834.2545 - mae: 834.9474 - val_loss: 450.4712 - val_mae: 451.1639\n",
      "Epoch 133/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 748.9371 - mae: 749.6302 - val_loss: 443.6050 - val_mae: 444.2982\n",
      "Epoch 134/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 27ms/step - loss: 742.9987 - mae: 743.6916 - val_loss: 390.2841 - val_mae: 390.9714\n",
      "Epoch 135/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 802.0325 - mae: 802.7249 - val_loss: 404.5226 - val_mae: 405.2157\n",
      "Epoch 136/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 731.7922 - mae: 732.4852 - val_loss: 410.2338 - val_mae: 410.9268\n",
      "Epoch 137/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 762.5573 - mae: 763.2487 - val_loss: 466.7154 - val_mae: 467.4085\n",
      "Epoch 138/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 775.2537 - mae: 775.9458 - val_loss: 398.5287 - val_mae: 399.2203\n",
      "Epoch 139/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 791.4382 - mae: 792.1312 - val_loss: 394.4872 - val_mae: 395.1801\n",
      "Epoch 140/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 775.5761 - mae: 776.2692 - val_loss: 413.6454 - val_mae: 414.3354\n",
      "Epoch 141/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 762.2575 - mae: 762.9503 - val_loss: 395.5181 - val_mae: 396.2095\n",
      "Epoch 142/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 801.7206 - mae: 802.4138 - val_loss: 419.3824 - val_mae: 420.0723\n",
      "Epoch 143/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 766.9888 - mae: 767.6798 - val_loss: 406.2841 - val_mae: 406.9772\n",
      "Epoch 144/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 705.2176 - mae: 705.9104 - val_loss: 387.0182 - val_mae: 387.7112\n",
      "Epoch 145/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 746.1851 - mae: 746.8779 - val_loss: 385.2797 - val_mae: 385.9727\n",
      "Epoch 146/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 707.1527 - mae: 707.8456 - val_loss: 380.4657 - val_mae: 381.1589\n",
      "Epoch 147/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 725.0521 - mae: 725.7453 - val_loss: 562.9957 - val_mae: 563.6889\n",
      "Epoch 148/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 848.4928 - mae: 849.1848 - val_loss: 390.7121 - val_mae: 391.4052\n",
      "Epoch 149/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 776.8951 - mae: 777.5880 - val_loss: 387.5855 - val_mae: 388.2784\n",
      "Epoch 150/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 715.0519 - mae: 715.7444 - val_loss: 396.8214 - val_mae: 397.5131\n",
      "Epoch 151/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 765.0158 - mae: 765.7087 - val_loss: 402.1227 - val_mae: 402.8147\n",
      "Epoch 152/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 732.2689 - mae: 732.9620 - val_loss: 386.8570 - val_mae: 387.5500\n",
      "Epoch 153/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 732.3547 - mae: 733.0467 - val_loss: 419.6848 - val_mae: 420.3740\n",
      "Epoch 154/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 741.0932 - mae: 741.7864 - val_loss: 391.3217 - val_mae: 392.0148\n",
      "Epoch 155/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 742.4428 - mae: 743.1356 - val_loss: 385.7912 - val_mae: 386.4808\n",
      "Epoch 156/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 748.5826 - mae: 749.2758 - val_loss: 410.0394 - val_mae: 410.7315\n",
      "Epoch 157/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 775.1812 - mae: 775.8735 - val_loss: 379.7927 - val_mae: 380.4857\n",
      "Epoch 158/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 731.8824 - mae: 732.5756 - val_loss: 446.8656 - val_mae: 447.5587\n",
      "Epoch 159/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 808.5517 - mae: 809.2440 - val_loss: 378.5891 - val_mae: 379.2812\n",
      "Epoch 160/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 778.9258 - mae: 779.6187 - val_loss: 393.6266 - val_mae: 394.3174\n",
      "Epoch 161/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 719.2366 - mae: 719.9296 - val_loss: 382.0265 - val_mae: 382.7196\n",
      "Epoch 162/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 744.6382 - mae: 745.3306 - val_loss: 376.3655 - val_mae: 377.0581\n",
      "Epoch 163/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 772.4445 - mae: 773.1368 - val_loss: 446.3576 - val_mae: 447.0508\n",
      "Epoch 164/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 808.8479 - mae: 809.5398 - val_loss: 376.5976 - val_mae: 377.2903\n",
      "Epoch 165/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 20ms/step - loss: 706.5790 - mae: 707.2718 - val_loss: 378.0866 - val_mae: 378.7775\n",
      "Epoch 166/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 759.4352 - mae: 760.1268 - val_loss: 386.1382 - val_mae: 386.8304\n",
      "Epoch 167/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 748.8318 - mae: 749.5231 - val_loss: 376.4397 - val_mae: 377.1328\n",
      "Epoch 168/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 761.7581 - mae: 762.4503 - val_loss: 377.9329 - val_mae: 378.6261\n",
      "Epoch 169/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 731.4614 - mae: 732.1542 - val_loss: 375.7527 - val_mae: 376.4458\n",
      "Epoch 170/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 732.7225 - mae: 733.4141 - val_loss: 436.9834 - val_mae: 437.6766\n",
      "Epoch 171/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 692.2066 - mae: 692.8997 - val_loss: 376.3549 - val_mae: 377.0467\n",
      "Epoch 172/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 713.5305 - mae: 714.2233 - val_loss: 374.9601 - val_mae: 375.6532\n",
      "Epoch 173/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 697.9957 - mae: 698.6882 - val_loss: 505.6827 - val_mae: 506.3759\n",
      "Epoch 174/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 762.0065 - mae: 762.6996 - val_loss: 402.9312 - val_mae: 403.6233\n",
      "Epoch 175/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 782.8064 - mae: 783.4995 - val_loss: 376.6387 - val_mae: 377.3299\n",
      "Epoch 176/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 722.2566 - mae: 722.9496 - val_loss: 378.3722 - val_mae: 379.0650\n",
      "Epoch 177/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 699.0715 - mae: 699.7646 - val_loss: 394.6117 - val_mae: 395.3047\n",
      "Epoch 178/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 738.2577 - mae: 738.9489 - val_loss: 396.0482 - val_mae: 396.7408\n",
      "Epoch 179/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 710.3084 - mae: 710.9999 - val_loss: 385.3415 - val_mae: 386.0346\n",
      "Epoch 180/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 701.4747 - mae: 702.1673 - val_loss: 386.9563 - val_mae: 387.6493\n",
      "Epoch 181/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 699.4322 - mae: 700.1250 - val_loss: 375.9375 - val_mae: 376.6281\n",
      "Epoch 182/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 744.3984 - mae: 745.0908 - val_loss: 385.0948 - val_mae: 385.7867\n",
      "Epoch 183/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 716.1696 - mae: 716.8623 - val_loss: 403.1851 - val_mae: 403.8770\n",
      "Epoch 184/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 794.2117 - mae: 794.9044 - val_loss: 389.9663 - val_mae: 390.6570\n",
      "Epoch 185/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 770.1111 - mae: 770.8032 - val_loss: 421.2460 - val_mae: 421.9382\n",
      "Epoch 186/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 740.1697 - mae: 740.8626 - val_loss: 375.8286 - val_mae: 376.5202\n",
      "Epoch 187/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 745.8865 - mae: 746.5775 - val_loss: 527.5734 - val_mae: 528.2664\n",
      "Epoch 188/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 779.5453 - mae: 780.2380 - val_loss: 379.9729 - val_mae: 380.6661\n",
      "Epoch 189/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 756.1177 - mae: 756.8091 - val_loss: 417.6493 - val_mae: 418.3416\n",
      "Epoch 190/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 759.2665 - mae: 759.9576 - val_loss: 387.2862 - val_mae: 387.9774\n",
      "Epoch 191/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 706.4078 - mae: 707.1006 - val_loss: 376.8133 - val_mae: 377.5048\n",
      "Epoch 192/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 745.7188 - mae: 746.4116 - val_loss: 384.7993 - val_mae: 385.4898\n",
      "Epoch 193/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 748.7061 - mae: 749.3981 - val_loss: 386.3956 - val_mae: 387.0887\n",
      "Epoch 194/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 687.5554 - mae: 688.2480 - val_loss: 395.1641 - val_mae: 395.8572\n",
      "Epoch 195/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 712.9613 - mae: 713.6531 - val_loss: 385.9624 - val_mae: 386.6553\n",
      "Epoch 196/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 20ms/step - loss: 744.8708 - mae: 745.5637 - val_loss: 391.5624 - val_mae: 392.2526\n",
      "Epoch 197/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 761.0439 - mae: 761.7359 - val_loss: 417.1536 - val_mae: 417.8468\n",
      "Epoch 198/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 796.0075 - mae: 796.7003 - val_loss: 396.3144 - val_mae: 397.0074\n",
      "Epoch 199/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 714.1382 - mae: 714.8302 - val_loss: 392.6779 - val_mae: 393.3693\n",
      "Epoch 200/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 724.0576 - mae: 724.7506 - val_loss: 387.5038 - val_mae: 388.1955\n",
      "Epoch 201/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 760.7665 - mae: 761.4597 - val_loss: 372.3573 - val_mae: 373.0487\n",
      "Epoch 202/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 753.1586 - mae: 753.8517 - val_loss: 423.2165 - val_mae: 423.9097\n",
      "Epoch 203/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 768.0735 - mae: 768.7664 - val_loss: 400.2934 - val_mae: 400.9866\n",
      "Epoch 204/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 749.9027 - mae: 750.5956 - val_loss: 389.8604 - val_mae: 390.5536\n",
      "Epoch 205/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 733.1622 - mae: 733.8516 - val_loss: 399.8240 - val_mae: 400.5154\n",
      "Epoch 206/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 700.0361 - mae: 700.7292 - val_loss: 379.0278 - val_mae: 379.7209\n",
      "Epoch 207/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 728.8531 - mae: 729.5462 - val_loss: 386.5567 - val_mae: 387.2498\n",
      "Epoch 208/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 705.5367 - mae: 706.2294 - val_loss: 403.6756 - val_mae: 404.3666\n",
      "Epoch 209/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 706.4126 - mae: 707.1055 - val_loss: 372.6868 - val_mae: 373.3798\n",
      "Epoch 210/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 733.7403 - mae: 734.4306 - val_loss: 387.0536 - val_mae: 387.7463\n",
      "Epoch 211/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 749.3039 - mae: 749.9965 - val_loss: 387.8853 - val_mae: 388.5757\n",
      "Epoch 212/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 677.2848 - mae: 677.9778 - val_loss: 373.1778 - val_mae: 373.8708\n",
      "Epoch 213/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 698.2683 - mae: 698.9600 - val_loss: 373.3549 - val_mae: 374.0480\n",
      "Epoch 214/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 716.6199 - mae: 717.3122 - val_loss: 414.0919 - val_mae: 414.7848\n",
      "Epoch 215/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 788.4788 - mae: 789.1702 - val_loss: 375.8466 - val_mae: 376.5352\n",
      "Epoch 216/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 704.9141 - mae: 705.6052 - val_loss: 376.4224 - val_mae: 377.1129\n",
      "Epoch 217/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 698.6874 - mae: 699.3806 - val_loss: 378.1207 - val_mae: 378.8132\n",
      "Epoch 218/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 712.8306 - mae: 713.5216 - val_loss: 394.8362 - val_mae: 395.5285\n",
      "Epoch 219/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 761.3691 - mae: 762.0612 - val_loss: 400.3852 - val_mae: 401.0757\n",
      "Epoch 220/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 694.0887 - mae: 694.7797 - val_loss: 374.1973 - val_mae: 374.8902\n",
      "Epoch 221/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 747.8754 - mae: 748.5682 - val_loss: 375.0800 - val_mae: 375.7728\n",
      "Epoch 222/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 759.4088 - mae: 760.1002 - val_loss: 452.9072 - val_mae: 453.6001\n",
      "Epoch 223/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 750.5997 - mae: 751.2928 - val_loss: 429.3876 - val_mae: 430.0799\n",
      "Epoch 224/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 761.8538 - mae: 762.5462 - val_loss: 461.0449 - val_mae: 461.7377\n",
      "Epoch 225/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 775.9481 - mae: 776.6412 - val_loss: 395.0286 - val_mae: 395.7183\n",
      "Epoch 226/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 708.1406 - mae: 708.8335 - val_loss: 440.8176 - val_mae: 441.5107\n",
      "Epoch 227/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 709.0031 - mae: 709.6959 - val_loss: 371.6347 - val_mae: 372.3277\n",
      "Epoch 228/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 697.1052 - mae: 697.7983 - val_loss: 381.7690 - val_mae: 382.4617\n",
      "Epoch 229/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 719.3075 - mae: 719.9996 - val_loss: 383.7565 - val_mae: 384.4495\n",
      "Epoch 230/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 751.4218 - mae: 752.1140 - val_loss: 388.2383 - val_mae: 388.9289\n",
      "Epoch 231/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 757.8789 - mae: 758.5718 - val_loss: 397.3935 - val_mae: 398.0864\n",
      "Epoch 232/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 737.6908 - mae: 738.3832 - val_loss: 379.8742 - val_mae: 380.5674\n",
      "Epoch 233/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 20ms/step - loss: 756.4942 - mae: 757.1866 - val_loss: 408.4154 - val_mae: 409.1079\n",
      "Epoch 234/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 748.2269 - mae: 748.9193 - val_loss: 391.2215 - val_mae: 391.9146\n",
      "Epoch 235/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 735.3626 - mae: 736.0557 - val_loss: 370.5322 - val_mae: 371.2238\n",
      "Epoch 236/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 685.2633 - mae: 685.9558 - val_loss: 370.3529 - val_mae: 371.0428\n",
      "Epoch 237/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 746.9947 - mae: 747.6874 - val_loss: 370.4015 - val_mae: 371.0935\n",
      "Epoch 238/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 667.9734 - mae: 668.6665 - val_loss: 373.4549 - val_mae: 374.1477\n",
      "Epoch 239/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 690.6658 - mae: 691.3558 - val_loss: 372.9218 - val_mae: 373.6149\n",
      "Epoch 240/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 707.2084 - mae: 707.8990 - val_loss: 473.1563 - val_mae: 473.8495\n",
      "Epoch 241/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 20ms/step - loss: 760.0920 - mae: 760.7850 - val_loss: 378.9024 - val_mae: 379.5925\n",
      "Epoch 242/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 708.3176 - mae: 709.0091 - val_loss: 465.3382 - val_mae: 466.0313\n",
      "Epoch 243/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 761.4907 - mae: 762.1829 - val_loss: 406.4790 - val_mae: 407.1721\n",
      "Epoch 244/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 710.5505 - mae: 711.2418 - val_loss: 399.2858 - val_mae: 399.9789\n",
      "Epoch 245/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 727.7355 - mae: 728.4283 - val_loss: 406.6940 - val_mae: 407.3867\n",
      "Epoch 246/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 742.3909 - mae: 743.0819 - val_loss: 390.4319 - val_mae: 391.1228\n",
      "Epoch 247/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 703.7016 - mae: 704.3930 - val_loss: 383.5799 - val_mae: 384.2730\n",
      "Epoch 248/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 717.5071 - mae: 718.1990 - val_loss: 382.0345 - val_mae: 382.7273\n",
      "Epoch 249/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 738.2689 - mae: 738.9603 - val_loss: 477.1580 - val_mae: 477.8511\n",
      "Epoch 250/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 799.8801 - mae: 800.5731 - val_loss: 375.1248 - val_mae: 375.8170\n",
      "Epoch 251/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 746.4205 - mae: 747.1127 - val_loss: 414.7894 - val_mae: 415.4807\n",
      "Epoch 252/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 692.4316 - mae: 693.1246 - val_loss: 471.8995 - val_mae: 472.5905\n",
      "Epoch 253/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 703.8242 - mae: 704.5164 - val_loss: 396.0602 - val_mae: 396.7533\n",
      "Epoch 254/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 709.2485 - mae: 709.9412 - val_loss: 381.4456 - val_mae: 382.1387\n",
      "Epoch 255/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 685.2563 - mae: 685.9487 - val_loss: 434.0344 - val_mae: 434.7274\n",
      "Epoch 256/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 654.1291 - mae: 654.8221 - val_loss: 391.8612 - val_mae: 392.5520\n",
      "Epoch 257/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 709.8488 - mae: 710.5417 - val_loss: 593.3744 - val_mae: 594.0658\n",
      "Epoch 258/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 799.7114 - mae: 800.4042 - val_loss: 411.2048 - val_mae: 411.8979\n",
      "Epoch 259/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 725.4926 - mae: 726.1841 - val_loss: 465.5713 - val_mae: 466.2645\n",
      "Epoch 260/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 714.1157 - mae: 714.8086 - val_loss: 389.5516 - val_mae: 390.2436\n",
      "Epoch 261/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 779.7163 - mae: 780.4084 - val_loss: 378.0529 - val_mae: 378.7446\n",
      "Epoch 262/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 740.8433 - mae: 741.5358 - val_loss: 412.2307 - val_mae: 412.9238\n",
      "Epoch 263/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 720.0121 - mae: 720.7051 - val_loss: 381.2227 - val_mae: 381.9141\n",
      "Epoch 264/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 686.4650 - mae: 687.1581 - val_loss: 382.4593 - val_mae: 383.1523\n",
      "Epoch 265/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 718.3508 - mae: 719.0430 - val_loss: 400.3746 - val_mae: 401.0647\n",
      "Epoch 266/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 755.4189 - mae: 756.1118 - val_loss: 372.3448 - val_mae: 373.0378\n",
      "Epoch 267/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 709.6673 - mae: 710.3586 - val_loss: 422.5781 - val_mae: 423.2712\n",
      "Epoch 268/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 712.9908 - mae: 713.6838 - val_loss: 382.0784 - val_mae: 382.7715\n",
      "Epoch 269/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 717.6154 - mae: 718.3084 - val_loss: 391.9252 - val_mae: 392.6142\n",
      "Epoch 270/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 723.6464 - mae: 724.3394 - val_loss: 412.8647 - val_mae: 413.5577\n",
      "Epoch 271/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 747.1184 - mae: 747.8079 - val_loss: 380.2810 - val_mae: 380.9741\n",
      "Epoch 272/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 717.6795 - mae: 718.3721 - val_loss: 414.2539 - val_mae: 414.9471\n",
      "Epoch 273/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 719.5148 - mae: 720.2062 - val_loss: 424.9688 - val_mae: 425.6613\n",
      "Epoch 274/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 700.6659 - mae: 701.3575 - val_loss: 427.7478 - val_mae: 428.4388\n",
      "Epoch 275/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 682.3687 - mae: 683.0615 - val_loss: 425.5323 - val_mae: 426.2223\n",
      "Epoch 276/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 724.3803 - mae: 725.0733 - val_loss: 434.4570 - val_mae: 435.1501\n",
      "Epoch 277/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 716.4151 - mae: 717.1053 - val_loss: 406.0332 - val_mae: 406.7263\n",
      "Epoch 278/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 671.4471 - mae: 672.1378 - val_loss: 448.4601 - val_mae: 449.1516\n",
      "Epoch 279/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 758.0626 - mae: 758.7555 - val_loss: 420.2391 - val_mae: 420.9292\n",
      "Epoch 280/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 667.6005 - mae: 668.2925 - val_loss: 381.4796 - val_mae: 382.1728\n",
      "Epoch 281/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 702.6003 - mae: 703.2933 - val_loss: 372.8456 - val_mae: 373.5368\n",
      "Epoch 282/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 762.6126 - mae: 763.3055 - val_loss: 379.9903 - val_mae: 380.6820\n",
      "Epoch 283/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 692.4454 - mae: 693.1380 - val_loss: 416.8339 - val_mae: 417.5271\n",
      "Epoch 284/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 726.1190 - mae: 726.8115 - val_loss: 376.9665 - val_mae: 377.6595\n",
      "Epoch 285/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 676.8160 - mae: 677.5089 - val_loss: 474.1024 - val_mae: 474.7956\n",
      "Epoch 286/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 736.7550 - mae: 737.4480 - val_loss: 386.2802 - val_mae: 386.9714\n",
      "Epoch 287/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 739.5104 - mae: 740.2034 - val_loss: 396.4366 - val_mae: 397.1275\n",
      "Epoch 288/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 754.7097 - mae: 755.4021 - val_loss: 441.6985 - val_mae: 442.3917\n",
      "Epoch 289/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 681.1671 - mae: 681.8602 - val_loss: 390.7412 - val_mae: 391.4339\n",
      "Epoch 290/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 715.4814 - mae: 716.1737 - val_loss: 406.8038 - val_mae: 407.4968\n",
      "Epoch 291/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 682.2913 - mae: 682.9843 - val_loss: 441.4180 - val_mae: 442.1112\n",
      "Epoch 292/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 752.9591 - mae: 753.6506 - val_loss: 374.7160 - val_mae: 375.4089\n",
      "Epoch 293/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 710.0856 - mae: 710.7774 - val_loss: 494.8963 - val_mae: 495.5894\n",
      "Epoch 294/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 748.0602 - mae: 748.7532 - val_loss: 372.0378 - val_mae: 372.7308\n",
      "Epoch 295/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 732.9400 - mae: 733.6330 - val_loss: 374.1151 - val_mae: 374.8082\n",
      "Epoch 296/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 714.3892 - mae: 715.0798 - val_loss: 400.2794 - val_mae: 400.9723\n",
      "Epoch 297/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 701.1603 - mae: 701.8528 - val_loss: 371.7203 - val_mae: 372.4133\n",
      "Epoch 298/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 711.4621 - mae: 712.1552 - val_loss: 390.8806 - val_mae: 391.5728\n",
      "Epoch 299/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 676.8748 - mae: 677.5657 - val_loss: 496.4034 - val_mae: 497.0963\n",
      "Epoch 300/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 728.4805 - mae: 729.1725 - val_loss: 483.4254 - val_mae: 484.1185\n",
      "Epoch 301/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 769.3141 - mae: 770.0071 - val_loss: 422.1293 - val_mae: 422.8222\n",
      "Epoch 302/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 737.8942 - mae: 738.5851 - val_loss: 377.2365 - val_mae: 377.9292\n",
      "Epoch 303/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 711.3635 - mae: 712.0563 - val_loss: 432.3791 - val_mae: 433.0722\n",
      "Epoch 304/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 742.3219 - mae: 743.0147 - val_loss: 384.3341 - val_mae: 385.0261\n",
      "Epoch 305/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 732.4214 - mae: 733.1139 - val_loss: 400.6551 - val_mae: 401.3482\n",
      "Epoch 306/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 749.1898 - mae: 749.8817 - val_loss: 428.1007 - val_mae: 428.7938\n",
      "Epoch 307/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 700.3831 - mae: 701.0760 - val_loss: 392.2314 - val_mae: 392.9191\n",
      "Epoch 308/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 710.6905 - mae: 711.3821 - val_loss: 460.9074 - val_mae: 461.6006\n",
      "Epoch 309/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 747.4775 - mae: 748.1689 - val_loss: 388.6960 - val_mae: 389.3889\n",
      "Epoch 310/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 725.0074 - mae: 725.7004 - val_loss: 373.3016 - val_mae: 373.9926\n",
      "Epoch 311/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 733.5262 - mae: 734.2193 - val_loss: 421.6187 - val_mae: 422.3118\n",
      "Epoch 312/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 687.0614 - mae: 687.7545 - val_loss: 465.2118 - val_mae: 465.9047\n",
      "Epoch 313/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 752.5268 - mae: 753.2200 - val_loss: 394.8109 - val_mae: 395.5041\n",
      "Epoch 314/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 723.0417 - mae: 723.7347 - val_loss: 403.7703 - val_mae: 404.4633\n",
      "Epoch 315/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 717.1285 - mae: 717.8214 - val_loss: 390.2174 - val_mae: 390.9094\n",
      "Epoch 316/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 728.7104 - mae: 729.4034 - val_loss: 459.6398 - val_mae: 460.3329\n",
      "Epoch 317/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 723.2772 - mae: 723.9694 - val_loss: 380.9785 - val_mae: 381.6714\n",
      "Epoch 318/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 734.5205 - mae: 735.2125 - val_loss: 375.9878 - val_mae: 376.6755\n",
      "Epoch 319/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 704.1355 - mae: 704.8285 - val_loss: 424.7946 - val_mae: 425.4877\n",
      "Epoch 320/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 704.4274 - mae: 705.1180 - val_loss: 434.8174 - val_mae: 435.5106\n",
      "Epoch 321/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 705.8655 - mae: 706.5585 - val_loss: 378.0039 - val_mae: 378.6971\n",
      "Epoch 322/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 765.9293 - mae: 766.6223 - val_loss: 384.7387 - val_mae: 385.4258\n",
      "Epoch 323/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 742.8367 - mae: 743.5295 - val_loss: 412.7739 - val_mae: 413.4669\n",
      "Epoch 324/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 729.9476 - mae: 730.6403 - val_loss: 426.4655 - val_mae: 427.1586\n",
      "Epoch 325/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 711.6534 - mae: 712.3455 - val_loss: 408.4341 - val_mae: 409.1271\n",
      "Epoch 326/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 680.6193 - mae: 681.3091 - val_loss: 379.4074 - val_mae: 380.0975\n",
      "Epoch 327/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 753.6503 - mae: 754.3432 - val_loss: 376.3355 - val_mae: 377.0280\n",
      "Epoch 328/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 744.5544 - mae: 745.2452 - val_loss: 416.7925 - val_mae: 417.4817\n",
      "Epoch 329/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 691.9982 - mae: 692.6902 - val_loss: 389.7246 - val_mae: 390.4140\n",
      "Epoch 330/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 748.2223 - mae: 748.9145 - val_loss: 427.7270 - val_mae: 428.4201\n",
      "Epoch 331/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 745.4866 - mae: 746.1782 - val_loss: 447.3599 - val_mae: 448.0530\n",
      "Epoch 332/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 680.6977 - mae: 681.3897 - val_loss: 410.0391 - val_mae: 410.7293\n",
      "Epoch 333/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 756.9305 - mae: 757.6230 - val_loss: 386.6426 - val_mae: 387.3356\n",
      "Epoch 334/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 822.8395 - mae: 823.5319 - val_loss: 397.2989 - val_mae: 397.9920\n",
      "Epoch 335/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 715.7333 - mae: 716.4260 - val_loss: 375.9382 - val_mae: 376.6297\n",
      "Epoch 336/5000\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 664.8024 - mae: 665.4932 - val_loss: 384.5208 - val_mae: 385.2131\n",
      "Epoch 336: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1831f9382e0>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 233
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LRZ1nHe0Gjy5"
   },
   "source": [
    "# **Testing Model**"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:25:25.914246Z",
     "start_time": "2024-04-21T17:25:25.901051Z"
    }
   },
   "cell_type": "code",
   "source": "#model.save('LSTM_complete_model344.h5', overwrite=True)",
   "outputs": [],
   "execution_count": 234
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qyAUCY0FGwsM",
    "ExecuteTime": {
     "end_time": "2024-04-21T17:25:25.929762Z",
     "start_time": "2024-04-21T17:25:25.915247Z"
    }
   },
   "source": [
    "#from tensorflow.keras.models import load_model\n",
    "#loaded_model = load_model('LSTM_complete_model344.h5')"
   ],
   "outputs": [],
   "execution_count": 235
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:25:25.945235Z",
     "start_time": "2024-04-21T17:25:25.931262Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 235
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "lT71_QwcHEof",
    "outputId": "674692de-7a3b-4e60-addc-39ce1d9a328d",
    "ExecuteTime": {
     "end_time": "2024-04-21T17:25:26.456567Z",
     "start_time": "2024-04-21T17:25:25.946412Z"
    }
   },
   "source": "y_pred = np.ravel(model.predict(X_test))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n"
     ]
    }
   ],
   "execution_count": 236
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:25:26.472178Z",
     "start_time": "2024-04-21T17:25:26.458176Z"
    }
   },
   "source": [
    "y_test=np.ravel(y_test)"
   ],
   "outputs": [],
   "execution_count": 237
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:25:26.488271Z",
     "start_time": "2024-04-21T17:25:26.473178Z"
    }
   },
   "cell_type": "code",
   "source": "y_pred",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28962.758, 28909.299, 29178.941, 30571.6  , 31794.377, 31091.182,\n",
       "       29843.54 , 29689.084, 29321.684, 29629.137, 31115.791, 29803.814,\n",
       "       30312.514, 29988.918, 29525.484, 28713.5  , 27412.562, 24014.26 ,\n",
       "       21927.283, 21358.734, 21434.518, 20679.97 , 19391.584, 19363.014,\n",
       "       20344.055, 21034.309, 20350.678, 20564.588, 21155.748, 21321.615,\n",
       "       21404.629, 21092.783, 20823.201, 20233.65 , 19385.719, 19560.254,\n",
       "       19266.615, 19253.904, 19560.605, 20058.809, 20203.904, 20783.75 ,\n",
       "       21786.047, 21646.395, 21136.707, 20483.613, 19651.742, 19582.754,\n",
       "       20034.875, 20718.29 , 20852.105, 21207.031, 21792.465, 22464.576,\n",
       "       23510.908, 22944.822, 23123.186, 22455.248, 22599.436, 21893.271,\n",
       "       21017.66 , 21570.643, 23252.219, 23905.748, 24061.523, 23665.06 ,\n",
       "       23152.46 , 22857.953, 23071.516, 22783.13 , 23044.684, 23139.63 ,\n",
       "       23033.691, 23942.94 , 23548.604, 23574.705, 24467.572, 24046.754,\n",
       "       24563.12 , 24488.89 , 24359.04 , 23991.805, 23745.793, 23367.516,\n",
       "       21821.857, 21173.148, 21299.465, 21414.666, 21593.598, 21598.771,\n",
       "       21725.547, 21244.264, 20147.682, 19917.684, 19982.654, 20202.74 ,\n",
       "       20330.205, 20079.96 , 20191.459, 19876.633, 19900.361, 19943.951,\n",
       "       19781.482, 19029.562, 19407.658, 20875.107, 21573.309, 21862.844,\n",
       "       22406.617, 21777.027, 20390.871, 20127.518, 19866.758, 20136.174,\n",
       "       20094.992, 19253.787, 19447.137, 19275.111, 19203.432, 19243.252,\n",
       "       19256.906, 19191.58 , 19238.584, 19971.902, 19361.037, 19635.771,\n",
       "       19720.979, 19487.807, 19339.264, 19459.006, 20118.605, 20293.99 ,\n",
       "       20266.545, 19835.604, 19547.945, 19554.283, 19497.867, 19260.37 ,\n",
       "       19285.248, 19188.988, 19681.684, 19249.549, 19273.432, 19502.812,\n",
       "       19627.586, 19354.111, 19195.94 , 19139.666, 19251.324, 19387.38 ,\n",
       "       19508.803, 19726.06 , 20675.541, 20806.283, 20493.123, 20895.15 ,\n",
       "       20820.37 , 20646.951, 20616.834, 20561.162, 20423.648, 20820.74 ,\n",
       "       21365.904, 21419.484, 20899.188, 19420.553, 17213.223, 16611.463,\n",
       "       16686.691, 16843.91 , 16773.916, 16528.639, 16867.33 , 16725.273,\n",
       "       16641.082, 16762.123, 16675.47 , 16682.283, 16062.856, 15949.714,\n",
       "       16472.648, 16611.576, 16557.549, 16577.06 , 16573.248, 16221.   ,\n",
       "       16416.676, 16910.393, 17078.203, 16964.092, 16972.043, 17019.959,\n",
       "       17188.682, 17001.84 , 16894.795, 16917.627, 17177.184, 17144.354,\n",
       "       17147.348, 16966.959, 17439.848, 17837.555, 17513.262, 16976.547,\n",
       "       16475.52 , 16594.479, 16570.14 , 16729.043, 16787.643, 16756.217,\n",
       "       16819.906, 16811.738, 16834.582, 16853.982, 16811.758, 16661.168,\n",
       "       16605.271, 16558.37 , 16597.914, 16609.002], dtype=float32)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 238
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:25:26.503431Z",
     "start_time": "2024-04-21T17:25:26.490279Z"
    }
   },
   "source": [
    "r2=r2_score(y_test,y_pred) #testing score/ r^2\n",
    "r2"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9722489681030226"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 239
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:25:26.518854Z",
     "start_time": "2024-04-21T17:25:26.504931Z"
    }
   },
   "source": [
    "mae=mean_absolute_error(y_test,y_pred) #mae\n",
    "mae"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385.2131"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 240
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:25:26.534360Z",
     "start_time": "2024-04-21T17:25:26.519855Z"
    }
   },
   "source": [
    "rmse=np.sqrt(mean_squared_error(y_test,y_pred)) #rmse\n",
    "rmse"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570.2814"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 241
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:25:26.549873Z",
     "start_time": "2024-04-21T17:25:26.535360Z"
    }
   },
   "source": [
    "mape=mean_absolute_percentage_error(y_test,y_pred) #mape\n",
    "mape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.818205788731575"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 242
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:25:26.565378Z",
     "start_time": "2024-04-21T17:25:26.550873Z"
    }
   },
   "source": [
    "pd.DataFrame(zip(['MAE','RMSE','MAPE','R^2'],[mae,rmse,mape,r2])).transpose()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            0           1         2         3\n",
       "0         MAE        RMSE      MAPE       R^2\n",
       "1  385.213104  570.281372  1.818206  0.972249"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAE</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>MAPE</td>\n",
       "      <td>R^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>385.213104</td>\n",
       "      <td>570.281372</td>\n",
       "      <td>1.818206</td>\n",
       "      <td>0.972249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 243
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:25:26.580988Z",
     "start_time": "2024-04-21T17:25:26.566378Z"
    }
   },
   "source": [
    "pd.DataFrame([y_test,y_pred]).transpose()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           0             1\n",
       "0    28888.0  28962.757812\n",
       "1    29144.0  28909.298828\n",
       "2    30589.0  29178.941406\n",
       "3    31711.0  30571.599609\n",
       "4    31096.0  31794.376953\n",
       "..       ...           ...\n",
       "215  16591.0  16661.167969\n",
       "216  16550.0  16605.271484\n",
       "217  16570.0  16558.369141\n",
       "218  16559.0  16597.914062\n",
       "219  16691.0  16609.001953\n",
       "\n",
       "[220 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28888.0</td>\n",
       "      <td>28962.757812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29144.0</td>\n",
       "      <td>28909.298828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30589.0</td>\n",
       "      <td>29178.941406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31711.0</td>\n",
       "      <td>30571.599609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31096.0</td>\n",
       "      <td>31794.376953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>16591.0</td>\n",
       "      <td>16661.167969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>16550.0</td>\n",
       "      <td>16605.271484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>16570.0</td>\n",
       "      <td>16558.369141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>16559.0</td>\n",
       "      <td>16597.914062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>16691.0</td>\n",
       "      <td>16609.001953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 244
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:25:26.596503Z",
     "start_time": "2024-04-21T17:25:26.582488Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 244
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:25:26.611639Z",
     "start_time": "2024-04-21T17:25:26.598622Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 244
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:25:26.627148Z",
     "start_time": "2024-04-21T17:25:26.612639Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 244
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Stock Market Predictor.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
